{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"patentCity \u00b6 Welcome to the patentCity documentation website. patentCity is the data backbone of Bergeaud and Verluise (2021). BibTeX @techreport { bergeaudVerluise2021, title={ } , author= { Bergeaud, Antonin and Verluise, Cyril } , year= { 2021 } } Chicago Bergeaud, Antonin and Cyril Verluise. \"\". 2021 Here, you can find the project and API documentation. We open source the code to support future extensions and a collaborative way to create and continuously improve research databases. patentCity is due to expand and improve continuously in the coming years. Make sure you receive updates, join our newsletter and star the GitHub repository! #mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; width:100%;} /* Add your own Mailchimp form style overrides in your site stylesheet or in this style block. We recommend moving this block and the preceding CSS link to the HEAD of your HTML file. */ \ud83d\udc8c Subscribe","title":"About"},{"location":"#patentcity","text":"Welcome to the patentCity documentation website. patentCity is the data backbone of Bergeaud and Verluise (2021). BibTeX @techreport { bergeaudVerluise2021, title={ } , author= { Bergeaud, Antonin and Verluise, Cyril } , year= { 2021 } } Chicago Bergeaud, Antonin and Cyril Verluise. \"\". 2021 Here, you can find the project and API documentation. We open source the code to support future extensions and a collaborative way to create and continuously improve research databases. patentCity is due to expand and improve continuously in the coming years. Make sure you receive updates, join our newsletter and star the GitHub repository! #mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; width:100%;} /* Add your own Mailchimp form style overrides in your site stylesheet or in this style block. We recommend moving this block and the preceding CSS link to the HEAD of your HTML file. */ \ud83d\udc8c Subscribe","title":"patentCity"},{"location":"API_BREW/","text":"grind ( path , max_workers = 10 ) \u00b6 Stream texts in path and return json objects to stdout. Files are expected to be patent texts named after the publication_number of the patent (e.g. US-12345-A.txt). Parameters: Name Type Description Default path str data path, wildcard allowed required max_workers int max number of workers 10 Output : { \"publication_number\" : str , \"text\" : str , \"hash_id\" : str } Usage: patencity brew v1.grind \"data/US/*.txt\" # Nb: if the file is large, you can split and zip Source code in patentcity/brew.py 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 @app . command ( name = \"v1.grind\" ) def grind ( path : str , max_workers : int = 10 ): \"\"\"Stream texts in `path` and return json objects to stdout. Files are expected to be patent texts named after the publication_number of the patent (e.g. US-12345-A.txt). Arguments: path: data path, wildcard allowed max_workers: max number of workers **Output**: ```json {\"publication_number\": str, \"text\": str, \"hash_id\": str} ``` **Usage:** ```shell patencity brew v1.grind \"data/US/*.txt\" # Nb: if the file is large, you can split and zip ``` \"\"\" files = iglob ( path ) with ThreadPoolExecutor ( max_workers = max_workers ) as executor : executor . map ( _get_blob , files ) topping ( file , config_file = None , max_workers = 10 ) \u00b6 Stream data in file and return enriched v1 json object to stdout. Parameters: Name Type Description Default file str file path required config_file str topping config file None max_workers max number of workers 10 Output : { \"publication_number\" : str , \"patentee\" : List [ dict ], \"hash_id\" : str , \"model_ents\" : str , \"model_rels\" : str , \"git_sha\" : str } Usage: mv data/US/entrel_uspatentxx.jsonl data/US/entrel_uspatentxx.jsonl.tmp patencity v1.topping --config-file configs/top_xxpatentxx.yaml \"data/US/entrel_uspatentxx.jsonl.tmp\" # Nb: if the file is large, you can split and zip Source code in patentcity/brew.py 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 @app . command ( name = \"v1.topping\" ) def topping ( file : str , config_file : str = None , max_workers = 10 ): \"\"\"Stream data in `file` and return enriched v1 json object to stdout. Arguments: file: file path config_file: topping config file max_workers: max number of workers **Output**: ```json {\"publication_number\": str, \"patentee\": List[dict], \"hash_id\": str, \"model_ents\": str, \"model_rels\": str, \"git_sha\": str} ``` **Usage:** ```shell mv data/US/entrel_uspatentxx.jsonl data/US/entrel_uspatentxx.jsonl.tmp patencity v1.topping --config-file configs/top_xxpatentxx.yaml \"data/US/entrel_uspatentxx.jsonl.tmp\" # Nb: if the file is large, you can split and zip ``` \"\"\" with open ( config_file , \"r\" ) as config_file : config = yaml . load ( config_file , Loader = yaml . FullLoader ) for k , v in config [ \"cit_code\" ] . items (): config [ \"cit_code\" ] . update ({ k : json . loads ( open ( v , \"r\" ) . read ())}) with open ( file , \"r\" ) as lines : with ThreadPoolExecutor ( max_workers = max_workers ) as executor : executor . map ( _topping , lines , repeat ( config )) v1 ( path , model , rel_config , max_char = 9999 , batch_size = 1000 , inDelim = '|' ) \u00b6 Stream json objects in path and return json v1 objects to stdout. Parameters: Name Type Description Default path str data path, wildcard allowed required model str model path required rel_config str relationship resolution config file path required max_char int max char considered for entity extraction 9999 batch_size int size of the data batch passed to spaCy model 1000 inDelim str in delimiter '|' Output : { \"publication_number\" : str , \"patentee\" : List [ dict ], \"hash_id\" : str , \"model_ents\" : str , \"model_rels\" : str , \"git_sha\" : str } Usage: patencity brew v1 \"data/US/uspatentxx*.jsonl\" # Nb: if the file is large, you can split and zip Source code in patentcity/brew.py 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 @app . command () def v1 ( path : str , model : str , rel_config : str , max_char : int = 9999 , batch_size : int = 1000 , inDelim : str = \"|\" , ): \"\"\" Stream json objects in `path` and return json v1 objects to stdout. Arguments: path: data path, wildcard allowed model: model path rel_config: relationship resolution config file path max_char: max char considered for entity extraction batch_size: size of the data batch passed to spaCy model inDelim: in delimiter **Output**: ```json {\"publication_number\": str, \"patentee\": List[dict], \"hash_id\": str, \"model_ents\": str, \"model_rels\": str, \"git_sha\": str} ``` **Usage:** ```shell patencity brew v1 \"data/US/uspatentxx*.jsonl\" # Nb: if the file is large, you can split and zip ``` \"\"\" nlp = spacy . load ( model ) with open ( rel_config , \"r\" ) as config_file : config = yaml . load ( config_file , Loader = yaml . FullLoader ) nlp . add_pipe ( \"relation_extractor\" , config = { \"config\" : config }, last = True ) files = glob ( path ) for file in files : publication_numbers = list ( ( json . loads ( line )[ \"publication_number\" ] for line in open ( file , \"r\" )) ) hash_ids = list (( json . loads ( line )[ \"hash_id\" ] for line in open ( file , \"r\" ))) with open ( file , \"r\" ) as lines : texts = ( json . loads ( line )[ \"text\" ][: max_char ] for line in lines ) docs = nlp . pipe ( texts , batch_size = batch_size ) for i , doc in enumerate ( docs ): publication_number = publication_numbers [ i ] hash_id = hash_ids [ i ] patentees = [ { k : clean_text ( v , inDelim ) for k , v in patentee . items ()} for patentee in doc . _ . patentees ] row = { \"publication_number\" : publication_number , \"patentee\" : patentees , \"hash_id\" : hash_id , \"model_ents\" : model , \"model_rels\" : rel_config , \"git_sha\" : sha , } typer . echo ( json . dumps ( row ))","title":"brew"},{"location":"API_BREW/#patentcity.brew.grind","text":"Stream texts in path and return json objects to stdout. Files are expected to be patent texts named after the publication_number of the patent (e.g. US-12345-A.txt). Parameters: Name Type Description Default path str data path, wildcard allowed required max_workers int max number of workers 10 Output : { \"publication_number\" : str , \"text\" : str , \"hash_id\" : str } Usage: patencity brew v1.grind \"data/US/*.txt\" # Nb: if the file is large, you can split and zip Source code in patentcity/brew.py 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 @app . command ( name = \"v1.grind\" ) def grind ( path : str , max_workers : int = 10 ): \"\"\"Stream texts in `path` and return json objects to stdout. Files are expected to be patent texts named after the publication_number of the patent (e.g. US-12345-A.txt). Arguments: path: data path, wildcard allowed max_workers: max number of workers **Output**: ```json {\"publication_number\": str, \"text\": str, \"hash_id\": str} ``` **Usage:** ```shell patencity brew v1.grind \"data/US/*.txt\" # Nb: if the file is large, you can split and zip ``` \"\"\" files = iglob ( path ) with ThreadPoolExecutor ( max_workers = max_workers ) as executor : executor . map ( _get_blob , files )","title":"grind()"},{"location":"API_BREW/#patentcity.brew.topping","text":"Stream data in file and return enriched v1 json object to stdout. Parameters: Name Type Description Default file str file path required config_file str topping config file None max_workers max number of workers 10 Output : { \"publication_number\" : str , \"patentee\" : List [ dict ], \"hash_id\" : str , \"model_ents\" : str , \"model_rels\" : str , \"git_sha\" : str } Usage: mv data/US/entrel_uspatentxx.jsonl data/US/entrel_uspatentxx.jsonl.tmp patencity v1.topping --config-file configs/top_xxpatentxx.yaml \"data/US/entrel_uspatentxx.jsonl.tmp\" # Nb: if the file is large, you can split and zip Source code in patentcity/brew.py 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 @app . command ( name = \"v1.topping\" ) def topping ( file : str , config_file : str = None , max_workers = 10 ): \"\"\"Stream data in `file` and return enriched v1 json object to stdout. Arguments: file: file path config_file: topping config file max_workers: max number of workers **Output**: ```json {\"publication_number\": str, \"patentee\": List[dict], \"hash_id\": str, \"model_ents\": str, \"model_rels\": str, \"git_sha\": str} ``` **Usage:** ```shell mv data/US/entrel_uspatentxx.jsonl data/US/entrel_uspatentxx.jsonl.tmp patencity v1.topping --config-file configs/top_xxpatentxx.yaml \"data/US/entrel_uspatentxx.jsonl.tmp\" # Nb: if the file is large, you can split and zip ``` \"\"\" with open ( config_file , \"r\" ) as config_file : config = yaml . load ( config_file , Loader = yaml . FullLoader ) for k , v in config [ \"cit_code\" ] . items (): config [ \"cit_code\" ] . update ({ k : json . loads ( open ( v , \"r\" ) . read ())}) with open ( file , \"r\" ) as lines : with ThreadPoolExecutor ( max_workers = max_workers ) as executor : executor . map ( _topping , lines , repeat ( config ))","title":"topping()"},{"location":"API_BREW/#patentcity.brew.v1","text":"Stream json objects in path and return json v1 objects to stdout. Parameters: Name Type Description Default path str data path, wildcard allowed required model str model path required rel_config str relationship resolution config file path required max_char int max char considered for entity extraction 9999 batch_size int size of the data batch passed to spaCy model 1000 inDelim str in delimiter '|' Output : { \"publication_number\" : str , \"patentee\" : List [ dict ], \"hash_id\" : str , \"model_ents\" : str , \"model_rels\" : str , \"git_sha\" : str } Usage: patencity brew v1 \"data/US/uspatentxx*.jsonl\" # Nb: if the file is large, you can split and zip Source code in patentcity/brew.py 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 @app . command () def v1 ( path : str , model : str , rel_config : str , max_char : int = 9999 , batch_size : int = 1000 , inDelim : str = \"|\" , ): \"\"\" Stream json objects in `path` and return json v1 objects to stdout. Arguments: path: data path, wildcard allowed model: model path rel_config: relationship resolution config file path max_char: max char considered for entity extraction batch_size: size of the data batch passed to spaCy model inDelim: in delimiter **Output**: ```json {\"publication_number\": str, \"patentee\": List[dict], \"hash_id\": str, \"model_ents\": str, \"model_rels\": str, \"git_sha\": str} ``` **Usage:** ```shell patencity brew v1 \"data/US/uspatentxx*.jsonl\" # Nb: if the file is large, you can split and zip ``` \"\"\" nlp = spacy . load ( model ) with open ( rel_config , \"r\" ) as config_file : config = yaml . load ( config_file , Loader = yaml . FullLoader ) nlp . add_pipe ( \"relation_extractor\" , config = { \"config\" : config }, last = True ) files = glob ( path ) for file in files : publication_numbers = list ( ( json . loads ( line )[ \"publication_number\" ] for line in open ( file , \"r\" )) ) hash_ids = list (( json . loads ( line )[ \"hash_id\" ] for line in open ( file , \"r\" ))) with open ( file , \"r\" ) as lines : texts = ( json . loads ( line )[ \"text\" ][: max_char ] for line in lines ) docs = nlp . pipe ( texts , batch_size = batch_size ) for i , doc in enumerate ( docs ): publication_number = publication_numbers [ i ] hash_id = hash_ids [ i ] patentees = [ { k : clean_text ( v , inDelim ) for k , v in patentee . items ()} for patentee in doc . _ . patentees ] row = { \"publication_number\" : publication_number , \"patentee\" : patentees , \"hash_id\" : hash_id , \"model_ents\" : model , \"model_rels\" : rel_config , \"git_sha\" : sha , } typer . echo ( json . dumps ( row ))","title":"v1()"},{"location":"API_EVAL/","text":"citizenship_fst ( test_file , fst_file , fuzzy_match = True , verbose = False ) \u00b6 Evaluate citizenship finite state transducer and return report to stdout Parameters: Name Type Description Default test_file str test file path required fst_file str fst file path required fuzzy_match bool accept/reject fuzzy match True verbose bool report verbosity False Usage: patentcity eval citizenship-fst data/gold_cit_uspatent01.csv lib/fst_cit.json Source code in patentcity/eval.py 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 @app . command () def citizenship_fst ( test_file : str , fst_file : str , fuzzy_match : bool = True , verbose : bool = False ): \"\"\"Evaluate citizenship finite state transducer and return report to stdout Arguments: test_file: test file path fst_file: fst file path fuzzy_match: accept/reject fuzzy match verbose: report verbosity **Usage:** ```shell patentcity eval citizenship-fst data/gold_cit_uspatent01.csv lib/fst_cit.json ``` \"\"\" fst = json . loads ( open ( fst_file , \"r\" ) . read ()) test_df = pd . read_csv ( test_file , sep = \";\" ) test_df = test_df . replace ({ np . nan : None }) res = [] for i , row in test_df . iterrows (): text = row [ \"text\" ] pred = get_cit_code ( text , fst , fuzzy_match ) res += [ [ row [ \"publication_number\" ], text , row [ \"gold\" ], pred , row [ \"gold\" ] == pred ] ] res = pd . DataFrame ( res , columns = [ \"publication_number\" , \"text\" , \"gold\" , \"pred\" , \"res\" ] ) errors = res . query ( \"res==False\" ) filename = os . path . basename ( test_file ) acc = 1 - len ( errors ) / len ( res ) typer . secho ( f \"## { filename } \\n \" , fg = typer . colors . BLUE ) typer . echo ( f \"Accuracy (fuzzy-match { fuzzy_match } ): { acc * 100 : .2f } % \\n \" ) if verbose : typer . echo ( f \"### Errors \\n { errors . to_markdown () } \" ) patentee_deduplication ( test_file , verbose = False ) \u00b6 Evaluate patentee deduplication and return the best threshold and related deduplication accuracy to stdout. Note: Deduplication is based on the relative levenshtein edit distance. Parameters: Name Type Description Default test_file str test file path required verbose bool report verbosity False Usage: patentcity eval patentee-deduplication data/gold_deduplication_uspatent01.jsonl Source code in patentcity/eval.py 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 @app . command () def patentee_deduplication ( test_file : str , verbose : bool = False ): \"\"\"Evaluate patentee deduplication and return the best threshold and related deduplication accuracy to stdout. Note: Deduplication is based on the relative levenshtein edit distance. Arguments: test_file: test file path verbose: report verbosity **Usage:** ```shell patentcity eval patentee-deduplication data/gold_deduplication_uspatent01.jsonl ``` \"\"\" df = pd . read_json ( test_file , lines = True ) df [ \"clas\" ] = df [ \"answer\" ] . apply ( lambda x : 0 if x == \"reject\" else ( 1 if x == \"accept\" else None ) ) df = df . query ( \"clas==clas\" ) . copy () accuracy = {} for threshold in np . arange ( 0 , 2 , 0.01 ): df [ \"pred\" ] = df [ \"lev_dist_rel\" ] . apply ( lambda x : 1 if x < threshold else 0 ) nb_true = len ( df . query ( \"clas==pred\" )) acc = nb_true / len ( df ) accuracy . update ({ threshold : acc }) accuracy = pd . DataFrame . from_dict ( accuracy , orient = \"index\" , columns = [ \"accuracy\" ]) if verbose : typer . secho ( \"## Levenshtein distance (rel) distribution\" , fg = typer . colors . BLUE ) typer . echo ( ( df . groupby ( \"answer\" ) . describe ( percentiles = np . arange ( 0 , 1 , 0.01 ))[ \"lev_dist_rel\" ] . filter ( regex = \"%\" ) . T . to_markdown () ) ) threshold_star , accuracy_star = ( accuracy . idxmax () . values [ 0 ], accuracy . max () . values [ 0 ], ) typer . secho ( \"## Best\" , fg = typer . colors . BLUE ) typer . echo ( f \"Best threshold: { threshold_star } \\n Accuracy: { accuracy_star } \" ) relationship_model ( test_file , rel_config , report = 'short' ) \u00b6 Evaluate relationship model and return report to stdout Parameters: Name Type Description Default test_file str test file path required rel_config str relationship resolution config file path required report str size and format of the performance report (in \"short\", \"long\", \"json\") 'short' Usage: patentcity eval relationship-model gold_rel_uspatent01.jsonl configs/rel_uspatent01.yaml Source code in patentcity/eval.py 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 @app . command () def relationship_model ( test_file : str , rel_config : str , report : str = \"short\" ): \"\"\" Evaluate relationship model and return report to stdout Arguments: test_file: test file path rel_config: relationship resolution config file path report: size and format of the performance report (in \"short\", \"long\", \"json\") **Usage:** ```shell patentcity eval relationship-model gold_rel_uspatent01.jsonl configs/rel_uspatent01.yaml ``` \"\"\" # TODO Transition to EntityRelationshipComponent assert report in [ \"short\" , \"long\" , \"json\" ] def eval_performance ( pred , gold , label : str = None ): def get_rel ( relations , label ): rel = [ { \"head\" : [ rel [ \"head_span\" ][ \"token_start\" ], rel [ \"head_span\" ][ \"token_end\" ], ], \"child\" : [ rel [ \"child_span\" ][ \"token_start\" ], rel [ \"child_span\" ][ \"token_end\" ], ], \"label\" : rel [ \"label\" ], } for rel in relations ] if label : rel = [ rel_ for rel_ in rel if rel_ [ \"label\" ] == label ] return rel rel_pred = get_rel ( pred , label ) rel_gold = get_rel ( gold , label ) true = list ( rel_gold ) true_positives = [ rel for rel in rel_pred if rel in rel_gold ] false_positives = [ rel for rel in rel_pred if rel not in rel_gold ] false_negatives = [ rel for rel in rel_gold if rel not in rel_pred ] return true , true_positives , false_positives , false_negatives def report_errors ( errors ): # an error is expressed as a rel with tokens # {\"head\": [head_start, head_end], \"child\": [child_start, child_end], \"label\": label, # \"tokens\": list} def report_error ( error ): tokens = error [ \"tokens\" ] def get_text ( tokens , boundaries ): text = tokens [ boundaries [ 0 ] : boundaries [ 1 ] + 1 ] text = \" \" . join ( text ) . replace ( \" \\n \" , \"\" ) return text start = min ( error [ \"head\" ][ 0 ], error [ \"child\" ][ 0 ]) end = max ( error [ \"head\" ][ 1 ], error [ \"child\" ][ 1 ]) error_rel = f \"\"\" { get_text ( tokens , error [ 'head' ]) } ( { error [ 'head' ] } )->- { error [ 'label' ] } ->- { get_text ( tokens , error [ 'child' ]) } ( { error [ 'child' ] } )\"\"\" . replace ( \" \\n \" , \"\" ) error_context = f \"\"\" { get_text ( tokens , [ start , end ]) } \"\"\" return error_rel , error_context data = [] for error in errors : data += [ report_error ( error )] typer . echo ( pd . DataFrame ( columns = [ \"error_rel\" , \"error_context\" ], data = data ) . to_markdown ( index = False ) ) def get_relation ( head , child ): relation = [] if child : for child_ in child : # nb: in some configs (max_n >1), there might be more than 1 child # here generate something in the flavor of eg[\"relations\"] for eval relation += [ { \"child\" : child_ [ \"token_end\" ], \"child_span\" : child_ , \"head\" : head [ \"token_end\" ], \"head_span\" : head , \"label\" : RELATIONS [ child_ [ \"label\" ]], } ] return relation def get_report ( truth_categories , report ): def filter_relation ( label , * args ): assert label in list ( RELATIONS . values ()) for l in args : yield [ e for e in l if e [ \"label\" ] == label ] def get_metrics ( true , true_positives , false_positives , false_negatives , label = None ): if label : true , true_positives , false_positives , false_negatives = filter_relation ( label , true , true_positives , false_positives , false_negatives ) # nb_t = len(true) nb_tp = len ( true_positives ) nb_fp = len ( false_positives ) nb_fn = len ( false_negatives ) try : prec = nb_tp / ( nb_tp + nb_fp ) rec = nb_tp / ( nb_tp + nb_fn ) f1 = 2 * prec * rec / ( prec + rec ) except ZeroDivisionError : rec = prec = f1 = None return prec , rec , f1 true , true_positives , false_positives , false_negatives = truth_categories res = {} for label in [ None ] + list ( RELATIONS . values ()): prec , rec , f1 = get_metrics ( true , true_positives , false_positives , false_negatives , label ) label = label if label else \"ALL\" if all ([ prec , rec , f1 ]): res . update ( { label : { \"p\" : round ( prec , 3 ), \"r\" : round ( rec , 3 ), \"f\" : round ( f1 , 3 ), } } ) else : res . update ({ label : { \"p\" : None , \"r\" : None , \"f\" : None }}) if report == \"json\" : typer . echo ( json . dumps ( res )) else : typer . secho ( \" \\n # Report\" , fg = typer . colors . BLUE ) typer . echo ( f \"Config file: { rel_config } \" ) typer . secho ( \" \\n ## Performance\" , fg = typer . colors . BLUE ) typer . echo ( pd . DataFrame . from_dict ( res ) . to_markdown ()) if report == \"long\" : typer . secho ( \" \\n ## False positives\" , fg = typer . colors . BLUE ) report_errors ( sorted ( false_positives , key = lambda d : d [ \"label\" ])) typer . secho ( \" \\n ## False negatives\" , fg = typer . colors . BLUE ) report_errors ( sorted ( false_negatives , key = lambda d : d [ \"label\" ])) true , true_positives , false_positives , false_negatives = [], [], [], [] with open ( rel_config , \"r\" ) as config_file : cfg = yaml . load ( config_file , Loader = yaml . FullLoader ) with open ( test_file , \"r\" ) as lines : for line in lines : eg = json . loads ( line ) ents = eg [ \"spans\" ] relations_gold = eg [ \"relations\" ] heads = [ ent for ent in ents if ent [ \"label\" ] in [ \"ASG\" , \"INV\" ]] children = [ ent for ent in ents if ent [ \"label\" ] not in [ \"ASG\" , \"INV\" ]] relations_pred = [] for head in heads : for label in [ \"LOC\" , \"OCC\" , \"CIT\" ]: cfg_ = cfg [ label ] child = get_child ( head , children , label , cfg_ [ \"max_length\" ], cfg_ [ \"position\" ], cfg_ [ \"max_n\" ], ) relations_pred += get_relation ( head , child ) true_ , true_positives_ , false_positives_ , false_negatives_ = eval_performance ( relations_pred , relations_gold ) true += true_ true_positives += true_positives_ false_positives += [ { ** fp , ** { \"tokens\" : [ tok [ \"text\" ] for tok in eg [ \"tokens\" ]]}} for fp in false_positives_ ] false_negatives += [ { ** fn , ** { \"tokens\" : [ tok [ \"text\" ] for tok in eg [ \"tokens\" ]]}} for fn in false_negatives_ ] get_report (( true , true_positives , false_positives , false_negatives ), report ) spacy_model ( model , components = 'ner' ) \u00b6 Evaluate spaCy model components and return report to stdout. Notes: i) only \"ner\" component is supported so far ii) report results from runtime eval Parameters: Name Type Description Default model str model path required components str spaCy model components (comma separated) 'ner' Usage: patentcity eval spacy-model models/en_ent_uspatent01 Source code in patentcity/eval.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 @app . command () def spacy_model ( model : str , components : str = \"ner\" ): \"\"\"Evaluate spaCy model `components` and return report to stdout. Notes: i) only \"ner\" component is supported so far ii) report results from runtime eval Arguments: model: model path components: spaCy model components (comma separated) **Usage:** ```shell patentcity eval spacy-model models/en_ent_uspatent01 ``` \"\"\" scores = json . loads ( open ( os . path . join ( model , \"meta.json\" ), \"r\" ) . read ())[ \"performance\" ] components = components . split ( \",\" ) if \"ner\" in components : p , r , f = scores [ \"ents_p\" ], scores [ \"ents_r\" ], scores [ \"ents_f\" ] typer . secho ( \"NER Scores\" , fg = typer . colors . BLUE ) perfs = pd . DataFrame . from_dict ( scores [ \"ents_per_type\" ]) perfs [ \"ALL\" ] = ( p , r , f ) perfs = perfs . round ( 2 ) perfs = perfs [ sorted ( perfs . columns )] typer . echo ( f \" { perfs . to_markdown () } \" )","title":"eval"},{"location":"API_EVAL/#patentcity.eval.citizenship_fst","text":"Evaluate citizenship finite state transducer and return report to stdout Parameters: Name Type Description Default test_file str test file path required fst_file str fst file path required fuzzy_match bool accept/reject fuzzy match True verbose bool report verbosity False Usage: patentcity eval citizenship-fst data/gold_cit_uspatent01.csv lib/fst_cit.json Source code in patentcity/eval.py 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 @app . command () def citizenship_fst ( test_file : str , fst_file : str , fuzzy_match : bool = True , verbose : bool = False ): \"\"\"Evaluate citizenship finite state transducer and return report to stdout Arguments: test_file: test file path fst_file: fst file path fuzzy_match: accept/reject fuzzy match verbose: report verbosity **Usage:** ```shell patentcity eval citizenship-fst data/gold_cit_uspatent01.csv lib/fst_cit.json ``` \"\"\" fst = json . loads ( open ( fst_file , \"r\" ) . read ()) test_df = pd . read_csv ( test_file , sep = \";\" ) test_df = test_df . replace ({ np . nan : None }) res = [] for i , row in test_df . iterrows (): text = row [ \"text\" ] pred = get_cit_code ( text , fst , fuzzy_match ) res += [ [ row [ \"publication_number\" ], text , row [ \"gold\" ], pred , row [ \"gold\" ] == pred ] ] res = pd . DataFrame ( res , columns = [ \"publication_number\" , \"text\" , \"gold\" , \"pred\" , \"res\" ] ) errors = res . query ( \"res==False\" ) filename = os . path . basename ( test_file ) acc = 1 - len ( errors ) / len ( res ) typer . secho ( f \"## { filename } \\n \" , fg = typer . colors . BLUE ) typer . echo ( f \"Accuracy (fuzzy-match { fuzzy_match } ): { acc * 100 : .2f } % \\n \" ) if verbose : typer . echo ( f \"### Errors \\n { errors . to_markdown () } \" )","title":"citizenship_fst()"},{"location":"API_EVAL/#patentcity.eval.patentee_deduplication","text":"Evaluate patentee deduplication and return the best threshold and related deduplication accuracy to stdout. Note: Deduplication is based on the relative levenshtein edit distance. Parameters: Name Type Description Default test_file str test file path required verbose bool report verbosity False Usage: patentcity eval patentee-deduplication data/gold_deduplication_uspatent01.jsonl Source code in patentcity/eval.py 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 @app . command () def patentee_deduplication ( test_file : str , verbose : bool = False ): \"\"\"Evaluate patentee deduplication and return the best threshold and related deduplication accuracy to stdout. Note: Deduplication is based on the relative levenshtein edit distance. Arguments: test_file: test file path verbose: report verbosity **Usage:** ```shell patentcity eval patentee-deduplication data/gold_deduplication_uspatent01.jsonl ``` \"\"\" df = pd . read_json ( test_file , lines = True ) df [ \"clas\" ] = df [ \"answer\" ] . apply ( lambda x : 0 if x == \"reject\" else ( 1 if x == \"accept\" else None ) ) df = df . query ( \"clas==clas\" ) . copy () accuracy = {} for threshold in np . arange ( 0 , 2 , 0.01 ): df [ \"pred\" ] = df [ \"lev_dist_rel\" ] . apply ( lambda x : 1 if x < threshold else 0 ) nb_true = len ( df . query ( \"clas==pred\" )) acc = nb_true / len ( df ) accuracy . update ({ threshold : acc }) accuracy = pd . DataFrame . from_dict ( accuracy , orient = \"index\" , columns = [ \"accuracy\" ]) if verbose : typer . secho ( \"## Levenshtein distance (rel) distribution\" , fg = typer . colors . BLUE ) typer . echo ( ( df . groupby ( \"answer\" ) . describe ( percentiles = np . arange ( 0 , 1 , 0.01 ))[ \"lev_dist_rel\" ] . filter ( regex = \"%\" ) . T . to_markdown () ) ) threshold_star , accuracy_star = ( accuracy . idxmax () . values [ 0 ], accuracy . max () . values [ 0 ], ) typer . secho ( \"## Best\" , fg = typer . colors . BLUE ) typer . echo ( f \"Best threshold: { threshold_star } \\n Accuracy: { accuracy_star } \" )","title":"patentee_deduplication()"},{"location":"API_EVAL/#patentcity.eval.relationship_model","text":"Evaluate relationship model and return report to stdout Parameters: Name Type Description Default test_file str test file path required rel_config str relationship resolution config file path required report str size and format of the performance report (in \"short\", \"long\", \"json\") 'short' Usage: patentcity eval relationship-model gold_rel_uspatent01.jsonl configs/rel_uspatent01.yaml Source code in patentcity/eval.py 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 @app . command () def relationship_model ( test_file : str , rel_config : str , report : str = \"short\" ): \"\"\" Evaluate relationship model and return report to stdout Arguments: test_file: test file path rel_config: relationship resolution config file path report: size and format of the performance report (in \"short\", \"long\", \"json\") **Usage:** ```shell patentcity eval relationship-model gold_rel_uspatent01.jsonl configs/rel_uspatent01.yaml ``` \"\"\" # TODO Transition to EntityRelationshipComponent assert report in [ \"short\" , \"long\" , \"json\" ] def eval_performance ( pred , gold , label : str = None ): def get_rel ( relations , label ): rel = [ { \"head\" : [ rel [ \"head_span\" ][ \"token_start\" ], rel [ \"head_span\" ][ \"token_end\" ], ], \"child\" : [ rel [ \"child_span\" ][ \"token_start\" ], rel [ \"child_span\" ][ \"token_end\" ], ], \"label\" : rel [ \"label\" ], } for rel in relations ] if label : rel = [ rel_ for rel_ in rel if rel_ [ \"label\" ] == label ] return rel rel_pred = get_rel ( pred , label ) rel_gold = get_rel ( gold , label ) true = list ( rel_gold ) true_positives = [ rel for rel in rel_pred if rel in rel_gold ] false_positives = [ rel for rel in rel_pred if rel not in rel_gold ] false_negatives = [ rel for rel in rel_gold if rel not in rel_pred ] return true , true_positives , false_positives , false_negatives def report_errors ( errors ): # an error is expressed as a rel with tokens # {\"head\": [head_start, head_end], \"child\": [child_start, child_end], \"label\": label, # \"tokens\": list} def report_error ( error ): tokens = error [ \"tokens\" ] def get_text ( tokens , boundaries ): text = tokens [ boundaries [ 0 ] : boundaries [ 1 ] + 1 ] text = \" \" . join ( text ) . replace ( \" \\n \" , \"\" ) return text start = min ( error [ \"head\" ][ 0 ], error [ \"child\" ][ 0 ]) end = max ( error [ \"head\" ][ 1 ], error [ \"child\" ][ 1 ]) error_rel = f \"\"\" { get_text ( tokens , error [ 'head' ]) } ( { error [ 'head' ] } )->- { error [ 'label' ] } ->- { get_text ( tokens , error [ 'child' ]) } ( { error [ 'child' ] } )\"\"\" . replace ( \" \\n \" , \"\" ) error_context = f \"\"\" { get_text ( tokens , [ start , end ]) } \"\"\" return error_rel , error_context data = [] for error in errors : data += [ report_error ( error )] typer . echo ( pd . DataFrame ( columns = [ \"error_rel\" , \"error_context\" ], data = data ) . to_markdown ( index = False ) ) def get_relation ( head , child ): relation = [] if child : for child_ in child : # nb: in some configs (max_n >1), there might be more than 1 child # here generate something in the flavor of eg[\"relations\"] for eval relation += [ { \"child\" : child_ [ \"token_end\" ], \"child_span\" : child_ , \"head\" : head [ \"token_end\" ], \"head_span\" : head , \"label\" : RELATIONS [ child_ [ \"label\" ]], } ] return relation def get_report ( truth_categories , report ): def filter_relation ( label , * args ): assert label in list ( RELATIONS . values ()) for l in args : yield [ e for e in l if e [ \"label\" ] == label ] def get_metrics ( true , true_positives , false_positives , false_negatives , label = None ): if label : true , true_positives , false_positives , false_negatives = filter_relation ( label , true , true_positives , false_positives , false_negatives ) # nb_t = len(true) nb_tp = len ( true_positives ) nb_fp = len ( false_positives ) nb_fn = len ( false_negatives ) try : prec = nb_tp / ( nb_tp + nb_fp ) rec = nb_tp / ( nb_tp + nb_fn ) f1 = 2 * prec * rec / ( prec + rec ) except ZeroDivisionError : rec = prec = f1 = None return prec , rec , f1 true , true_positives , false_positives , false_negatives = truth_categories res = {} for label in [ None ] + list ( RELATIONS . values ()): prec , rec , f1 = get_metrics ( true , true_positives , false_positives , false_negatives , label ) label = label if label else \"ALL\" if all ([ prec , rec , f1 ]): res . update ( { label : { \"p\" : round ( prec , 3 ), \"r\" : round ( rec , 3 ), \"f\" : round ( f1 , 3 ), } } ) else : res . update ({ label : { \"p\" : None , \"r\" : None , \"f\" : None }}) if report == \"json\" : typer . echo ( json . dumps ( res )) else : typer . secho ( \" \\n # Report\" , fg = typer . colors . BLUE ) typer . echo ( f \"Config file: { rel_config } \" ) typer . secho ( \" \\n ## Performance\" , fg = typer . colors . BLUE ) typer . echo ( pd . DataFrame . from_dict ( res ) . to_markdown ()) if report == \"long\" : typer . secho ( \" \\n ## False positives\" , fg = typer . colors . BLUE ) report_errors ( sorted ( false_positives , key = lambda d : d [ \"label\" ])) typer . secho ( \" \\n ## False negatives\" , fg = typer . colors . BLUE ) report_errors ( sorted ( false_negatives , key = lambda d : d [ \"label\" ])) true , true_positives , false_positives , false_negatives = [], [], [], [] with open ( rel_config , \"r\" ) as config_file : cfg = yaml . load ( config_file , Loader = yaml . FullLoader ) with open ( test_file , \"r\" ) as lines : for line in lines : eg = json . loads ( line ) ents = eg [ \"spans\" ] relations_gold = eg [ \"relations\" ] heads = [ ent for ent in ents if ent [ \"label\" ] in [ \"ASG\" , \"INV\" ]] children = [ ent for ent in ents if ent [ \"label\" ] not in [ \"ASG\" , \"INV\" ]] relations_pred = [] for head in heads : for label in [ \"LOC\" , \"OCC\" , \"CIT\" ]: cfg_ = cfg [ label ] child = get_child ( head , children , label , cfg_ [ \"max_length\" ], cfg_ [ \"position\" ], cfg_ [ \"max_n\" ], ) relations_pred += get_relation ( head , child ) true_ , true_positives_ , false_positives_ , false_negatives_ = eval_performance ( relations_pred , relations_gold ) true += true_ true_positives += true_positives_ false_positives += [ { ** fp , ** { \"tokens\" : [ tok [ \"text\" ] for tok in eg [ \"tokens\" ]]}} for fp in false_positives_ ] false_negatives += [ { ** fn , ** { \"tokens\" : [ tok [ \"text\" ] for tok in eg [ \"tokens\" ]]}} for fn in false_negatives_ ] get_report (( true , true_positives , false_positives , false_negatives ), report )","title":"relationship_model()"},{"location":"API_EVAL/#patentcity.eval.spacy_model","text":"Evaluate spaCy model components and return report to stdout. Notes: i) only \"ner\" component is supported so far ii) report results from runtime eval Parameters: Name Type Description Default model str model path required components str spaCy model components (comma separated) 'ner' Usage: patentcity eval spacy-model models/en_ent_uspatent01 Source code in patentcity/eval.py 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 @app . command () def spacy_model ( model : str , components : str = \"ner\" ): \"\"\"Evaluate spaCy model `components` and return report to stdout. Notes: i) only \"ner\" component is supported so far ii) report results from runtime eval Arguments: model: model path components: spaCy model components (comma separated) **Usage:** ```shell patentcity eval spacy-model models/en_ent_uspatent01 ``` \"\"\" scores = json . loads ( open ( os . path . join ( model , \"meta.json\" ), \"r\" ) . read ())[ \"performance\" ] components = components . split ( \",\" ) if \"ner\" in components : p , r , f = scores [ \"ents_p\" ], scores [ \"ents_r\" ], scores [ \"ents_f\" ] typer . secho ( \"NER Scores\" , fg = typer . colors . BLUE ) perfs = pd . DataFrame . from_dict ( scores [ \"ents_per_type\" ]) perfs [ \"ALL\" ] = ( p , r , f ) perfs = perfs . round ( 2 ) perfs = perfs [ sorted ( perfs . columns )] typer . echo ( f \" { perfs . to_markdown () } \" )","title":"spacy_model()"},{"location":"API_GEO/","text":"add_geoc_data ( file , geoc_file , source = None , max_workers = 5 , verbose = False ) \u00b6 Add geoc data from geoc_file to file Parameters: Name Type Description Default file str file path required geoc_file str geoc file path (geocoding output, csv) required source str geocoding service (in [\"HERE\", \"GMAPS\", \"MANUAL\"]) None max_workers int max number of workers 5 verbose bool verbosity False Usage: patentcity geo add entrel_uspatentxx.jsonl geoc_uspatentxx.here.csv --source HERE Source code in patentcity/geo.py 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 @app . command ( name = \"add\" ) def add_geoc_data ( file : str , geoc_file : str , source : str = None , max_workers : int = 5 , verbose : bool = False , ): \"\"\"Add geoc data from `geoc_file`to `file` Arguments: file: file path geoc_file: geoc file path (geocoding output, csv) source: geocoding service (in [\"HERE\", \"GMAPS\", \"MANUAL\"]) max_workers: max number of workers verbose: verbosity **Usage:** ```shell patentcity geo add entrel_uspatentxx.jsonl geoc_uspatentxx.here.csv --source HERE ``` \"\"\" assert source in [ \"GMAPS\" , \"HERE\" , \"MANUAL\" ] index = _get_geoc_index ( geoc_file , dump = False ) blobs = open ( file , \"r\" ) with ThreadPoolExecutor ( max_workers = max_workers ) as executor : executor . map ( _update_loc , blobs , repeat ( source ), repeat ( index ), repeat ( verbose )) add_geoc_disamb ( disamb_file , index_geoc_file , flavor = 'GMAPS' , inDelim = '|' ) \u00b6 Return a list of recId|geoc(target) from a list of recid|target. Parameters: Name Type Description Default disamb_file str disambiguation data file path required index_geoc_file str index geocoding file path required flavor str flavor of index_geoc_file (in [\"HERE\",\"GMAPS\"]) 'GMAPS' inDelim str inner delimiter '|' Usage: patentcity geo add.disamb ${ DISAMBFILE } ${ GEOCINDEX } --flavor ${ FLAVOR } Info Use before patentcity geo add Source code in patentcity/geo.py 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 @app . command ( name = \"add.disamb\" ) def add_geoc_disamb ( disamb_file : str , index_geoc_file : str , flavor : str = \"GMAPS\" , inDelim : str = \"|\" ): \"\"\"Return a list of recId|geoc(target) from a list of recid|target. Arguments: disamb_file: disambiguation data file path index_geoc_file: index geocoding file path flavor: flavor of `index_geoc_file` (in [\"HERE\",\"GMAPS\"]) inDelim: inner delimiter **Usage:** ```shell patentcity geo add.disamb ${DISAMBFILE} ${GEOCINDEX} --flavor ${FLAVOR} ``` !!! info Use before `patentcity geo add` \"\"\" assert flavor in [ \"GMAPS\" , \"HERE\" ] if flavor == \"GMAPS\" : index = {} with open ( index_geoc_file , \"r\" ) as lines : for line in lines : recid , geoc = line . split ( inDelim ) index . update ({ recid : json . loads ( geoc )}) with open ( disamb_file , \"r\" ) as lines : for line in lines : recid , disamb_loc = line . split ( inDelim ) disamb_loc_recid = get_recid ( clean_text ( disamb_loc )) typer . echo ( f \" { recid }{ inDelim }{ json . dumps ( index . get ( disamb_loc_recid )) } \" ) else : index = _get_geoc_index ( index_geoc_file , dump = False ) fieldnames = GEOC_OUTCOLS writer = csv . DictWriter ( sys . stdout , fieldnames = fieldnames ) writer . writeheader () with open ( disamb_file , \"r\" ) as lines : for line in lines : recid , searchtext = line . replace ( \" \\n \" , \"\" ) . split ( inDelim ) geoc_disamb = index . get ( get_recid ( searchtext )) geoc_disamb . update ({ \"recId\" : recid }) writer . writerow ( geoc_disamb ) add_statisticalareas ( file , statisticalareas_path , verbose = False ) \u00b6 Return file with statistical areas to stdout. Parameters: Name Type Description Default file str file path required statisticalareas_path str satistical area files path (wildcard allowed) required verbose bool verbosity False Usage: patentcity geo add.statisticalareas geoc_gbpatentxx.here.csv \"assets/statisticalareas_*.csv\" Source code in patentcity/geo.py 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 @app . command ( name = \"add.statisticalareas\" ) def add_statisticalareas ( file : str , statisticalareas_path : str , verbose : bool = False ): \"\"\"Return `file` with statistical areas to stdout. Arguments: file: file path statisticalareas_path: satistical area files path (wildcard allowed) verbose: verbosity **Usage:** ```shell patentcity geo add.statisticalareas geoc_gbpatentxx.here.csv \"assets/statisticalareas_*.csv\" ``` \"\"\" statisticalareas_df = read_csv_many ( statisticalareas_path , verbose = verbose , dtype = str ) geoc_df = pd . read_csv ( file , dtype = str , error_bad_lines = False ) geoc_df = geoc_df . where ( pd . notnull ( geoc_df ), None ) # we replace pandas nan by None vars = [ \"country\" , \"state\" , \"county\" , \"city\" , \"postalCode\" ] geoc_df [ \"key\" ] = geoc_df [ vars ] . apply ( lambda x : get_statisticalarea_key ( x ), axis = 1 ) geoc_df = geoc_df . merge ( statisticalareas_df , how = \"left\" , on = [ \"country\" , \"key\" ]) typer . echo ( geoc_df . to_csv ( sys . stdout , index = False )) get_geoc_data_gmaps ( file , api_key , region , language = 'en' , max_workers = 5 , inDelim = '|' , skip_header = True ) \u00b6 Geocode addresses in file using GMAPS Parameters: Name Type Description Default file str file path required api_key str api key required region str region code, specified as a ccTLD (\u201ctop-level domain\u201d) two-character value (e.g. de, fr, uk, us, etc). required language str the language in which to return results 'en' max_workers int max number of workers 5 inDelim str inner delimiter '|' skip_header bool whether to ski header or not True Usage: patentcity geo gmaps.get loc_uspatentxx.txt $APIKEY us Info Quickstart Overview Language Source code in patentcity/geo.py 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 @app . command ( name = \"gmaps.get\" ) def get_geoc_data_gmaps ( file : str , api_key : str , region : str , language : str = \"en\" , max_workers : int = 5 , inDelim : str = \"|\" , skip_header : bool = True , ): \"\"\"Geocode addresses in `file` using GMAPS Arguments: file: file path api_key: api key region: region code, specified as a ccTLD (\u201ctop-level domain\u201d) two-character value (e.g. de, fr, uk, us, etc). language: the language in which to return results max_workers: max number of workers inDelim: inner delimiter skip_header: whether to ski header or not **Usage:** ```shell patentcity geo gmaps.get loc_uspatentxx.txt $APIKEY us ``` !!! info - [Quickstart](https://developers.google.com/maps/documentation/geocoding/start) - [Overview](https://developers.google.com/maps/documentation/geocoding/overview) - [Language](https://developers.google.com/maps/faq#languagesupport) \"\"\" gmaps = googlemaps . Client ( api_key ) with open ( file , \"r\" ) as lines : if skip_header : next ( lines ) with ThreadPoolExecutor ( max_workers ) as executor : executor . map ( _get_geoc_data_gmaps , lines , repeat ( gmaps ), repeat ( region ), repeat ( language ), repeat ( inDelim ), ) get_geoc_data_here ( request_id , api_key , output_dir = None , unzip = True ) \u00b6 Download and save HERE geocoded data to output_dir / request_id .zip Parameters: Name Type Description Default request_id str HERE job request ID (returned by `here.post) required api_key str HERE api key required output_dir str saving directory None unzip bool whether to unzip the output True Usage: patentcity geo here.get $REQUESTID $APIKEY --output-dir <your-dir> Info Read output Source code in patentcity/geo.py 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 @app . command ( name = \"here.get\" ) def get_geoc_data_here ( request_id : str , api_key : str , output_dir : str = None , unzip : bool = True ): \"\"\"Download and save HERE geocoded data to `output_dir`/`request_id`.zip Arguments: request_id: HERE job request ID (returned by `here.post) api_key: HERE api key output_dir: saving directory unzip: whether to unzip the output **Usage:** ```shell patentcity geo here.get $REQUESTID $APIKEY --output-dir <your-dir> ``` !!! info - [Read output](https://developer.here.com/documentation/batch-geocoder/dev_guide/topics/read-batch-request-output.html) \"\"\" def dump_data ( response , output_file ): with open ( output_file , \"wb\" ) as fout : fout . write ( response . content ) typer . secho ( f \" { ok }{ output_file } \" , fg = typer . colors . GREEN ) def unzip_data ( zip_file ): unzip_dir = os . path . splitext ( zip_file )[ 0 ] with ZipFile ( zip_file , \"r\" ) as zipObj : # Extract all the contents of zip file in different directory zipObj . extractall ( unzip_dir ) typer . secho ( f \" { ok }{ zip_file } unzipped\" , fg = typer . colors . GREEN ) output_file = os . path . join ( output_dir , f \" { request_id } .zip\" ) params = (( \"apiKey\" , api_key ),) response = requests . get ( f \"https://batch.geocoder.ls.hereapi.com/6.2/jobs/ { request_id } /result/\" , params = params , ) if response . status_code == 200 : dump_data ( response , output_file ) if unzip : unzip_data ( output_file ) else : typer . secho ( f \" { not_ok } Failed with status { response . status_code } \\n { response . content } \" , fg = typer . colors . RED , ) # return response get_geoc_status_here ( request_id , api_key , freq = 5 , verbose = False ) \u00b6 Check status of job request_id every freq seconds Parameters: Name Type Description Default request_id str HERE job request ID (returned by `here.post) required api_key str HERE api key required freq int interval between 2 consecutive status updates 5 verbose bool verbosity False Usage: patentcity geo here.status $REQUESTID $APIKEY Source code in patentcity/geo.py 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 @app . command ( name = \"here.status\" ) def get_geoc_status_here ( request_id : str , api_key : str , freq : int = 5 , verbose : bool = False ): \"\"\"Check status of job `request_id` every `freq` seconds Arguments: request_id: HERE job request ID (returned by `here.post) api_key: HERE api key freq: interval between 2 consecutive status updates verbose: verbosity **Usage:** ```shell patentcity geo here.status $REQUESTID $APIKEY ``` \"\"\" def summarize_status ( response , verbose ): soup = BeautifulSoup ( response . text , \"xml\" ) now = get_dt_human () Status = soup . Status . text TotalCount = soup . TotalCount . text ProcessedCount = soup . ProcessedCount . text PendingCount = soup . PendingCount . text ErrorCount = soup . ErrorCount . text SuccessCount = soup . SuccessCount . text typer . secho ( f \" { now } : { ProcessedCount } / { TotalCount } ( { PendingCount } pending)\" , fg = typer . colors . BLUE , ) if int ( SuccessCount ) > 0 : typer . secho ( f \" { ok }{ SuccessCount } addresses successfully geocoded\" , fg = typer . colors . GREEN , ) if int ( ErrorCount ) > 0 : typer . secho ( f \" { not_ok }{ ErrorCount } errors detected\" , fg = typer . colors . RED ) if verbose : typer . echo ( soup . prettify ()) return Status params = (( \"action\" , \"status\" ), ( \"apiKey\" , api_key )) completed = False while not completed : response = requests . get ( f \" { GEOC_URL } / { request_id } \" , params = params ) Status = summarize_status ( response , verbose ) if Status == \"completed\" : completed = True typer . secho ( f \" { ok }{ ok } Job completed\" , fg = typer . colors . GREEN ) else : typer . secho ( f \"Status: { Status } \" , fg = typer . colors . BLUE ) time . sleep ( freq ) get_parsed_loc_libpostal ( path , api_reference , max_workers = 10 , debug = False ) \u00b6 Send data in path to libpostal service (hosted at api_reference ) and return parsed loc json blobs to stdout. Parameters: Name Type Description Default path str data path (wildcard allowed) required api_reference str reference of service host \"ip:port\" required max_workers int max number of workers 10 debug bool verbosity degree False Usage: patentcity geo libpostal.get <your-addresses.txt> <ip:port> Source code in patentcity/geo.py 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 @app . command ( deprecated = True , name = \"libpostal.get\" ) def get_parsed_loc_libpostal ( path : str , api_reference : str , max_workers : int = 10 , debug : bool = False ): \"\"\"Send data in `path` to libpostal service (hosted at `api_reference`) and return parsed loc json blobs to stdout. Arguments: path: data path (wildcard allowed) api_reference: reference of service host \"ip:port\" max_workers: max number of workers debug: verbosity degree **Usage:** ```shell patentcity geo libpostal.get <your-addresses.txt> <ip:port> ``` \"\"\" files = glob ( path ) for file in files : data = open ( file , \"r\" ) with ThreadPoolExecutor ( max_workers = max_workers ) as executor : executor . map ( _parse_loc_blob , data , repeat ( api_reference ), repeat ( debug )) harmonize_geoc_data_gmaps ( file , inDelim = '|' , out_format = 'csv' , header = True ) \u00b6 Harmonize Gmaps response with HERE Geocoding API responses (csv) Parameters: Name Type Description Default file str file path required inDelim str inner delimiter '|' out_format str format of the output (in [\"csv\", \"jsonl\"]) 'csv' header bool whether to add a header (if out_format is \"csv\") True Usage: patentcity geo gmaps.harmonize geoc_uspatentxx.gmaps.jsonl Source code in patentcity/geo.py 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 @app . command ( name = \"gmaps.harmonize\" ) def harmonize_geoc_data_gmaps ( file : str , inDelim : str = \"|\" , out_format : str = \"csv\" , header : bool = True ): \"\"\"Harmonize Gmaps response with HERE Geocoding API responses (csv) Arguments: file: file path inDelim: inner delimiter out_format: format of the output (in [\"csv\", \"jsonl\"]) header: whether to add a header (if `out_format` is \"csv\") **Usage:** ```shell patentcity geo gmaps.harmonize geoc_uspatentxx.gmaps.jsonl ``` \"\"\" assert out_format in [ \"csv\" , \"jsonl\" ] iso_crossover = get_isocrossover () us_state_crossover = get_usstatecrossover () county_crossover = get_countycrossover () if out_format == \"csv\" and header : csvwriter = csv . DictWriter ( sys . stdout , GEOC_OUTCOLS ) csvwriter . writeheader () with open ( file , \"r\" ) as lines : for line in lines : line = clean_text ( line , inDelim = f \" { inDelim } \" ) # clean cases like \"Jack A. Claes Pavilion | Elk Grove Park District\" returned by Gmaps try : recid , response = line . split ( inDelim ) _parse_response_gmaps ( response , recid , out_format , iso_crossover , us_state_crossover , county_crossover , ) except ValueError : pass # occurs when there is still an inDelim in the result # (e.g. \"long_name\": \"S2|02 Robert-Piloty-Geb\\u00e4ude\") post_geoc_data_here ( file , api_key , countryfocus , outCols = None , inDelim = '|' , outDelim = ',' , locationattributes = 'addressDetails' , language = 'en-EN' , includeinputfields = False , verbose = False ) \u00b6 Post file to HERE batch geocoding API Parameters: Name Type Description Default file str file path. File is expected to be formatted as follows recId|searchText required api_key str HERE api key required countryfocus str iso3 country code (e.g. deu, fra, gbr, usa, etc), see Format input required outCols str see Request parameters None inDelim str see Request parameters '|' outDelim str see Request parameters ',' locationattributes str see Request parameters 'addressDetails' language str output language, see Request parameters 'en-EN' includeinputfields bool see Request parameters False verbose bool verbosity False Usage: patentcity geo here.post loc_uspatentxx.txt $APIKEY usa Info Format input Request parameters Source code in patentcity/geo.py 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 @app . command ( name = \"here.post\" ) def post_geoc_data_here ( file : str , api_key : str , countryfocus : str , # ISO3? outCols : str = None , inDelim : str = \"|\" , outDelim : str = \",\" , locationattributes : str = \"addressDetails\" , language : str = \"en-EN\" , # eg \"en-EN\", \"en-US\" includeinputfields : bool = False , # False for downstream compatibility verbose : bool = False , ): \"\"\"Post `file` to HERE batch geocoding API Arguments: file: file path. File is expected to be formatted as follows recId|searchText api_key: HERE api key countryfocus: iso3 country code (e.g. deu, fra, gbr, usa, etc), see [Format input](https://developer.here.com/documentation/batch-geocoder/dev_guide/topics/data-input.html) outCols: see [Request parameters](https://developer.here.com/documentation/batch-geocoder/dev_guide/topics/request-parameters.html) inDelim: see [Request parameters](https://developer.here.com/documentation/batch-geocoder/dev_guide/topics/request-parameters.html) outDelim: see [Request parameters](https://developer.here.com/documentation/batch-geocoder/dev_guide/topics/request-parameters.html) locationattributes: see [Request parameters](https://developer.here.com/documentation/batch-geocoder/dev_guide/topics/request-parameters.html) language: output language, see [Request parameters](https://developer.here.com/documentation/batch-geocoder/dev_guide/topics/request-parameters.html) includeinputfields: see [Request parameters](https://developer.here.com/documentation/batch-geocoder/dev_guide/topics/request-parameters.html) verbose: verbosity **Usage:** ```shell patentcity geo here.post loc_uspatentxx.txt $APIKEY usa ``` !!! info - [Format input](https://developer.here.com/documentation/batch-geocoder/dev_guide/topics/data-input.html) - [Request parameters](https://developer.here.com/documentation/batch-geocoder/dev_guide/topics/request-parameters.html) \"\"\" def check_post ( response ): soup = BeautifulSoup ( response . text , features = \"xml\" ) RequestId = soup . RequestId . text Status = soup . Status . text log_msg = f \" { file } \\t { Status } \\t { RequestId } \\t { get_dt_human () } \" if verbose : typer . echo ( soup . prettify ()) if Status == \"accepted\" : typer . secho ( f \" { ok }{ log_msg } \" , fg = typer . colors . GREEN ) else : typer . secho ( f \" { not_ok } \\t { log_msg } \" , fg = typer . colors . RED ) headers = { \"Content-Type\" : \"text/plain\" } outCols = outCols . split ( \",\" ) if outCols else GEOC_OUTCOLS # Remove default columns to avoid duplicated columns for col in [ \"recID\" , \"seqNumber\" , \"seqLength\" ]: try : outCols . remove ( col ) except ValueError : pass params = ( ( \"apiKey\" , api_key ), ( \"action\" , \"run\" ), ( \"header\" , \"true\" ), ( \"inDelim\" , inDelim ), ( \"outDelim\" , outDelim ), ( \"outCols\" , \",\" . join ( outCols )), ( \"outputcombined\" , \"true\" ), ( \"countryfocus\" , countryfocus ), ( \"language\" , language ), ( \"locationattributes\" , locationattributes ), ( \"includeinputfields\" , includeinputfields ), ) data = open ( file , \"rb\" ) . read () response = requests . post ( GEOC_URL , headers = headers , params = params , data = data ) if response . status_code == 200 : check_post ( response ) else : typer . secho ( f \" { not_ok } Failed with status { response . status_code } \\n { response . content } \" , fg = typer . colors . RED , ) prep_geoc_data ( file , inDelim = '|' ) \u00b6 Return patentees' loc data formatted for geocoding to stdout (recId|searchText). Parameters: Name Type Description Default file str file path required inDelim str inner delimiter used by HERE '|' Usage: patentcity geo prep entrel_uspatent01.jsonl #Sort and deduplicate addresses before batch geocoding sort -u loc_uspatent01.txt Source code in patentcity/geo.py 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 @app . command ( name = \"prep\" ) def prep_geoc_data ( file : str , inDelim : str = \"|\" ): \"\"\"Return patentees' loc data formatted for geocoding to stdout (recId|searchText). Arguments: file: file path inDelim: inner delimiter used by HERE **Usage:** ```shell patentcity geo prep entrel_uspatent01.jsonl #Sort and deduplicate addresses before batch geocoding sort -u loc_uspatent01.txt ``` \"\"\" with open ( file , \"r\" ) as lines : typer . echo ( f \"recId { inDelim } searchText\" ) # This is the required header for line in lines : line = json . loads ( line ) patentees = line . get ( \"patentee\" ) for patentee in patentees : loc_recid = patentee . get ( \"loc_recId\" ) loc_text = patentee . get ( \"loc_text\" ) if loc_recid and loc_text : typer . echo ( f \" { loc_recid }{ inDelim }{ loc_text } \" )","title":"geo"},{"location":"API_GEO/#patentcity.geo.add_geoc_data","text":"Add geoc data from geoc_file to file Parameters: Name Type Description Default file str file path required geoc_file str geoc file path (geocoding output, csv) required source str geocoding service (in [\"HERE\", \"GMAPS\", \"MANUAL\"]) None max_workers int max number of workers 5 verbose bool verbosity False Usage: patentcity geo add entrel_uspatentxx.jsonl geoc_uspatentxx.here.csv --source HERE Source code in patentcity/geo.py 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 @app . command ( name = \"add\" ) def add_geoc_data ( file : str , geoc_file : str , source : str = None , max_workers : int = 5 , verbose : bool = False , ): \"\"\"Add geoc data from `geoc_file`to `file` Arguments: file: file path geoc_file: geoc file path (geocoding output, csv) source: geocoding service (in [\"HERE\", \"GMAPS\", \"MANUAL\"]) max_workers: max number of workers verbose: verbosity **Usage:** ```shell patentcity geo add entrel_uspatentxx.jsonl geoc_uspatentxx.here.csv --source HERE ``` \"\"\" assert source in [ \"GMAPS\" , \"HERE\" , \"MANUAL\" ] index = _get_geoc_index ( geoc_file , dump = False ) blobs = open ( file , \"r\" ) with ThreadPoolExecutor ( max_workers = max_workers ) as executor : executor . map ( _update_loc , blobs , repeat ( source ), repeat ( index ), repeat ( verbose ))","title":"add_geoc_data()"},{"location":"API_GEO/#patentcity.geo.add_geoc_disamb","text":"Return a list of recId|geoc(target) from a list of recid|target. Parameters: Name Type Description Default disamb_file str disambiguation data file path required index_geoc_file str index geocoding file path required flavor str flavor of index_geoc_file (in [\"HERE\",\"GMAPS\"]) 'GMAPS' inDelim str inner delimiter '|' Usage: patentcity geo add.disamb ${ DISAMBFILE } ${ GEOCINDEX } --flavor ${ FLAVOR } Info Use before patentcity geo add Source code in patentcity/geo.py 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 @app . command ( name = \"add.disamb\" ) def add_geoc_disamb ( disamb_file : str , index_geoc_file : str , flavor : str = \"GMAPS\" , inDelim : str = \"|\" ): \"\"\"Return a list of recId|geoc(target) from a list of recid|target. Arguments: disamb_file: disambiguation data file path index_geoc_file: index geocoding file path flavor: flavor of `index_geoc_file` (in [\"HERE\",\"GMAPS\"]) inDelim: inner delimiter **Usage:** ```shell patentcity geo add.disamb ${DISAMBFILE} ${GEOCINDEX} --flavor ${FLAVOR} ``` !!! info Use before `patentcity geo add` \"\"\" assert flavor in [ \"GMAPS\" , \"HERE\" ] if flavor == \"GMAPS\" : index = {} with open ( index_geoc_file , \"r\" ) as lines : for line in lines : recid , geoc = line . split ( inDelim ) index . update ({ recid : json . loads ( geoc )}) with open ( disamb_file , \"r\" ) as lines : for line in lines : recid , disamb_loc = line . split ( inDelim ) disamb_loc_recid = get_recid ( clean_text ( disamb_loc )) typer . echo ( f \" { recid }{ inDelim }{ json . dumps ( index . get ( disamb_loc_recid )) } \" ) else : index = _get_geoc_index ( index_geoc_file , dump = False ) fieldnames = GEOC_OUTCOLS writer = csv . DictWriter ( sys . stdout , fieldnames = fieldnames ) writer . writeheader () with open ( disamb_file , \"r\" ) as lines : for line in lines : recid , searchtext = line . replace ( \" \\n \" , \"\" ) . split ( inDelim ) geoc_disamb = index . get ( get_recid ( searchtext )) geoc_disamb . update ({ \"recId\" : recid }) writer . writerow ( geoc_disamb )","title":"add_geoc_disamb()"},{"location":"API_GEO/#patentcity.geo.add_statisticalareas","text":"Return file with statistical areas to stdout. Parameters: Name Type Description Default file str file path required statisticalareas_path str satistical area files path (wildcard allowed) required verbose bool verbosity False Usage: patentcity geo add.statisticalareas geoc_gbpatentxx.here.csv \"assets/statisticalareas_*.csv\" Source code in patentcity/geo.py 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 @app . command ( name = \"add.statisticalareas\" ) def add_statisticalareas ( file : str , statisticalareas_path : str , verbose : bool = False ): \"\"\"Return `file` with statistical areas to stdout. Arguments: file: file path statisticalareas_path: satistical area files path (wildcard allowed) verbose: verbosity **Usage:** ```shell patentcity geo add.statisticalareas geoc_gbpatentxx.here.csv \"assets/statisticalareas_*.csv\" ``` \"\"\" statisticalareas_df = read_csv_many ( statisticalareas_path , verbose = verbose , dtype = str ) geoc_df = pd . read_csv ( file , dtype = str , error_bad_lines = False ) geoc_df = geoc_df . where ( pd . notnull ( geoc_df ), None ) # we replace pandas nan by None vars = [ \"country\" , \"state\" , \"county\" , \"city\" , \"postalCode\" ] geoc_df [ \"key\" ] = geoc_df [ vars ] . apply ( lambda x : get_statisticalarea_key ( x ), axis = 1 ) geoc_df = geoc_df . merge ( statisticalareas_df , how = \"left\" , on = [ \"country\" , \"key\" ]) typer . echo ( geoc_df . to_csv ( sys . stdout , index = False ))","title":"add_statisticalareas()"},{"location":"API_GEO/#patentcity.geo.get_geoc_data_gmaps","text":"Geocode addresses in file using GMAPS Parameters: Name Type Description Default file str file path required api_key str api key required region str region code, specified as a ccTLD (\u201ctop-level domain\u201d) two-character value (e.g. de, fr, uk, us, etc). required language str the language in which to return results 'en' max_workers int max number of workers 5 inDelim str inner delimiter '|' skip_header bool whether to ski header or not True Usage: patentcity geo gmaps.get loc_uspatentxx.txt $APIKEY us Info Quickstart Overview Language Source code in patentcity/geo.py 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 @app . command ( name = \"gmaps.get\" ) def get_geoc_data_gmaps ( file : str , api_key : str , region : str , language : str = \"en\" , max_workers : int = 5 , inDelim : str = \"|\" , skip_header : bool = True , ): \"\"\"Geocode addresses in `file` using GMAPS Arguments: file: file path api_key: api key region: region code, specified as a ccTLD (\u201ctop-level domain\u201d) two-character value (e.g. de, fr, uk, us, etc). language: the language in which to return results max_workers: max number of workers inDelim: inner delimiter skip_header: whether to ski header or not **Usage:** ```shell patentcity geo gmaps.get loc_uspatentxx.txt $APIKEY us ``` !!! info - [Quickstart](https://developers.google.com/maps/documentation/geocoding/start) - [Overview](https://developers.google.com/maps/documentation/geocoding/overview) - [Language](https://developers.google.com/maps/faq#languagesupport) \"\"\" gmaps = googlemaps . Client ( api_key ) with open ( file , \"r\" ) as lines : if skip_header : next ( lines ) with ThreadPoolExecutor ( max_workers ) as executor : executor . map ( _get_geoc_data_gmaps , lines , repeat ( gmaps ), repeat ( region ), repeat ( language ), repeat ( inDelim ), )","title":"get_geoc_data_gmaps()"},{"location":"API_GEO/#patentcity.geo.get_geoc_data_here","text":"Download and save HERE geocoded data to output_dir / request_id .zip Parameters: Name Type Description Default request_id str HERE job request ID (returned by `here.post) required api_key str HERE api key required output_dir str saving directory None unzip bool whether to unzip the output True Usage: patentcity geo here.get $REQUESTID $APIKEY --output-dir <your-dir> Info Read output Source code in patentcity/geo.py 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 @app . command ( name = \"here.get\" ) def get_geoc_data_here ( request_id : str , api_key : str , output_dir : str = None , unzip : bool = True ): \"\"\"Download and save HERE geocoded data to `output_dir`/`request_id`.zip Arguments: request_id: HERE job request ID (returned by `here.post) api_key: HERE api key output_dir: saving directory unzip: whether to unzip the output **Usage:** ```shell patentcity geo here.get $REQUESTID $APIKEY --output-dir <your-dir> ``` !!! info - [Read output](https://developer.here.com/documentation/batch-geocoder/dev_guide/topics/read-batch-request-output.html) \"\"\" def dump_data ( response , output_file ): with open ( output_file , \"wb\" ) as fout : fout . write ( response . content ) typer . secho ( f \" { ok }{ output_file } \" , fg = typer . colors . GREEN ) def unzip_data ( zip_file ): unzip_dir = os . path . splitext ( zip_file )[ 0 ] with ZipFile ( zip_file , \"r\" ) as zipObj : # Extract all the contents of zip file in different directory zipObj . extractall ( unzip_dir ) typer . secho ( f \" { ok }{ zip_file } unzipped\" , fg = typer . colors . GREEN ) output_file = os . path . join ( output_dir , f \" { request_id } .zip\" ) params = (( \"apiKey\" , api_key ),) response = requests . get ( f \"https://batch.geocoder.ls.hereapi.com/6.2/jobs/ { request_id } /result/\" , params = params , ) if response . status_code == 200 : dump_data ( response , output_file ) if unzip : unzip_data ( output_file ) else : typer . secho ( f \" { not_ok } Failed with status { response . status_code } \\n { response . content } \" , fg = typer . colors . RED , ) # return response","title":"get_geoc_data_here()"},{"location":"API_GEO/#patentcity.geo.get_geoc_status_here","text":"Check status of job request_id every freq seconds Parameters: Name Type Description Default request_id str HERE job request ID (returned by `here.post) required api_key str HERE api key required freq int interval between 2 consecutive status updates 5 verbose bool verbosity False Usage: patentcity geo here.status $REQUESTID $APIKEY Source code in patentcity/geo.py 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 @app . command ( name = \"here.status\" ) def get_geoc_status_here ( request_id : str , api_key : str , freq : int = 5 , verbose : bool = False ): \"\"\"Check status of job `request_id` every `freq` seconds Arguments: request_id: HERE job request ID (returned by `here.post) api_key: HERE api key freq: interval between 2 consecutive status updates verbose: verbosity **Usage:** ```shell patentcity geo here.status $REQUESTID $APIKEY ``` \"\"\" def summarize_status ( response , verbose ): soup = BeautifulSoup ( response . text , \"xml\" ) now = get_dt_human () Status = soup . Status . text TotalCount = soup . TotalCount . text ProcessedCount = soup . ProcessedCount . text PendingCount = soup . PendingCount . text ErrorCount = soup . ErrorCount . text SuccessCount = soup . SuccessCount . text typer . secho ( f \" { now } : { ProcessedCount } / { TotalCount } ( { PendingCount } pending)\" , fg = typer . colors . BLUE , ) if int ( SuccessCount ) > 0 : typer . secho ( f \" { ok }{ SuccessCount } addresses successfully geocoded\" , fg = typer . colors . GREEN , ) if int ( ErrorCount ) > 0 : typer . secho ( f \" { not_ok }{ ErrorCount } errors detected\" , fg = typer . colors . RED ) if verbose : typer . echo ( soup . prettify ()) return Status params = (( \"action\" , \"status\" ), ( \"apiKey\" , api_key )) completed = False while not completed : response = requests . get ( f \" { GEOC_URL } / { request_id } \" , params = params ) Status = summarize_status ( response , verbose ) if Status == \"completed\" : completed = True typer . secho ( f \" { ok }{ ok } Job completed\" , fg = typer . colors . GREEN ) else : typer . secho ( f \"Status: { Status } \" , fg = typer . colors . BLUE ) time . sleep ( freq )","title":"get_geoc_status_here()"},{"location":"API_GEO/#patentcity.geo.get_parsed_loc_libpostal","text":"Send data in path to libpostal service (hosted at api_reference ) and return parsed loc json blobs to stdout. Parameters: Name Type Description Default path str data path (wildcard allowed) required api_reference str reference of service host \"ip:port\" required max_workers int max number of workers 10 debug bool verbosity degree False Usage: patentcity geo libpostal.get <your-addresses.txt> <ip:port> Source code in patentcity/geo.py 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 @app . command ( deprecated = True , name = \"libpostal.get\" ) def get_parsed_loc_libpostal ( path : str , api_reference : str , max_workers : int = 10 , debug : bool = False ): \"\"\"Send data in `path` to libpostal service (hosted at `api_reference`) and return parsed loc json blobs to stdout. Arguments: path: data path (wildcard allowed) api_reference: reference of service host \"ip:port\" max_workers: max number of workers debug: verbosity degree **Usage:** ```shell patentcity geo libpostal.get <your-addresses.txt> <ip:port> ``` \"\"\" files = glob ( path ) for file in files : data = open ( file , \"r\" ) with ThreadPoolExecutor ( max_workers = max_workers ) as executor : executor . map ( _parse_loc_blob , data , repeat ( api_reference ), repeat ( debug ))","title":"get_parsed_loc_libpostal()"},{"location":"API_GEO/#patentcity.geo.harmonize_geoc_data_gmaps","text":"Harmonize Gmaps response with HERE Geocoding API responses (csv) Parameters: Name Type Description Default file str file path required inDelim str inner delimiter '|' out_format str format of the output (in [\"csv\", \"jsonl\"]) 'csv' header bool whether to add a header (if out_format is \"csv\") True Usage: patentcity geo gmaps.harmonize geoc_uspatentxx.gmaps.jsonl Source code in patentcity/geo.py 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 @app . command ( name = \"gmaps.harmonize\" ) def harmonize_geoc_data_gmaps ( file : str , inDelim : str = \"|\" , out_format : str = \"csv\" , header : bool = True ): \"\"\"Harmonize Gmaps response with HERE Geocoding API responses (csv) Arguments: file: file path inDelim: inner delimiter out_format: format of the output (in [\"csv\", \"jsonl\"]) header: whether to add a header (if `out_format` is \"csv\") **Usage:** ```shell patentcity geo gmaps.harmonize geoc_uspatentxx.gmaps.jsonl ``` \"\"\" assert out_format in [ \"csv\" , \"jsonl\" ] iso_crossover = get_isocrossover () us_state_crossover = get_usstatecrossover () county_crossover = get_countycrossover () if out_format == \"csv\" and header : csvwriter = csv . DictWriter ( sys . stdout , GEOC_OUTCOLS ) csvwriter . writeheader () with open ( file , \"r\" ) as lines : for line in lines : line = clean_text ( line , inDelim = f \" { inDelim } \" ) # clean cases like \"Jack A. Claes Pavilion | Elk Grove Park District\" returned by Gmaps try : recid , response = line . split ( inDelim ) _parse_response_gmaps ( response , recid , out_format , iso_crossover , us_state_crossover , county_crossover , ) except ValueError : pass # occurs when there is still an inDelim in the result # (e.g. \"long_name\": \"S2|02 Robert-Piloty-Geb\\u00e4ude\")","title":"harmonize_geoc_data_gmaps()"},{"location":"API_GEO/#patentcity.geo.post_geoc_data_here","text":"Post file to HERE batch geocoding API Parameters: Name Type Description Default file str file path. File is expected to be formatted as follows recId|searchText required api_key str HERE api key required countryfocus str iso3 country code (e.g. deu, fra, gbr, usa, etc), see Format input required outCols str see Request parameters None inDelim str see Request parameters '|' outDelim str see Request parameters ',' locationattributes str see Request parameters 'addressDetails' language str output language, see Request parameters 'en-EN' includeinputfields bool see Request parameters False verbose bool verbosity False Usage: patentcity geo here.post loc_uspatentxx.txt $APIKEY usa Info Format input Request parameters Source code in patentcity/geo.py 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 @app . command ( name = \"here.post\" ) def post_geoc_data_here ( file : str , api_key : str , countryfocus : str , # ISO3? outCols : str = None , inDelim : str = \"|\" , outDelim : str = \",\" , locationattributes : str = \"addressDetails\" , language : str = \"en-EN\" , # eg \"en-EN\", \"en-US\" includeinputfields : bool = False , # False for downstream compatibility verbose : bool = False , ): \"\"\"Post `file` to HERE batch geocoding API Arguments: file: file path. File is expected to be formatted as follows recId|searchText api_key: HERE api key countryfocus: iso3 country code (e.g. deu, fra, gbr, usa, etc), see [Format input](https://developer.here.com/documentation/batch-geocoder/dev_guide/topics/data-input.html) outCols: see [Request parameters](https://developer.here.com/documentation/batch-geocoder/dev_guide/topics/request-parameters.html) inDelim: see [Request parameters](https://developer.here.com/documentation/batch-geocoder/dev_guide/topics/request-parameters.html) outDelim: see [Request parameters](https://developer.here.com/documentation/batch-geocoder/dev_guide/topics/request-parameters.html) locationattributes: see [Request parameters](https://developer.here.com/documentation/batch-geocoder/dev_guide/topics/request-parameters.html) language: output language, see [Request parameters](https://developer.here.com/documentation/batch-geocoder/dev_guide/topics/request-parameters.html) includeinputfields: see [Request parameters](https://developer.here.com/documentation/batch-geocoder/dev_guide/topics/request-parameters.html) verbose: verbosity **Usage:** ```shell patentcity geo here.post loc_uspatentxx.txt $APIKEY usa ``` !!! info - [Format input](https://developer.here.com/documentation/batch-geocoder/dev_guide/topics/data-input.html) - [Request parameters](https://developer.here.com/documentation/batch-geocoder/dev_guide/topics/request-parameters.html) \"\"\" def check_post ( response ): soup = BeautifulSoup ( response . text , features = \"xml\" ) RequestId = soup . RequestId . text Status = soup . Status . text log_msg = f \" { file } \\t { Status } \\t { RequestId } \\t { get_dt_human () } \" if verbose : typer . echo ( soup . prettify ()) if Status == \"accepted\" : typer . secho ( f \" { ok }{ log_msg } \" , fg = typer . colors . GREEN ) else : typer . secho ( f \" { not_ok } \\t { log_msg } \" , fg = typer . colors . RED ) headers = { \"Content-Type\" : \"text/plain\" } outCols = outCols . split ( \",\" ) if outCols else GEOC_OUTCOLS # Remove default columns to avoid duplicated columns for col in [ \"recID\" , \"seqNumber\" , \"seqLength\" ]: try : outCols . remove ( col ) except ValueError : pass params = ( ( \"apiKey\" , api_key ), ( \"action\" , \"run\" ), ( \"header\" , \"true\" ), ( \"inDelim\" , inDelim ), ( \"outDelim\" , outDelim ), ( \"outCols\" , \",\" . join ( outCols )), ( \"outputcombined\" , \"true\" ), ( \"countryfocus\" , countryfocus ), ( \"language\" , language ), ( \"locationattributes\" , locationattributes ), ( \"includeinputfields\" , includeinputfields ), ) data = open ( file , \"rb\" ) . read () response = requests . post ( GEOC_URL , headers = headers , params = params , data = data ) if response . status_code == 200 : check_post ( response ) else : typer . secho ( f \" { not_ok } Failed with status { response . status_code } \\n { response . content } \" , fg = typer . colors . RED , )","title":"post_geoc_data_here()"},{"location":"API_GEO/#patentcity.geo.prep_geoc_data","text":"Return patentees' loc data formatted for geocoding to stdout (recId|searchText). Parameters: Name Type Description Default file str file path required inDelim str inner delimiter used by HERE '|' Usage: patentcity geo prep entrel_uspatent01.jsonl #Sort and deduplicate addresses before batch geocoding sort -u loc_uspatent01.txt Source code in patentcity/geo.py 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 @app . command ( name = \"prep\" ) def prep_geoc_data ( file : str , inDelim : str = \"|\" ): \"\"\"Return patentees' loc data formatted for geocoding to stdout (recId|searchText). Arguments: file: file path inDelim: inner delimiter used by HERE **Usage:** ```shell patentcity geo prep entrel_uspatent01.jsonl #Sort and deduplicate addresses before batch geocoding sort -u loc_uspatent01.txt ``` \"\"\" with open ( file , \"r\" ) as lines : typer . echo ( f \"recId { inDelim } searchText\" ) # This is the required header for line in lines : line = json . loads ( line ) patentees = line . get ( \"patentee\" ) for patentee in patentees : loc_recid = patentee . get ( \"loc_recId\" ) loc_text = patentee . get ( \"loc_text\" ) if loc_recid and loc_text : typer . echo ( f \" { loc_recid }{ inDelim }{ loc_text } \" )","title":"prep_geoc_data()"},{"location":"API_IO/","text":"augment_patentcity ( src_table , destination_table , credentials = None ) \u00b6 Add (mainly interoperability) variables to src_table and save to `destination_table Parameters: Name Type Description Default src_table str source table (project.dataset.table) required destination_table str destination table (project.dataset.table) required credentials str BQ credentials file path None Usage: patentcity io augment-patentcity <src_table> <destination_table> credentials-patentcity.json Source code in patentcity/io.py 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 @app . command () def augment_patentcity ( src_table : str , destination_table : str , credentials : str = None ): \"\"\"Add (mainly interoperability) variables to `src_table` and save to `destination_table Arguments: src_table: source table (project.dataset.table) destination_table: destination table (project.dataset.table) credentials: BQ credentials file path **Usage:** ```shell patentcity io augment-patentcity <src_table> <destination_table> credentials-patentcity.json ``` \"\"\" query = f \"\"\" SELECT pc.publication_number, p.publication_date, p.family_id, SPLIT(pc.publication_number, \"-\")[OFFSET(0)] AS country_code, SPLIT(pc.publication_number, \"-\")[OFFSET(1)] AS pubnum, SPLIT(pc.publication_number, \"-\")[OFFSET(2)] AS kind_code, pc.* EXCEPT(publication_number) FROM `patents-public-data.patents.publications` AS p RIGHT JOIN ` { src_table } ` AS pc ON pc.publication_number = p.publication_number \"\"\" _get_job_done ( query , destination_table , credentials ) build_wgp_as_patentcity ( addresses_table , patentee_location_table , patstat_patent_properties_table = None , tls206_table = None , tls207_table = None , destination_table = None , flavor = None , credentials = None ) \u00b6 Join addresses and individuals from WGP and add data at the patent as well as individual level. Parameters: Name Type Description Default addresses_table str WGP addresses table (project.dataset.table) required patentee_location_table str WGP patentees table (project.dataset.table) required patstat_patent_properties_table str PATSTAT patent properties table on BQ (project.dataset.table) None tls206_table str PATSTAT tls206 table on BQ (project.dataset.table) None tls207_table str PATSTAT tls207 table on BQ (project.dataset.table) None destination_table str destination table (project.dataset.table) None flavor int WGP source data flavor (in [25, 45]) None credentials str BQ credentials file path None Usage: patentcity io build-wgp-as-patentcity patentcity.external.addresses_florian45_patentcity patentcity.external.person_location_id --tls206-table patentcity.external.tls206 --tls207-table patentcity.external.tls207 --patstat-patent-properties-table patentcity.external.patstat_patent_properties --destination-table patentcity.tmp.patentcity45 --flavor 45 --key-file $KEY_FILE Source code in patentcity/io.py 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 @app . command () def build_wgp_as_patentcity ( addresses_table : str , patentee_location_table : str , patstat_patent_properties_table : str = None , tls206_table : str = None , tls207_table : str = None , destination_table : str = None , flavor : int = None , credentials : str = None , ): \"\"\"Join addresses and individuals from WGP and add data at the patent as well as individual level. Arguments: addresses_table: WGP addresses table (project.dataset.table) patentee_location_table: WGP patentees table (project.dataset.table) patstat_patent_properties_table: PATSTAT patent properties table on BQ (project.dataset.table) tls206_table: PATSTAT tls206 table on BQ (project.dataset.table) tls207_table: PATSTAT tls207 table on BQ (project.dataset.table) destination_table: destination table (project.dataset.table) flavor: WGP source data flavor (in [25, 45]) credentials: BQ credentials file path **Usage:** ```shell patentcity io build-wgp-as-patentcity patentcity.external.addresses_florian45_patentcity patentcity.external.person_location_id --tls206-table patentcity.external.tls206 --tls207-table patentcity.external.tls207 --patstat-patent-properties-table patentcity.external.patstat_patent_properties --destination-table patentcity.tmp.patentcity45 --flavor 45 --key-file $KEY_FILE ``` \"\"\" assert flavor in [ 25 , 45 ] assert patentee_location_table assert addresses_table if flavor == 25 : query = f \"\"\" WITH tmp AS ( SELECT patee.* EXCEPT(recId), loc.*, app_inv=\"INV\" AS is_inv, app_inv=\"APP\" AS is_app FROM ( SELECT * FROM ` { addresses_table } ` # patentcity.external.addresses_cyril25_patentcity WHERE seqNumber = 1 AND (matchLevel=\"NOMATCH\" AND source=\"HERE\") IS FALSE ) AS loc JOIN ` { patentee_location_table } ` AS patee # patentcity.external.inventor_applicant_recid ON loc.recId = patee.recId ) # location_id SELECT tmp.* EXCEPT(appln_id, pat_publn_id), patstat.*, SPLIT(patstat.publication_number, \"-\")[OFFSET(0)] AS country_code, SPLIT(patstat.publication_number, \"-\")[OFFSET(1)] AS pubnum, SPLIT(patstat.publication_number, \"-\")[OFFSET(2)] AS kind_code FROM tmp LEFT JOIN ` { patstat_patent_properties_table } ` AS patstat ON tmp.pat_publn_id = patstat.pat_publn_id #tmp.appln_id = patstat.appln_id # here we are at the publication level, not the patent level WHERE SPLIT(patstat.publication_number, \"-\")[OFFSET(0)] IN (\"DE\", \"GB\", \"FR\", \"US\") \"\"\" if flavor == 45 : assert tls206_table assert tls207_table query = f \"\"\" WITH tmp AS ( WITH tmp_ AS ( WITH person AS ( SELECT tls207.*, tls206.person_name, invt_seq_nr > 0 AS is_inv, applt_seq_nr > 0 AS is_asg FROM ` { tls206_table } ` AS tls206, # usptobias.patstat.tls206 ` { tls207_table } ` AS tls207 # usptobias.patstat.tls207 WHERE tls207.person_id=tls206.person_id ) SELECT patee.*, person.* EXCEPT(person_id) FROM ` { patentee_location_table } ` AS patee # patentcity.external.person_location_id LEFT JOIN person ON patee.person_id = person.person_id) SELECT * FROM tmp_ LEFT JOIN ` { addresses_table } ` AS loc # patentcity.external.addresses_florian45_patentcity ON tmp_.location_id = loc.recId WHERE seqNumber = 1 ) SELECT tmp.* EXCEPT(appln_id), patstat.*, SPLIT(patstat.publication_number, \"-\")[OFFSET(0)] AS country_code, SPLIT(patstat.publication_number, \"-\")[OFFSET(1)] AS pubnum, SPLIT(patstat.publication_number, \"-\")[OFFSET(2)] AS kind_code FROM tmp LEFT JOIN ` { patstat_patent_properties_table } ` AS patstat ON tmp.appln_id = patstat.appln_id # here we are at the the patent level WHERE SPLIT(patstat.publication_number, \"-\")[OFFSET(0)] IN (\"DE\", \"GB\", \"FR\", \"US\") \"\"\" _get_job_done ( query , destination_table , credentials ) deduplicate ( src_table , destination_table , credentials ) \u00b6 Deduplicate patentcity table from publications which are both in at least 2 of the following data sources PC, WGP45 and WGP25. We prioritize PC, then WGP45 and then WGP25. Argument src_table: source table (project.dataset.table) destination_table: destination table (project.dataset.table) credentials: BQ credentials file path Usage: patentcity io deduplicate <src-table> <destination-table> credentials-patentcity.json Source code in patentcity/io.py 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 @app . command () def deduplicate ( src_table : str , destination_table : str , credentials : str ): \"\"\" Deduplicate patentcity table from publications which are both in at least 2 of the following data sources PC, WGP45 and WGP25. We prioritize PC, then WGP45 and then WGP25. Argument: src_table: source table (project.dataset.table) destination_table: destination table (project.dataset.table) credentials: BQ credentials file path **Usage:** ```shell patentcity io deduplicate <src-table> <destination-table> credentials-patentcity.json ``` \"\"\" query = f \"\"\" WITH duplicates AS ( SELECT publication_number, COUNT(publication_number) AS nb_occ, STRING_AGG(DISTINCT(origin)) AS origins FROM { src_table } #`patentcity.tmp.v100rc5` GROUP BY publication_number), keep_list AS ( SELECT tmp.publication_number, tmp.origin, duplicates.* EXCEPT(publication_number), CASE WHEN nb_occ = 1 THEN TRUE WHEN nb_occ > 1 AND origins LIKE \"%PC%\" AND origin=\"PC\" THEN TRUE WHEN nb_occ > 1 AND origins LIKE \"%WGP45%\" AND origins NOT LIKE \"%PC%\" AND origin=\"WGP45\" THEN TRUE WHEN nb_occ > 1 AND origins LIKE \"%WGP25%\" AND origins NOT LIKE \"%PC%\" AND origins NOT LIKE \"%WGP45%\" AND origin=\"WGP25\" THEN TRUE ELSE FALSE END AS keep FROM { src_table } AS tmp # `patentcity.tmp.v100rc5` LEFT JOIN duplicates ON tmp.publication_number = duplicates.publication_number ) SELECT tmp.*#, #keep_list.* EXCEPT(publication_number, origin) ## for dbg FROM { src_table } AS tmp # `patentcity.tmp.v100rc5` LEFT JOIN keep_list ON tmp.publication_number=keep_list.publication_number AND tmp.origin=keep_list.origin WHERE keep IS TRUE \"\"\" _get_job_done ( query , destination_table , credentials ) extract_sample_kepler ( src_table , dest_file , sample_ratio = 0.1 , office = None , credentials = None ) \u00b6 Extract sample for kepler.gl Parameters: Name Type Description Default src_table str source table (project.dataset.table) required dest_file str destination file path (local) required sample_ratio float share of patents to extract 0.1 office str patent office two letter-code (e.g. DD, DE, FR, etc) None credentials str BQ credentials file path None Usage: patentcity io extract-sample-kepler <src_table> <dest_file> --office DE --credentials credentials-patentcity.json Source code in patentcity/io.py 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 @app . command () def extract_sample_kepler ( src_table : str , dest_file : str , sample_ratio : float = 0.1 , office : str = None , credentials : str = None , ): \"\"\"Extract sample for kepler.gl Arguments: src_table: source table (project.dataset.table) dest_file: destination file path (local) sample_ratio: share of patents to extract office: patent office two letter-code (e.g. DD, DE, FR, etc) credentials: BQ credentials file path **Usage:** ```shell patentcity io extract-sample-kepler <src_table> <dest_file> --office DE --credentials credentials-patentcity.json ``` \"\"\" office_clause = f \"\"\"AND country_code=\" { office } \" \"\"\" if office else \"\" query = f \"\"\" SELECT publication_number, country_code, CAST(publication_date/10000 AS INT64) AS publication_year, PARSE_TIMESTAMP('%Y%m%d%H%M%S', CAST(publication_date*100000 AS STRING)) as publication_date, patentee.loc_country as country, patentee.loc_city as city, patentee.loc_latitude as point_latitude, patentee.loc_longitude as point_longitude FROM { src_table } , UNNEST(patentee) AS patentee WHERE RAND()< { sample_ratio } AND publication_date>0 AND patentee.loc_source IS NOT NULL AND patentee.loc_latitude IS NOT NULL { office_clause } \"\"\" client = _get_bq_client ( credentials ) typer . secho ( f \"Start: \\n { query } \" , fg = typer . colors . BLUE ) df = client . query ( query ) . to_dataframe () df . to_csv ( dest_file , index = False ) typer . secho ( f \" { ok } Extract for Kepler saved to { dest_file } .\" , fg = typer . colors . GREEN ) family_expansion ( src_table , destination_table , credentials , destination_schema ) \u00b6 Expand along families in table ref . The returned table contains all publications belonging to a family existing in src_table but absent from the latter. Family data are assigned from data in src_table . Parameters: Name Type Description Default src_table str source table (project.dataset.table) required destination_table str destination table (project.dataset.table) required credentials str BQ credentials file path required destination_schema str destination schema file path required Usage: patentcity io family-expansion <src-table> <destination-table> credentials-patentcity.json schema/patentcity_v1.json Source code in patentcity/io.py 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 @app . command () def family_expansion ( src_table : str , destination_table : str , credentials : str , destination_schema : str ): \"\"\"Expand along families in `table ref`. The returned table contains all publications belonging to a family existing in `src_table` *but* absent from the latter. Family data are *assigned* from data in `src_table`. Arguments: src_table: source table (project.dataset.table) destination_table: destination table (project.dataset.table) credentials: BQ credentials file path destination_schema: destination schema file path **Usage:** ```shell patentcity io family-expansion <src-table> <destination-table> credentials-patentcity.json schema/patentcity_v1.json ``` \"\"\" query = f \"\"\" WITH family_table AS ( SELECT family_id, ANY_VALUE(patentee) as patentee FROM ` { src_table } ` # patentcity.patentcity.v100rc4 GROUP BY family_id ), publication_list AS ( SELECT DISTINCT(publication_number) AS publication_number FROM ` { src_table } `), # patentcity.patentcity.v100rc4 expanded_family_table AS ( SELECT p.publication_number, p.publication_date, family_table.* FROM `patents-public-data.patents.publications`AS p, family_table WHERE p.family_id = family_table.family_id AND family_table.family_id IS NOT NULL AND SPLIT(p.publication_number, \"-\")[OFFSET(0)] in (\"DD\",\"DE\", \"FR\", \"GB\", \"US\"))#, SELECT expanded_family_table.*, #EXCEPT(appln_id, pat_publn_id, docdb_family_id, inpadoc_family_id), SPLIT(expanded_family_table.publication_number, \"-\")[OFFSET(0)] as country_code, SPLIT(expanded_family_table.publication_number, \"-\")[OFFSET(1)] as pubnum, SPLIT(expanded_family_table.publication_number, \"-\")[OFFSET(2)] as kind_code, \"EXP\" AS origin FROM publication_list RIGHT JOIN expanded_family_table ON expanded_family_table.publication_number=publication_list.publication_number WHERE publication_list.publication_number IS NULL \"\"\" _get_job_done ( query , destination_table , credentials , destination_schema = destination_schema ) filter_kind_codes ( src_table , destination_table , credentials ) \u00b6 Filter src_table to make sure that only utility patents are reported. Parameters: Name Type Description Default src_table str source table (project.dataset.table) required destination_table str destination table (project.dataset.table) required credentials str BQ credentials file path required Usage: patentcity io filter-kind-codes <src_table> <destination_table> credentials-patentcity.json Source code in patentcity/io.py 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 @app . command () def filter_kind_codes ( src_table : str , destination_table : str , credentials : str ): \"\"\"Filter `src_table` to make sure that only *utility patents* are reported. Arguments: src_table: source table (project.dataset.table) destination_table: destination table (project.dataset.table) credentials: BQ credentials file path **Usage:** ```shell patentcity io filter-kind-codes <src_table> <destination_table> credentials-patentcity.json ``` \"\"\" query = f \"\"\" WITH keep_list AS ( SELECT publication_number, CASE WHEN country_code = \"DD\" AND (kind_code in (\"A\", \"A1\", \"A3\", \"B\")) THEN TRUE WHEN country_code = \"DE\" AND (kind_code in (\"A1\", \"B\", \"B3\", \"C\", \"C1\", \"D1\")) THEN TRUE WHEN country_code = \"FR\" AND (kind_code in (\"A\", \"A1\")) THEN TRUE WHEN country_code = \"GB\" AND (kind_code in (\"A\")) THEN TRUE WHEN country_code = \"US\" AND (kind_code in (\"A\", \"B1\", \"B2\")) THEN TRUE ELSE FALSE END AS keep FROM ` { src_table } `) # patentcity.patentcity.v100rc4 SELECT origin.* FROM ` { src_table } ` as origin, # patentcity.patentcity.v100rc4 keep_list WHERE keep_list.publication_number = origin.publication_number AND keep_list.keep IS TRUE \"\"\" _get_job_done ( query , destination_table , credentials ) get_stratified_sample ( src_table , bin_size = 50 , preview = False , destination_table = None , credentials = None ) \u00b6 Return a stratified sample of src_table (based on country_code and publication_decade) with bin_size samples in each bin (if possible). Parameters: Name Type Description Default src_table str source table (project.dataset.table) required bin_size int bin size 50 preview bool if True, output not saved and table stats to stdout. Else, output saved to destination_table False destination_table str destination table (project.dataset.table) None credentials str BQ credentials file path None Usage: patentcity io get-stratified-sample patentcity.patentcity.v1 Tip Stratified random sampling with bigquery - StackOverflow Source code in patentcity/io.py 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 @app . command () def get_stratified_sample ( src_table : str , bin_size : int = 50 , preview : bool = False , destination_table : str = None , credentials : str = None , ): \"\"\"Return a stratified sample of `src_table` (based on country_code and publication_decade) with `bin_size` samples in each bin (if possible). Arguments: src_table: source table (project.dataset.table) bin_size: bin size preview: if True, output not saved and table stats to stdout. Else, output saved to `destination_table` destination_table: destination table (project.dataset.table) credentials: BQ credentials file path **Usage:** ```shell patentcity io get-stratified-sample patentcity.patentcity.v1 ``` !!! tip [Stratified random sampling with bigquery - StackOverflow](https://stackoverflow.com/questions/52901451/stratified-random-sampling-with-bigquery) \"\"\" if preview : prefix = \"\"\" SELECT COUNT(*) nb_samples, country_code, publication_decade, ROUND(100*COUNT(*)/MAX(nb_bin),2) AS percentage FROM ( \"\"\" select = ( \"\"\"SELECT publication_number, publication_decade, country_code, nb_bin\"\"\" ) suffix = \"\"\") GROUP BY country_code, publication_decade\"\"\" else : prefix , select , suffix = \"\" , \"SELECT * \" , \"\" query = f \"\"\" WITH tmp AS ( SELECT CAST(publication_date/100000 AS INT64) AS publication_decade, * EXCEPT(patentee) FROM ` { src_table } `, # patentcity.patentcity.wgp_v1 UNNEST(patentee) as patentee WHERE patentee.loc_text IS NOT NULL AND patentee.loc_source IS NOT NULL ), table_stats AS ( SELECT *, SUM(nb_bin) OVER() AS nb_total FROM ( SELECT country_code, CAST(publication_date/100000 AS INT64) AS publication_decade, COUNT(*) nb_bin FROM tmp GROUP BY country_code, publication_decade) ) { prefix } { select } FROM tmp JOIN table_stats USING(country_code, publication_decade) WHERE RAND()< { bin_size } /nb_bin { suffix } \"\"\" if preview : client = _get_bq_client ( credentials ) tmp = ( client . query ( query ) . to_dataframe () . sort_values ( by = [ \"country_code\" , \"publication_decade\" ]) ) typer . echo ( tmp . to_markdown ( index = False )) typer . secho ( f \"Nb samples: { tmp [ 'nb_samples' ] . sum () } \" , fg = typer . colors . BLUE ) else : _get_job_done ( query , destination_table , credentials ) get_wgp25_recid ( country_code , src_table , patstat_patent_properties_table , destination_table , credentials ) \u00b6 Extract recId and searchText from wgp25 for patents published in country_code . Parameters: Name Type Description Default country_code str country code of the patent office (e.g. DE, FR, GB, US, etc) required src_table str source table (project.dataset.table) required patstat_patent_properties_table str PATSTAT patent properties table on BQ (project.dataset.table) required destination_table str destination table (project.dataset.table) required credentials str BQ credentials file path required Usage: OFFICE = DE patentcity io get-wgp25-recid $OFFICE patentcity.external.inventor_applicant_recid patentcity.tmp.loc_ ${ (L)OFFICE } patentwgp25 credentials-patentcity.json Info This function assumes that the recId has been added to inventor_applicant_locationid beforehand (using utils.get_recid(address_) ). Source code in patentcity/io.py 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 @app . command () def get_wgp25_recid ( country_code : str , src_table : str , patstat_patent_properties_table : str , destination_table : str , credentials : str , ): \"\"\"Extract recId and searchText from wgp25 for patents published in `country_code`. Arguments: country_code: country code of the patent office (e.g. DE, FR, GB, US, etc) src_table: source table (project.dataset.table) patstat_patent_properties_table: PATSTAT patent properties table on BQ (project.dataset.table) destination_table: destination table (project.dataset.table) credentials: BQ credentials file path **Usage:** ```shell OFFICE=DE patentcity io get-wgp25-recid $OFFICE patentcity.external.inventor_applicant_recid patentcity.tmp.loc_${(L)OFFICE}patentwgp25 credentials-patentcity.json ``` !!! info This function assumes that the recId has been added to inventor_applicant_locationid beforehand (using `utils.get_recid(address_)`).\"\"\" assert len ( country_code ) == 2 query = f \"\"\" WITH tmp AS ( SELECT loc.*, patstat.*, SPLIT(patstat.publication_number, \"-\")[OFFSET(0)] AS country_code FROM ` { src_table } ` AS loc, # patentcity.external.inventor_applicant_recid ` { patstat_patent_properties_table } ` AS patstat # patentcity.external.patstat_patent_properties WHERE loc.appln_id = patstat.appln_id AND loc.appln_id IS NOT NULL AND SPLIT(patstat.publication_number, \"-\")[OFFSET(0)] IN \" { country_code } \" SELECT recId, ANY_VALUE(address_) AS searchText FROM tmp GROUP BY recId \"\"\" _get_job_done ( query , destination_table , credentials ) impute_publication_date ( src_table , imputation_table , country_code = None , credentials = None ) \u00b6 Update src_table publication_date - DE & DD only Parameters: Name Type Description Default src_table str source table (project.dataset.table) required imputation_table str imputation table (project.dataset.table) required country_code str in [\"DE\", \"DD\"] None credentials str BQ credentials file path None Usage: patentcity io impute-publication-date <src_table> <imputation_table> --country-code DE --credentials credentials-patentcity.json Source code in patentcity/io.py 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 @app . command () def impute_publication_date ( src_table : str , imputation_table : str , country_code : str = None , credentials : str = None , ): \"\"\"Update `src_table` publication_date - DE & DD only Arguments: src_table: source table (project.dataset.table) imputation_table: imputation table (project.dataset.table) country_code: in [\"DE\", \"DD\"] credentials: BQ credentials file path **Usage:** ```shell patentcity io impute-publication-date <src_table> <imputation_table> --country-code DE --credentials credentials-patentcity.json ``` \"\"\" de_clause = ( \"\"\"AND CAST(t.pubnum AS INT64)<330000\"\"\" if country_code == \"DE\" else \"\"\"\"\"\" ) query = f \"\"\"UPDATE ` { src_table } ` AS t SET t.publication_date = imputation.publication_date FROM ` { imputation_table } ` AS imputation WHERE t.pubnum = imputation.pubnum AND country_code=\" { country_code } \" { de_clause } \"\"\" client = _get_bq_client ( credentials ) typer . secho ( f \"Start: \\n { query } \" , fg = typer . colors . BLUE ) client . query ( query ) . result () typer . secho ( f \" { ok }{ src_table } updated.\" , fg = typer . colors . GREEN ) order ( src_table , by = None , destination_table = None , credentials = None ) \u00b6 Order src_table by by and stage it onto destination_table Parameters: Name Type Description Default src_table str source table (project.dataset.table) required by str ordering dimension (e.g. publication_number) None destination_table str destination table (project.dataset.table) None credentials str BQ credentials file path None Usage: patentcity io order patentcity.tmp.patentcity25 --by publication_number --destination-table patentcity.tmp.tmp25 --key-file credentials-patentcity.json Source code in patentcity/io.py 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 @app . command () def order ( src_table : str , by : str = None , destination_table : str = None , credentials : str = None , ): \"\"\"Order `src_table` by `by` and stage it onto `destination_table` Arguments: src_table: source table (project.dataset.table) by: ordering dimension (e.g. publication_number) destination_table: destination table (project.dataset.table) credentials: BQ credentials file path **Usage:** ```shell patentcity io order patentcity.tmp.patentcity25 --by publication_number --destination-table patentcity.tmp.tmp25 --key-file credentials-patentcity.json ``` \"\"\" query = f \"\"\" SELECT * FROM ` { src_table } ` ORDER BY { by } # publication_number \"\"\" _get_job_done ( query , destination_table , credentials )","title":"io"},{"location":"API_IO/#patentcity.io.augment_patentcity","text":"Add (mainly interoperability) variables to src_table and save to `destination_table Parameters: Name Type Description Default src_table str source table (project.dataset.table) required destination_table str destination table (project.dataset.table) required credentials str BQ credentials file path None Usage: patentcity io augment-patentcity <src_table> <destination_table> credentials-patentcity.json Source code in patentcity/io.py 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 @app . command () def augment_patentcity ( src_table : str , destination_table : str , credentials : str = None ): \"\"\"Add (mainly interoperability) variables to `src_table` and save to `destination_table Arguments: src_table: source table (project.dataset.table) destination_table: destination table (project.dataset.table) credentials: BQ credentials file path **Usage:** ```shell patentcity io augment-patentcity <src_table> <destination_table> credentials-patentcity.json ``` \"\"\" query = f \"\"\" SELECT pc.publication_number, p.publication_date, p.family_id, SPLIT(pc.publication_number, \"-\")[OFFSET(0)] AS country_code, SPLIT(pc.publication_number, \"-\")[OFFSET(1)] AS pubnum, SPLIT(pc.publication_number, \"-\")[OFFSET(2)] AS kind_code, pc.* EXCEPT(publication_number) FROM `patents-public-data.patents.publications` AS p RIGHT JOIN ` { src_table } ` AS pc ON pc.publication_number = p.publication_number \"\"\" _get_job_done ( query , destination_table , credentials )","title":"augment_patentcity()"},{"location":"API_IO/#patentcity.io.build_wgp_as_patentcity","text":"Join addresses and individuals from WGP and add data at the patent as well as individual level. Parameters: Name Type Description Default addresses_table str WGP addresses table (project.dataset.table) required patentee_location_table str WGP patentees table (project.dataset.table) required patstat_patent_properties_table str PATSTAT patent properties table on BQ (project.dataset.table) None tls206_table str PATSTAT tls206 table on BQ (project.dataset.table) None tls207_table str PATSTAT tls207 table on BQ (project.dataset.table) None destination_table str destination table (project.dataset.table) None flavor int WGP source data flavor (in [25, 45]) None credentials str BQ credentials file path None Usage: patentcity io build-wgp-as-patentcity patentcity.external.addresses_florian45_patentcity patentcity.external.person_location_id --tls206-table patentcity.external.tls206 --tls207-table patentcity.external.tls207 --patstat-patent-properties-table patentcity.external.patstat_patent_properties --destination-table patentcity.tmp.patentcity45 --flavor 45 --key-file $KEY_FILE Source code in patentcity/io.py 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 @app . command () def build_wgp_as_patentcity ( addresses_table : str , patentee_location_table : str , patstat_patent_properties_table : str = None , tls206_table : str = None , tls207_table : str = None , destination_table : str = None , flavor : int = None , credentials : str = None , ): \"\"\"Join addresses and individuals from WGP and add data at the patent as well as individual level. Arguments: addresses_table: WGP addresses table (project.dataset.table) patentee_location_table: WGP patentees table (project.dataset.table) patstat_patent_properties_table: PATSTAT patent properties table on BQ (project.dataset.table) tls206_table: PATSTAT tls206 table on BQ (project.dataset.table) tls207_table: PATSTAT tls207 table on BQ (project.dataset.table) destination_table: destination table (project.dataset.table) flavor: WGP source data flavor (in [25, 45]) credentials: BQ credentials file path **Usage:** ```shell patentcity io build-wgp-as-patentcity patentcity.external.addresses_florian45_patentcity patentcity.external.person_location_id --tls206-table patentcity.external.tls206 --tls207-table patentcity.external.tls207 --patstat-patent-properties-table patentcity.external.patstat_patent_properties --destination-table patentcity.tmp.patentcity45 --flavor 45 --key-file $KEY_FILE ``` \"\"\" assert flavor in [ 25 , 45 ] assert patentee_location_table assert addresses_table if flavor == 25 : query = f \"\"\" WITH tmp AS ( SELECT patee.* EXCEPT(recId), loc.*, app_inv=\"INV\" AS is_inv, app_inv=\"APP\" AS is_app FROM ( SELECT * FROM ` { addresses_table } ` # patentcity.external.addresses_cyril25_patentcity WHERE seqNumber = 1 AND (matchLevel=\"NOMATCH\" AND source=\"HERE\") IS FALSE ) AS loc JOIN ` { patentee_location_table } ` AS patee # patentcity.external.inventor_applicant_recid ON loc.recId = patee.recId ) # location_id SELECT tmp.* EXCEPT(appln_id, pat_publn_id), patstat.*, SPLIT(patstat.publication_number, \"-\")[OFFSET(0)] AS country_code, SPLIT(patstat.publication_number, \"-\")[OFFSET(1)] AS pubnum, SPLIT(patstat.publication_number, \"-\")[OFFSET(2)] AS kind_code FROM tmp LEFT JOIN ` { patstat_patent_properties_table } ` AS patstat ON tmp.pat_publn_id = patstat.pat_publn_id #tmp.appln_id = patstat.appln_id # here we are at the publication level, not the patent level WHERE SPLIT(patstat.publication_number, \"-\")[OFFSET(0)] IN (\"DE\", \"GB\", \"FR\", \"US\") \"\"\" if flavor == 45 : assert tls206_table assert tls207_table query = f \"\"\" WITH tmp AS ( WITH tmp_ AS ( WITH person AS ( SELECT tls207.*, tls206.person_name, invt_seq_nr > 0 AS is_inv, applt_seq_nr > 0 AS is_asg FROM ` { tls206_table } ` AS tls206, # usptobias.patstat.tls206 ` { tls207_table } ` AS tls207 # usptobias.patstat.tls207 WHERE tls207.person_id=tls206.person_id ) SELECT patee.*, person.* EXCEPT(person_id) FROM ` { patentee_location_table } ` AS patee # patentcity.external.person_location_id LEFT JOIN person ON patee.person_id = person.person_id) SELECT * FROM tmp_ LEFT JOIN ` { addresses_table } ` AS loc # patentcity.external.addresses_florian45_patentcity ON tmp_.location_id = loc.recId WHERE seqNumber = 1 ) SELECT tmp.* EXCEPT(appln_id), patstat.*, SPLIT(patstat.publication_number, \"-\")[OFFSET(0)] AS country_code, SPLIT(patstat.publication_number, \"-\")[OFFSET(1)] AS pubnum, SPLIT(patstat.publication_number, \"-\")[OFFSET(2)] AS kind_code FROM tmp LEFT JOIN ` { patstat_patent_properties_table } ` AS patstat ON tmp.appln_id = patstat.appln_id # here we are at the the patent level WHERE SPLIT(patstat.publication_number, \"-\")[OFFSET(0)] IN (\"DE\", \"GB\", \"FR\", \"US\") \"\"\" _get_job_done ( query , destination_table , credentials )","title":"build_wgp_as_patentcity()"},{"location":"API_IO/#patentcity.io.deduplicate","text":"Deduplicate patentcity table from publications which are both in at least 2 of the following data sources PC, WGP45 and WGP25. We prioritize PC, then WGP45 and then WGP25. Argument src_table: source table (project.dataset.table) destination_table: destination table (project.dataset.table) credentials: BQ credentials file path Usage: patentcity io deduplicate <src-table> <destination-table> credentials-patentcity.json Source code in patentcity/io.py 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 @app . command () def deduplicate ( src_table : str , destination_table : str , credentials : str ): \"\"\" Deduplicate patentcity table from publications which are both in at least 2 of the following data sources PC, WGP45 and WGP25. We prioritize PC, then WGP45 and then WGP25. Argument: src_table: source table (project.dataset.table) destination_table: destination table (project.dataset.table) credentials: BQ credentials file path **Usage:** ```shell patentcity io deduplicate <src-table> <destination-table> credentials-patentcity.json ``` \"\"\" query = f \"\"\" WITH duplicates AS ( SELECT publication_number, COUNT(publication_number) AS nb_occ, STRING_AGG(DISTINCT(origin)) AS origins FROM { src_table } #`patentcity.tmp.v100rc5` GROUP BY publication_number), keep_list AS ( SELECT tmp.publication_number, tmp.origin, duplicates.* EXCEPT(publication_number), CASE WHEN nb_occ = 1 THEN TRUE WHEN nb_occ > 1 AND origins LIKE \"%PC%\" AND origin=\"PC\" THEN TRUE WHEN nb_occ > 1 AND origins LIKE \"%WGP45%\" AND origins NOT LIKE \"%PC%\" AND origin=\"WGP45\" THEN TRUE WHEN nb_occ > 1 AND origins LIKE \"%WGP25%\" AND origins NOT LIKE \"%PC%\" AND origins NOT LIKE \"%WGP45%\" AND origin=\"WGP25\" THEN TRUE ELSE FALSE END AS keep FROM { src_table } AS tmp # `patentcity.tmp.v100rc5` LEFT JOIN duplicates ON tmp.publication_number = duplicates.publication_number ) SELECT tmp.*#, #keep_list.* EXCEPT(publication_number, origin) ## for dbg FROM { src_table } AS tmp # `patentcity.tmp.v100rc5` LEFT JOIN keep_list ON tmp.publication_number=keep_list.publication_number AND tmp.origin=keep_list.origin WHERE keep IS TRUE \"\"\" _get_job_done ( query , destination_table , credentials )","title":"deduplicate()"},{"location":"API_IO/#patentcity.io.extract_sample_kepler","text":"Extract sample for kepler.gl Parameters: Name Type Description Default src_table str source table (project.dataset.table) required dest_file str destination file path (local) required sample_ratio float share of patents to extract 0.1 office str patent office two letter-code (e.g. DD, DE, FR, etc) None credentials str BQ credentials file path None Usage: patentcity io extract-sample-kepler <src_table> <dest_file> --office DE --credentials credentials-patentcity.json Source code in patentcity/io.py 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 @app . command () def extract_sample_kepler ( src_table : str , dest_file : str , sample_ratio : float = 0.1 , office : str = None , credentials : str = None , ): \"\"\"Extract sample for kepler.gl Arguments: src_table: source table (project.dataset.table) dest_file: destination file path (local) sample_ratio: share of patents to extract office: patent office two letter-code (e.g. DD, DE, FR, etc) credentials: BQ credentials file path **Usage:** ```shell patentcity io extract-sample-kepler <src_table> <dest_file> --office DE --credentials credentials-patentcity.json ``` \"\"\" office_clause = f \"\"\"AND country_code=\" { office } \" \"\"\" if office else \"\" query = f \"\"\" SELECT publication_number, country_code, CAST(publication_date/10000 AS INT64) AS publication_year, PARSE_TIMESTAMP('%Y%m%d%H%M%S', CAST(publication_date*100000 AS STRING)) as publication_date, patentee.loc_country as country, patentee.loc_city as city, patentee.loc_latitude as point_latitude, patentee.loc_longitude as point_longitude FROM { src_table } , UNNEST(patentee) AS patentee WHERE RAND()< { sample_ratio } AND publication_date>0 AND patentee.loc_source IS NOT NULL AND patentee.loc_latitude IS NOT NULL { office_clause } \"\"\" client = _get_bq_client ( credentials ) typer . secho ( f \"Start: \\n { query } \" , fg = typer . colors . BLUE ) df = client . query ( query ) . to_dataframe () df . to_csv ( dest_file , index = False ) typer . secho ( f \" { ok } Extract for Kepler saved to { dest_file } .\" , fg = typer . colors . GREEN )","title":"extract_sample_kepler()"},{"location":"API_IO/#patentcity.io.family_expansion","text":"Expand along families in table ref . The returned table contains all publications belonging to a family existing in src_table but absent from the latter. Family data are assigned from data in src_table . Parameters: Name Type Description Default src_table str source table (project.dataset.table) required destination_table str destination table (project.dataset.table) required credentials str BQ credentials file path required destination_schema str destination schema file path required Usage: patentcity io family-expansion <src-table> <destination-table> credentials-patentcity.json schema/patentcity_v1.json Source code in patentcity/io.py 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 @app . command () def family_expansion ( src_table : str , destination_table : str , credentials : str , destination_schema : str ): \"\"\"Expand along families in `table ref`. The returned table contains all publications belonging to a family existing in `src_table` *but* absent from the latter. Family data are *assigned* from data in `src_table`. Arguments: src_table: source table (project.dataset.table) destination_table: destination table (project.dataset.table) credentials: BQ credentials file path destination_schema: destination schema file path **Usage:** ```shell patentcity io family-expansion <src-table> <destination-table> credentials-patentcity.json schema/patentcity_v1.json ``` \"\"\" query = f \"\"\" WITH family_table AS ( SELECT family_id, ANY_VALUE(patentee) as patentee FROM ` { src_table } ` # patentcity.patentcity.v100rc4 GROUP BY family_id ), publication_list AS ( SELECT DISTINCT(publication_number) AS publication_number FROM ` { src_table } `), # patentcity.patentcity.v100rc4 expanded_family_table AS ( SELECT p.publication_number, p.publication_date, family_table.* FROM `patents-public-data.patents.publications`AS p, family_table WHERE p.family_id = family_table.family_id AND family_table.family_id IS NOT NULL AND SPLIT(p.publication_number, \"-\")[OFFSET(0)] in (\"DD\",\"DE\", \"FR\", \"GB\", \"US\"))#, SELECT expanded_family_table.*, #EXCEPT(appln_id, pat_publn_id, docdb_family_id, inpadoc_family_id), SPLIT(expanded_family_table.publication_number, \"-\")[OFFSET(0)] as country_code, SPLIT(expanded_family_table.publication_number, \"-\")[OFFSET(1)] as pubnum, SPLIT(expanded_family_table.publication_number, \"-\")[OFFSET(2)] as kind_code, \"EXP\" AS origin FROM publication_list RIGHT JOIN expanded_family_table ON expanded_family_table.publication_number=publication_list.publication_number WHERE publication_list.publication_number IS NULL \"\"\" _get_job_done ( query , destination_table , credentials , destination_schema = destination_schema )","title":"family_expansion()"},{"location":"API_IO/#patentcity.io.filter_kind_codes","text":"Filter src_table to make sure that only utility patents are reported. Parameters: Name Type Description Default src_table str source table (project.dataset.table) required destination_table str destination table (project.dataset.table) required credentials str BQ credentials file path required Usage: patentcity io filter-kind-codes <src_table> <destination_table> credentials-patentcity.json Source code in patentcity/io.py 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 @app . command () def filter_kind_codes ( src_table : str , destination_table : str , credentials : str ): \"\"\"Filter `src_table` to make sure that only *utility patents* are reported. Arguments: src_table: source table (project.dataset.table) destination_table: destination table (project.dataset.table) credentials: BQ credentials file path **Usage:** ```shell patentcity io filter-kind-codes <src_table> <destination_table> credentials-patentcity.json ``` \"\"\" query = f \"\"\" WITH keep_list AS ( SELECT publication_number, CASE WHEN country_code = \"DD\" AND (kind_code in (\"A\", \"A1\", \"A3\", \"B\")) THEN TRUE WHEN country_code = \"DE\" AND (kind_code in (\"A1\", \"B\", \"B3\", \"C\", \"C1\", \"D1\")) THEN TRUE WHEN country_code = \"FR\" AND (kind_code in (\"A\", \"A1\")) THEN TRUE WHEN country_code = \"GB\" AND (kind_code in (\"A\")) THEN TRUE WHEN country_code = \"US\" AND (kind_code in (\"A\", \"B1\", \"B2\")) THEN TRUE ELSE FALSE END AS keep FROM ` { src_table } `) # patentcity.patentcity.v100rc4 SELECT origin.* FROM ` { src_table } ` as origin, # patentcity.patentcity.v100rc4 keep_list WHERE keep_list.publication_number = origin.publication_number AND keep_list.keep IS TRUE \"\"\" _get_job_done ( query , destination_table , credentials )","title":"filter_kind_codes()"},{"location":"API_IO/#patentcity.io.get_stratified_sample","text":"Return a stratified sample of src_table (based on country_code and publication_decade) with bin_size samples in each bin (if possible). Parameters: Name Type Description Default src_table str source table (project.dataset.table) required bin_size int bin size 50 preview bool if True, output not saved and table stats to stdout. Else, output saved to destination_table False destination_table str destination table (project.dataset.table) None credentials str BQ credentials file path None Usage: patentcity io get-stratified-sample patentcity.patentcity.v1 Tip Stratified random sampling with bigquery - StackOverflow Source code in patentcity/io.py 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 @app . command () def get_stratified_sample ( src_table : str , bin_size : int = 50 , preview : bool = False , destination_table : str = None , credentials : str = None , ): \"\"\"Return a stratified sample of `src_table` (based on country_code and publication_decade) with `bin_size` samples in each bin (if possible). Arguments: src_table: source table (project.dataset.table) bin_size: bin size preview: if True, output not saved and table stats to stdout. Else, output saved to `destination_table` destination_table: destination table (project.dataset.table) credentials: BQ credentials file path **Usage:** ```shell patentcity io get-stratified-sample patentcity.patentcity.v1 ``` !!! tip [Stratified random sampling with bigquery - StackOverflow](https://stackoverflow.com/questions/52901451/stratified-random-sampling-with-bigquery) \"\"\" if preview : prefix = \"\"\" SELECT COUNT(*) nb_samples, country_code, publication_decade, ROUND(100*COUNT(*)/MAX(nb_bin),2) AS percentage FROM ( \"\"\" select = ( \"\"\"SELECT publication_number, publication_decade, country_code, nb_bin\"\"\" ) suffix = \"\"\") GROUP BY country_code, publication_decade\"\"\" else : prefix , select , suffix = \"\" , \"SELECT * \" , \"\" query = f \"\"\" WITH tmp AS ( SELECT CAST(publication_date/100000 AS INT64) AS publication_decade, * EXCEPT(patentee) FROM ` { src_table } `, # patentcity.patentcity.wgp_v1 UNNEST(patentee) as patentee WHERE patentee.loc_text IS NOT NULL AND patentee.loc_source IS NOT NULL ), table_stats AS ( SELECT *, SUM(nb_bin) OVER() AS nb_total FROM ( SELECT country_code, CAST(publication_date/100000 AS INT64) AS publication_decade, COUNT(*) nb_bin FROM tmp GROUP BY country_code, publication_decade) ) { prefix } { select } FROM tmp JOIN table_stats USING(country_code, publication_decade) WHERE RAND()< { bin_size } /nb_bin { suffix } \"\"\" if preview : client = _get_bq_client ( credentials ) tmp = ( client . query ( query ) . to_dataframe () . sort_values ( by = [ \"country_code\" , \"publication_decade\" ]) ) typer . echo ( tmp . to_markdown ( index = False )) typer . secho ( f \"Nb samples: { tmp [ 'nb_samples' ] . sum () } \" , fg = typer . colors . BLUE ) else : _get_job_done ( query , destination_table , credentials )","title":"get_stratified_sample()"},{"location":"API_IO/#patentcity.io.get_wgp25_recid","text":"Extract recId and searchText from wgp25 for patents published in country_code . Parameters: Name Type Description Default country_code str country code of the patent office (e.g. DE, FR, GB, US, etc) required src_table str source table (project.dataset.table) required patstat_patent_properties_table str PATSTAT patent properties table on BQ (project.dataset.table) required destination_table str destination table (project.dataset.table) required credentials str BQ credentials file path required Usage: OFFICE = DE patentcity io get-wgp25-recid $OFFICE patentcity.external.inventor_applicant_recid patentcity.tmp.loc_ ${ (L)OFFICE } patentwgp25 credentials-patentcity.json Info This function assumes that the recId has been added to inventor_applicant_locationid beforehand (using utils.get_recid(address_) ). Source code in patentcity/io.py 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 @app . command () def get_wgp25_recid ( country_code : str , src_table : str , patstat_patent_properties_table : str , destination_table : str , credentials : str , ): \"\"\"Extract recId and searchText from wgp25 for patents published in `country_code`. Arguments: country_code: country code of the patent office (e.g. DE, FR, GB, US, etc) src_table: source table (project.dataset.table) patstat_patent_properties_table: PATSTAT patent properties table on BQ (project.dataset.table) destination_table: destination table (project.dataset.table) credentials: BQ credentials file path **Usage:** ```shell OFFICE=DE patentcity io get-wgp25-recid $OFFICE patentcity.external.inventor_applicant_recid patentcity.tmp.loc_${(L)OFFICE}patentwgp25 credentials-patentcity.json ``` !!! info This function assumes that the recId has been added to inventor_applicant_locationid beforehand (using `utils.get_recid(address_)`).\"\"\" assert len ( country_code ) == 2 query = f \"\"\" WITH tmp AS ( SELECT loc.*, patstat.*, SPLIT(patstat.publication_number, \"-\")[OFFSET(0)] AS country_code FROM ` { src_table } ` AS loc, # patentcity.external.inventor_applicant_recid ` { patstat_patent_properties_table } ` AS patstat # patentcity.external.patstat_patent_properties WHERE loc.appln_id = patstat.appln_id AND loc.appln_id IS NOT NULL AND SPLIT(patstat.publication_number, \"-\")[OFFSET(0)] IN \" { country_code } \" SELECT recId, ANY_VALUE(address_) AS searchText FROM tmp GROUP BY recId \"\"\" _get_job_done ( query , destination_table , credentials )","title":"get_wgp25_recid()"},{"location":"API_IO/#patentcity.io.impute_publication_date","text":"Update src_table publication_date - DE & DD only Parameters: Name Type Description Default src_table str source table (project.dataset.table) required imputation_table str imputation table (project.dataset.table) required country_code str in [\"DE\", \"DD\"] None credentials str BQ credentials file path None Usage: patentcity io impute-publication-date <src_table> <imputation_table> --country-code DE --credentials credentials-patentcity.json Source code in patentcity/io.py 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 @app . command () def impute_publication_date ( src_table : str , imputation_table : str , country_code : str = None , credentials : str = None , ): \"\"\"Update `src_table` publication_date - DE & DD only Arguments: src_table: source table (project.dataset.table) imputation_table: imputation table (project.dataset.table) country_code: in [\"DE\", \"DD\"] credentials: BQ credentials file path **Usage:** ```shell patentcity io impute-publication-date <src_table> <imputation_table> --country-code DE --credentials credentials-patentcity.json ``` \"\"\" de_clause = ( \"\"\"AND CAST(t.pubnum AS INT64)<330000\"\"\" if country_code == \"DE\" else \"\"\"\"\"\" ) query = f \"\"\"UPDATE ` { src_table } ` AS t SET t.publication_date = imputation.publication_date FROM ` { imputation_table } ` AS imputation WHERE t.pubnum = imputation.pubnum AND country_code=\" { country_code } \" { de_clause } \"\"\" client = _get_bq_client ( credentials ) typer . secho ( f \"Start: \\n { query } \" , fg = typer . colors . BLUE ) client . query ( query ) . result () typer . secho ( f \" { ok }{ src_table } updated.\" , fg = typer . colors . GREEN )","title":"impute_publication_date()"},{"location":"API_IO/#patentcity.io.order","text":"Order src_table by by and stage it onto destination_table Parameters: Name Type Description Default src_table str source table (project.dataset.table) required by str ordering dimension (e.g. publication_number) None destination_table str destination table (project.dataset.table) None credentials str BQ credentials file path None Usage: patentcity io order patentcity.tmp.patentcity25 --by publication_number --destination-table patentcity.tmp.tmp25 --key-file credentials-patentcity.json Source code in patentcity/io.py 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 @app . command () def order ( src_table : str , by : str = None , destination_table : str = None , credentials : str = None , ): \"\"\"Order `src_table` by `by` and stage it onto `destination_table` Arguments: src_table: source table (project.dataset.table) by: ordering dimension (e.g. publication_number) destination_table: destination table (project.dataset.table) credentials: BQ credentials file path **Usage:** ```shell patentcity io order patentcity.tmp.patentcity25 --by publication_number --destination-table patentcity.tmp.tmp25 --key-file credentials-patentcity.json ``` \"\"\" query = f \"\"\" SELECT * FROM ` { src_table } ` ORDER BY { by } # publication_number \"\"\" _get_job_done ( query , destination_table , credentials )","title":"order()"},{"location":"API_SEARCH/","text":"relationship_best ( path , report = 'short' ) \u00b6 Report perf of each (long)/best (short) config` Parameters: Name Type Description Default path str data file path (wildcard allowed) required report str report type (in [\"short\", \"long\"]) 'short' Usage: patentcity eval relationship-model data/gold_rel_ddpatent01.jsonl rel_ddpatent01.yaml --report json Source code in patentcity/search.py 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 @app . command () def relationship_best ( path : str , report : str = \"short\" ): \"\"\"Report perf of each (long)/best (short) config` Arguments: path: data file path (wildcard allowed) report: report type (in [\"short\", \"long\"]) **Usage:** ```shell patentcity eval relationship-model data/gold_rel_ddpatent01.jsonl rel_ddpatent01.yaml --report json ``` \"\"\" files = glob ( path ) assert report in [ \"short\" , \"long\" ] res = pd . DataFrame () for file in files : tmp = pd . read_json ( file ) . T tmp [ \"config\" ] = os . path . basename ( file ) res = res . append ( tmp ) res = res . reset_index () . rename ( columns = { \"index\" : \"label\" }) labels = [ \"ALL\" ] + list ( RELATIONS . values ()) for i , label in enumerate ( labels ): res_label = res . query ( f \"label==' { label } '\" ) . sort_values ( \"f\" , ascending = False ) if report == \"long\" : if i == 0 : typer . secho ( f \"# Report\" , fg = typer . colors . BLUE ) typer . secho ( f \" \\n ## { label } \" , fg = typer . colors . BLUE ) typer . echo ( res_label . to_markdown ( index = False )) else : if i == 0 : best = pd . DataFrame ( columns = res_label . columns ) best = best . append ( res_label . iloc [: 1 ]) if report == \"short\" : typer . echo ( best . to_markdown ( index = False )) relationship_params ( config_search ) \u00b6 Generate config files defined by config_search grid Parameters: Name Type Description Default config_search str config search file path required Usage: `shell patentcity search relationship-params configs/rel_search.yaml Source code in patentcity/search.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 @app . command () def relationship_params ( config_search : str ): \"\"\"Generate config files defined by `config_search` grid Arguments: config_search: config search file path **Usage:** ```shell patentcity search relationship-params configs/rel_search.yaml `` \"\"\" filename = os . path . basename ( config_search ) path = os . path . dirname ( config_search ) with open ( config_search , \"r\" ) as config_file : cfg = yaml . load ( config_file , Loader = yaml . FullLoader ) search = cfg [ \"search\" ] base = cfg [ \"base\" ] for param in search . keys (): try : start , end = list ( map ( lambda x : int ( x ), search [ param ] . split ( \"-\" ))) grid = range ( start , end ) except ValueError : grid = search [ param ] . split ( \"-\" ) for i , val in enumerate ( grid ): for label in base . keys (): base [ label ] . update ({ param : val }) with open ( os . path . join ( path , filename . replace ( \"search\" , str ( i ))), \"w\" ) as file : yaml . dump ( base , file ) typer . secho ( f \"config files saved in { path } \" , fg = typer . colors . BLUE )","title":"search"},{"location":"API_SEARCH/#patentcity.search.relationship_best","text":"Report perf of each (long)/best (short) config` Parameters: Name Type Description Default path str data file path (wildcard allowed) required report str report type (in [\"short\", \"long\"]) 'short' Usage: patentcity eval relationship-model data/gold_rel_ddpatent01.jsonl rel_ddpatent01.yaml --report json Source code in patentcity/search.py 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 @app . command () def relationship_best ( path : str , report : str = \"short\" ): \"\"\"Report perf of each (long)/best (short) config` Arguments: path: data file path (wildcard allowed) report: report type (in [\"short\", \"long\"]) **Usage:** ```shell patentcity eval relationship-model data/gold_rel_ddpatent01.jsonl rel_ddpatent01.yaml --report json ``` \"\"\" files = glob ( path ) assert report in [ \"short\" , \"long\" ] res = pd . DataFrame () for file in files : tmp = pd . read_json ( file ) . T tmp [ \"config\" ] = os . path . basename ( file ) res = res . append ( tmp ) res = res . reset_index () . rename ( columns = { \"index\" : \"label\" }) labels = [ \"ALL\" ] + list ( RELATIONS . values ()) for i , label in enumerate ( labels ): res_label = res . query ( f \"label==' { label } '\" ) . sort_values ( \"f\" , ascending = False ) if report == \"long\" : if i == 0 : typer . secho ( f \"# Report\" , fg = typer . colors . BLUE ) typer . secho ( f \" \\n ## { label } \" , fg = typer . colors . BLUE ) typer . echo ( res_label . to_markdown ( index = False )) else : if i == 0 : best = pd . DataFrame ( columns = res_label . columns ) best = best . append ( res_label . iloc [: 1 ]) if report == \"short\" : typer . echo ( best . to_markdown ( index = False ))","title":"relationship_best()"},{"location":"API_SEARCH/#patentcity.search.relationship_params","text":"Generate config files defined by config_search grid Parameters: Name Type Description Default config_search str config search file path required Usage: `shell patentcity search relationship-params configs/rel_search.yaml Source code in patentcity/search.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 @app . command () def relationship_params ( config_search : str ): \"\"\"Generate config files defined by `config_search` grid Arguments: config_search: config search file path **Usage:** ```shell patentcity search relationship-params configs/rel_search.yaml `` \"\"\" filename = os . path . basename ( config_search ) path = os . path . dirname ( config_search ) with open ( config_search , \"r\" ) as config_file : cfg = yaml . load ( config_file , Loader = yaml . FullLoader ) search = cfg [ \"search\" ] base = cfg [ \"base\" ] for param in search . keys (): try : start , end = list ( map ( lambda x : int ( x ), search [ param ] . split ( \"-\" ))) grid = range ( start , end ) except ValueError : grid = search [ param ] . split ( \"-\" ) for i , val in enumerate ( grid ): for label in base . keys (): base [ label ] . update ({ param : val }) with open ( os . path . join ( path , filename . replace ( \"search\" , str ( i ))), \"w\" ) as file : yaml . dump ( base , file ) typer . secho ( f \"config files saved in { path } \" , fg = typer . colors . BLUE )","title":"relationship_params()"},{"location":"ASSETS_AREA/","text":"AREA \u00b6 File Source area_xx.csv DE Ros\u00e9s-Wolf database on regional GDP (version 6, 2020) , FR Wikipedia , GB Eurostat , US Fabian Eckert, Andr\u00e9s Gvirtz, Jack Liang, and Michael Peters. \"A Method to Construct Geographical Crosswalks with an Application to US Counties since 1790.\" NBER Working Paper #26770, 2020 Coverage \u00b6 Country Geographical level Time DE 2 (nuts2) 2020 FR 3 (nuts3) 2020 GB 2 (nuts2) 2020 US 2 (commuting zone) 2020 Variables \u00b6 Variable Description Type country_code Country code str statisticalAreaCode Statistical area code (nuts/fips) str statisticalAreaName Statistical area name (literal) str area Area of the statistical area (in kilometers float Focus on GB statistical areas construction Some modern counties are made of a couple of older ones. In this case, we recompose modern counties or use the old name. statisticalAreaName Construction City and County of the City of London County of London (includes the city) Ross and Cromarty Ross-shire Roxburgh, Ettrick and Lauderdale Roxburghshire + Selkirkshire + Berwickshire/4 + Midlothian/4 Ayrshire and Arran South Ayrshire + North Ayrshire + East Ayrshire Tweeddale Peeblesshire Stirling and Falkirk Stirling + Falkirk","title":"Area"},{"location":"ASSETS_AREA/#area","text":"File Source area_xx.csv DE Ros\u00e9s-Wolf database on regional GDP (version 6, 2020) , FR Wikipedia , GB Eurostat , US Fabian Eckert, Andr\u00e9s Gvirtz, Jack Liang, and Michael Peters. \"A Method to Construct Geographical Crosswalks with an Application to US Counties since 1790.\" NBER Working Paper #26770, 2020","title":"AREA"},{"location":"ASSETS_AREA/#coverage","text":"Country Geographical level Time DE 2 (nuts2) 2020 FR 3 (nuts3) 2020 GB 2 (nuts2) 2020 US 2 (commuting zone) 2020","title":"Coverage"},{"location":"ASSETS_AREA/#variables","text":"Variable Description Type country_code Country code str statisticalAreaCode Statistical area code (nuts/fips) str statisticalAreaName Statistical area name (literal) str area Area of the statistical area (in kilometers float Focus on GB statistical areas construction Some modern counties are made of a couple of older ones. In this case, we recompose modern counties or use the old name. statisticalAreaName Construction City and County of the City of London County of London (includes the city) Ross and Cromarty Ross-shire Roxburgh, Ettrick and Lauderdale Roxburghshire + Selkirkshire + Berwickshire/4 + Midlothian/4 Ayrshire and Arran South Ayrshire + North Ayrshire + East Ayrshire Tweeddale Peeblesshire Stirling and Falkirk Stirling + Falkirk","title":"Variables"},{"location":"ASSETS_BORDER/","text":"Border \u00b6 File Source border_xx.csv Mayer, T. & Zignago, S. (2011); Notes on CEPII\u2019s distances measures : the GeoDist Database; CEPII Working Paper 2011-25 Coverage \u00b6 Country Time AUS, AUT, BEL, CAN, CZE, DNK, FRA, DEU, GBR, HUN, ITA, JPN, NLD, POL, RUS, SWE, CHE, USA 2011 Variables \u00b6 Variable Description Type origin_country_code Country code of the origin country str destination_country_code Country code of the destination country str common_border Whether the origin and destination country share a common border bool","title":"Border"},{"location":"ASSETS_BORDER/#border","text":"File Source border_xx.csv Mayer, T. & Zignago, S. (2011); Notes on CEPII\u2019s distances measures : the GeoDist Database; CEPII Working Paper 2011-25","title":"Border"},{"location":"ASSETS_BORDER/#coverage","text":"Country Time AUS, AUT, BEL, CAN, CZE, DNK, FRA, DEU, GBR, HUN, ITA, JPN, NLD, POL, RUS, SWE, CHE, USA 2011","title":"Coverage"},{"location":"ASSETS_BORDER/#variables","text":"Variable Description Type origin_country_code Country code of the origin country str destination_country_code Country code of the destination country str common_border Whether the origin and destination country share a common border bool","title":"Variables"},{"location":"ASSETS_DISTANCE/","text":"Distance \u00b6 File Source distance_xx.csv Mayer, T. & Zignago, S. \"Notes on CEPII's distances measures: the GeoDist Database\". CEPII Working Paper 2011-25 . 2011 Coverage \u00b6 Country Time AUS, AUT, BEL, CAN, CZE, DNK, FRA, DEU, GBR, HUN, ITA, JPN, NLD, POL, RUS, SWE, CHE, USA 2011 Variables \u00b6 Variable Description Type origin_country_code Country code of the origin country str destination_country_code Country code of the destination country str distance Distance between origin country and destination country (in kilometers) float","title":"Distance"},{"location":"ASSETS_DISTANCE/#distance","text":"File Source distance_xx.csv Mayer, T. & Zignago, S. \"Notes on CEPII's distances measures: the GeoDist Database\". CEPII Working Paper 2011-25 . 2011","title":"Distance"},{"location":"ASSETS_DISTANCE/#coverage","text":"Country Time AUS, AUT, BEL, CAN, CZE, DNK, FRA, DEU, GBR, HUN, ITA, JPN, NLD, POL, RUS, SWE, CHE, USA 2011","title":"Coverage"},{"location":"ASSETS_DISTANCE/#variables","text":"Variable Description Type origin_country_code Country code of the origin country str destination_country_code Country code of the destination country str distance Distance between origin country and destination country (in kilometers) float","title":"Variables"},{"location":"ASSETS_EXPORTS/","text":"Exports \u00b6 File Source exports_xx.csv Barbieri, Katherine and Omar M. G. Omar Keshk. 2016. Correlates of War Project Trade Data Set Codebook, Version 4.0. Online: http://correlatesofwar.org. Coverage \u00b6 Country Period AUS, AUT, BEL, CAN, CZE, DNK, FRA, DEU, GBR, HUN, ITA, JPN, NLD, POL, RUS, SWE, CHE, USA 1870-2014 Variables \u00b6 Variable Description Type origin_country_code Country code of the origin country str destination_country_code Country code of the destination country str exports Exports from origin country to destination country (in current US millions of dollars) float","title":"Exports"},{"location":"ASSETS_EXPORTS/#exports","text":"File Source exports_xx.csv Barbieri, Katherine and Omar M. G. Omar Keshk. 2016. Correlates of War Project Trade Data Set Codebook, Version 4.0. Online: http://correlatesofwar.org.","title":"Exports"},{"location":"ASSETS_EXPORTS/#coverage","text":"Country Period AUS, AUT, BEL, CAN, CZE, DNK, FRA, DEU, GBR, HUN, ITA, JPN, NLD, POL, RUS, SWE, CHE, USA 1870-2014","title":"Coverage"},{"location":"ASSETS_EXPORTS/#variables","text":"Variable Description Type origin_country_code Country code of the origin country str destination_country_code Country code of the destination country str exports Exports from origin country to destination country (in current US millions of dollars) float","title":"Variables"},{"location":"ASSETS_GDPPCCOUNTRY/","text":"GDP per capita (country level) \u00b6 File Source gdppccountry_xx.csv Maddison Project Database, version 2020. Bolt, Jutta and Jan Luiten van Zanden (2020), \u201cMaddison style estimates of the evolution of the world economy. A new 2020 update \u201d Coverage \u00b6 Country Period AUS, AUT, BEL, CAN, CZE, DNK, FRA, DEU, GBR, HUN, ITA, JPN, NLD, POL, RUS, SWE, CHE, USA 1870-2018 Variables \u00b6 Variable Description Type country Country str country_code Country code str year Year int gdppc GDP per capita (in 2011 USD) float","title":"GDP per capita"},{"location":"ASSETS_GDPPCCOUNTRY/#gdp-per-capita-country-level","text":"File Source gdppccountry_xx.csv Maddison Project Database, version 2020. Bolt, Jutta and Jan Luiten van Zanden (2020), \u201cMaddison style estimates of the evolution of the world economy. A new 2020 update \u201d","title":"GDP per capita (country level)"},{"location":"ASSETS_GDPPCCOUNTRY/#coverage","text":"Country Period AUS, AUT, BEL, CAN, CZE, DNK, FRA, DEU, GBR, HUN, ITA, JPN, NLD, POL, RUS, SWE, CHE, USA 1870-2018","title":"Coverage"},{"location":"ASSETS_GDPPCCOUNTRY/#variables","text":"Variable Description Type country Country str country_code Country code str year Year int gdppc GDP per capita (in 2011 USD) float","title":"Variables"},{"location":"ASSETS_GDPREG/","text":"Regional GDP \u00b6 File Source gdpreg_xx.csv Ros\u00e9s-Wolf database on regional GDP (version 6, 2020) Coverage \u00b6 Country Geographical level Period DE 2 (nuts2) 1900-2015 FR 3 (nuts3) 1900-2015 GB 2 (nuts2) 1900-2015 Warning US not supported yet Variables \u00b6 Variable Description Type country_code Country code str statisticalAreaCode Statistical area code str statisticalArea Statistical area str year Year int gdp GDP (in 1990 USD) float","title":"Regional GDP"},{"location":"ASSETS_GDPREG/#regional-gdp","text":"File Source gdpreg_xx.csv Ros\u00e9s-Wolf database on regional GDP (version 6, 2020)","title":"Regional GDP"},{"location":"ASSETS_GDPREG/#coverage","text":"Country Geographical level Period DE 2 (nuts2) 1900-2015 FR 3 (nuts3) 1900-2015 GB 2 (nuts2) 1900-2015 Warning US not supported yet","title":"Coverage"},{"location":"ASSETS_GDPREG/#variables","text":"Variable Description Type country_code Country code str statisticalAreaCode Statistical area code str statisticalArea Statistical area str year Year int gdp GDP (in 1990 USD) float","title":"Variables"},{"location":"ASSETS_GDPSHAREAGRICULTURE/","text":"GDP share agriculture \u00b6 File Source gdpshareagriculture_xx.csv Ros\u00e9s-Wolf database on regional GDP (version 6, 2020) Coverage \u00b6 Country Geographical level Period DE 2 (nuts2) 1900-2015 FR 3 (nuts3) 1900-2015 GB 2 (nuts2) 1900-2015 Warning US not supported yet Variables \u00b6 Variable Description Type country_code Country code str statisticalAreaCode Statistical area code str statisticalArea Statistical area str year Year int share_agriculture Share of GDP represented by the agriculture sector (in %) float","title":"Share agriculture"},{"location":"ASSETS_GDPSHAREAGRICULTURE/#gdp-share-agriculture","text":"File Source gdpshareagriculture_xx.csv Ros\u00e9s-Wolf database on regional GDP (version 6, 2020)","title":"GDP share agriculture"},{"location":"ASSETS_GDPSHAREAGRICULTURE/#coverage","text":"Country Geographical level Period DE 2 (nuts2) 1900-2015 FR 3 (nuts3) 1900-2015 GB 2 (nuts2) 1900-2015 Warning US not supported yet","title":"Coverage"},{"location":"ASSETS_GDPSHAREAGRICULTURE/#variables","text":"Variable Description Type country_code Country code str statisticalAreaCode Statistical area code str statisticalArea Statistical area str year Year int share_agriculture Share of GDP represented by the agriculture sector (in %) float","title":"Variables"},{"location":"ASSETS_GDPSHAREINDUSTRY/","text":"GDP share industry \u00b6 File Source gdpshareindustry_xx.csv Ros\u00e9s-Wolf database on regional GDP (version 6, 2020) Coverage \u00b6 Country Geographical level Period DE 2 (nuts2) 1900-2015 FR 3 (nuts3) 1900-2015 GB 2 (nuts2) 1900-2015 Warning US not supported yet Variables \u00b6 Variable Description Type country_code Country code str statisticalAreaCode Statistical area code str statisticalArea Statistical area str year Year int share_industry Share of GDP represented by the industry sector (in %) float","title":"Share industry"},{"location":"ASSETS_GDPSHAREINDUSTRY/#gdp-share-industry","text":"File Source gdpshareindustry_xx.csv Ros\u00e9s-Wolf database on regional GDP (version 6, 2020)","title":"GDP share industry"},{"location":"ASSETS_GDPSHAREINDUSTRY/#coverage","text":"Country Geographical level Period DE 2 (nuts2) 1900-2015 FR 3 (nuts3) 1900-2015 GB 2 (nuts2) 1900-2015 Warning US not supported yet","title":"Coverage"},{"location":"ASSETS_GDPSHAREINDUSTRY/#variables","text":"Variable Description Type country_code Country code str statisticalAreaCode Statistical area code str statisticalArea Statistical area str year Year int share_industry Share of GDP represented by the industry sector (in %) float","title":"Variables"},{"location":"ASSETS_GDPSHARESERVICE/","text":"GDP share service \u00b6 File Source gdpshareservice_xx.csv Ros\u00e9s-Wolf database on regional GDP (version 6, 2020) Coverage \u00b6 Country Geographical level Period DE 2 (nuts2) 1900-2015 FR 3 (nuts3) 1900-2015 GB 2 (nuts2) 1900-2015 Warning US not supported yet Variables \u00b6 Variable Description Type country_code Country code str statisticalAreaCode Statistical area code str statisticalArea Statistical area str year Year int share_service Share of GDP represented by the service sector (in %) float","title":"Share service"},{"location":"ASSETS_GDPSHARESERVICE/#gdp-share-service","text":"File Source gdpshareservice_xx.csv Ros\u00e9s-Wolf database on regional GDP (version 6, 2020)","title":"GDP share service"},{"location":"ASSETS_GDPSHARESERVICE/#coverage","text":"Country Geographical level Period DE 2 (nuts2) 1900-2015 FR 3 (nuts3) 1900-2015 GB 2 (nuts2) 1900-2015 Warning US not supported yet","title":"Coverage"},{"location":"ASSETS_GDPSHARESERVICE/#variables","text":"Variable Description Type country_code Country code str statisticalAreaCode Statistical area code str statisticalArea Statistical area str year Year int share_service Share of GDP represented by the service sector (in %) float","title":"Variables"},{"location":"ASSETS_IMMIGRATION/","text":"Immigration \u00b6 File Source immigration_us.csv US census immigrationbyorigin_us.csv US census Coverage \u00b6 Country Geographical level Period US 0(country) 1850-2000 Variables \u00b6 immigration Variable Description Type name Name of the origin country/region str year Year int value Value float immigrationbyorigin Variable Description Type region Region str level Geographical level of the entity defined by name . 1 : Countries, 2 : Country groups, 3 :United Kingdom, 4 : Other regions, 5 : European regions, 6 : Continental areas, 7 : Continent, 8 :Subtotals, 9 : Total, \"n.e.c.\" Not elsewhere classified (e.g. Europe) int year Year int immigrants Number of immigrants (in units) float Focus Geographical levels: The table from census.gov proposes different scales. We add a column level to specify the geographical level at which a given entry is defined. Wales: Wales unitary authorities are an aggregation of districts made using wikipedia historical data.","title":"Immigration"},{"location":"ASSETS_IMMIGRATION/#immigration","text":"File Source immigration_us.csv US census immigrationbyorigin_us.csv US census","title":"Immigration"},{"location":"ASSETS_IMMIGRATION/#coverage","text":"Country Geographical level Period US 0(country) 1850-2000","title":"Coverage"},{"location":"ASSETS_IMMIGRATION/#variables","text":"immigration Variable Description Type name Name of the origin country/region str year Year int value Value float immigrationbyorigin Variable Description Type region Region str level Geographical level of the entity defined by name . 1 : Countries, 2 : Country groups, 3 :United Kingdom, 4 : Other regions, 5 : European regions, 6 : Continental areas, 7 : Continent, 8 :Subtotals, 9 : Total, \"n.e.c.\" Not elsewhere classified (e.g. Europe) int year Year int immigrants Number of immigrants (in units) float Focus Geographical levels: The table from census.gov proposes different scales. We add a column level to specify the geographical level at which a given entry is defined. Wales: Wales unitary authorities are an aggregation of districts made using wikipedia historical data.","title":"Variables"},{"location":"ASSETS_IMPORTS/","text":"Imports \u00b6 File Source imports_xx.csv Barbieri, Katherine and Omar M. G. Omar Keshk. 2016. Correlates of War Project Trade Data Set Codebook, Version 4.0. Online: http://correlatesofwar.org. Coverage \u00b6 Country Period AUS, AUT, BEL, CAN, CZE, DNK, FRA, DEU, GBR, HUN, ITA, JPN, NLD, POL, RUS, SWE, CHE, USA 1870-2014 Variables \u00b6 Variable Description Type origin_country_code Country code of the origin country str destination_country_code Country code of the destination country str exports Imports from origin country to destination country (in current US millions of dollars) float","title":"Imports"},{"location":"ASSETS_IMPORTS/#imports","text":"File Source imports_xx.csv Barbieri, Katherine and Omar M. G. Omar Keshk. 2016. Correlates of War Project Trade Data Set Codebook, Version 4.0. Online: http://correlatesofwar.org.","title":"Imports"},{"location":"ASSETS_IMPORTS/#coverage","text":"Country Period AUS, AUT, BEL, CAN, CZE, DNK, FRA, DEU, GBR, HUN, ITA, JPN, NLD, POL, RUS, SWE, CHE, USA 1870-2014","title":"Coverage"},{"location":"ASSETS_IMPORTS/#variables","text":"Variable Description Type origin_country_code Country code of the origin country str destination_country_code Country code of the destination country str exports Imports from origin country to destination country (in current US millions of dollars) float","title":"Variables"},{"location":"ASSETS_LANGUAGE/","text":"Language \u00b6 File Source language_xx.csv Mayer, T. & Zignago, S. (2011); Notes on CEPII\u2019s distances measures : the GeoDist Database; CEPII Working Paper 2011-25 Coverage \u00b6 Country Time AUS, AUT, BEL, CAN, CZE, DNK, FRA, DEU, GBR, HUN, ITA, JPN, NLD, POL, RUS, SWE, CHE, USA 2011 Variables \u00b6 Variable Description Type origin_country_code Country code of the origin country str destination_country_code Country code of the destination country str common_language Whether the origin and destination country share a common language bool","title":"Language"},{"location":"ASSETS_LANGUAGE/#language","text":"File Source language_xx.csv Mayer, T. & Zignago, S. (2011); Notes on CEPII\u2019s distances measures : the GeoDist Database; CEPII Working Paper 2011-25","title":"Language"},{"location":"ASSETS_LANGUAGE/#coverage","text":"Country Time AUS, AUT, BEL, CAN, CZE, DNK, FRA, DEU, GBR, HUN, ITA, JPN, NLD, POL, RUS, SWE, CHE, USA 2011","title":"Coverage"},{"location":"ASSETS_LANGUAGE/#variables","text":"Variable Description Type origin_country_code Country code of the origin country str destination_country_code Country code of the destination country str common_language Whether the origin and destination country share a common language bool","title":"Variables"},{"location":"ASSETS_POPULATION/","text":"Population \u00b6 File Source(s) population_xx.csv DE: Ros\u00e9s-Wolf database on regional GDP (version 6, 2020) , FR: INSEE , GB: Vision of Britain (pre 1981) & ONS (post 1981) & Wiki (Northern Ireland) and Census (London), US: Fabian Eckert, Andr\u00e9s Gvirtz, Jack Liang, and Michael Peters. \"A Method to Construct Geographical Crosswalks with an Application to US Counties since 1790.\" NBER Working Paper #26770, 2020 Coverage \u00b6 Country Geographical level Period DE 2 (nuts2) 1900-2015 FR 3 (nuts3) 1876-2018 GB 2 (nuts2) 1851-2019 US 2 (commuting zone) 1830-2000 Variables \u00b6 Variable Description Type country_code Country code str statisticalAreaCode Statistical area code (nuts/fips) str statisticalAreaName Statistical area name (literal) str year Year int population Population in the statistical area (in thousands) float population_raw Population in the statistical area before correction (in thousands). Relevant for GB only (see notes below) float Focus on GB data GB population data are not available at a sufficiently detailed NUTS level over long period - at least we did not find it. For instance, Ros\u00e9s and Wolf (2020) only provides data at the NUTS1 level for GB. Hence, we had to build the population data for GB at the NUTS2 level ourselves. This includes 3 main stages: 1. Pre-1981 data collection, 2. Post-1981 data collection, 3. Data harmonization Pre-1981 data collection : We use Vision of Britain (VoB) population data, except for London where we use data from the Census. Some VoB geographic entities have no population data though. In this case, we made our best to reconstitute the data from smaller entities with known population data. Below we detail the contruction of these entities VoB Construction Tweeddale Peebles+Selkirkshire Roxburgh Ettrick and Lauderdale Roxburghshire + Selkirkshire + Berwickshire/4 + Midlothian/4 Cheshire Halton + Warrington + Cheshire east + Cheshire West and Chester Mid Glamorgan Caerphilly/2 + Bridgend + Merthyr Tydfil + Rhondda; Cynon; Taff South Glamorgan Vale of Glamorgan + Cardiff Clwyd Flintshire + Wrexham + Denbighshire Dyfed Carmarthenshire + Ceredigion + Pembrokeshire Gwent Blaenau Gwent + Caerphilly/2 + Monmouthshire + Newport + Torfaen Vale of Glamorgan Glamorganshire Missing VoB data (concentrated in 1871, 1901 and 1941) are filled with linear interpolation. Once we have data for all VoB entities (real or imputed), we caggregate them to obtain population data at the NUTS2 level using the conversion table reported in statisticalareasvob_gb.csv . Post-1981 data collection After 1981, the ONS provides data at the local authority level for each year. Same as before, we aggregate them to obtain population data at the NUTS2 level using the conversion table reported in [XX]. The conversion table is based on the local authority to NUTS crossover table and the Scotish Review of NUTS boundaries . Data harmonization As pre-1981 data are constructed using a collection of sources creating potential flaws or approximations. Hence, we found it desirable to compare the two datasets in 1981 (the only year of overlap) to compute a correction coefficient obtained as \\(\\frac{population~in~1981~using~ONS~data_{NUTS2}}{population~in~1981~using~VoB~data_{NUTS2}}\\) . We then apply this correction coefficient to all pre-1981 data to make sure that the time series is consistent for each NUTS2 despite the data source change. Note that for East Wales and Scotland, 1981 (and 1971 for East Wales) data are missing from VoB. We used the 1971 data and applied the national population growth rate to (roughly) estimate the VoB data and hence the correction coefficient.","title":"Population"},{"location":"ASSETS_POPULATION/#population","text":"File Source(s) population_xx.csv DE: Ros\u00e9s-Wolf database on regional GDP (version 6, 2020) , FR: INSEE , GB: Vision of Britain (pre 1981) & ONS (post 1981) & Wiki (Northern Ireland) and Census (London), US: Fabian Eckert, Andr\u00e9s Gvirtz, Jack Liang, and Michael Peters. \"A Method to Construct Geographical Crosswalks with an Application to US Counties since 1790.\" NBER Working Paper #26770, 2020","title":"Population"},{"location":"ASSETS_POPULATION/#coverage","text":"Country Geographical level Period DE 2 (nuts2) 1900-2015 FR 3 (nuts3) 1876-2018 GB 2 (nuts2) 1851-2019 US 2 (commuting zone) 1830-2000","title":"Coverage"},{"location":"ASSETS_POPULATION/#variables","text":"Variable Description Type country_code Country code str statisticalAreaCode Statistical area code (nuts/fips) str statisticalAreaName Statistical area name (literal) str year Year int population Population in the statistical area (in thousands) float population_raw Population in the statistical area before correction (in thousands). Relevant for GB only (see notes below) float Focus on GB data GB population data are not available at a sufficiently detailed NUTS level over long period - at least we did not find it. For instance, Ros\u00e9s and Wolf (2020) only provides data at the NUTS1 level for GB. Hence, we had to build the population data for GB at the NUTS2 level ourselves. This includes 3 main stages: 1. Pre-1981 data collection, 2. Post-1981 data collection, 3. Data harmonization Pre-1981 data collection : We use Vision of Britain (VoB) population data, except for London where we use data from the Census. Some VoB geographic entities have no population data though. In this case, we made our best to reconstitute the data from smaller entities with known population data. Below we detail the contruction of these entities VoB Construction Tweeddale Peebles+Selkirkshire Roxburgh Ettrick and Lauderdale Roxburghshire + Selkirkshire + Berwickshire/4 + Midlothian/4 Cheshire Halton + Warrington + Cheshire east + Cheshire West and Chester Mid Glamorgan Caerphilly/2 + Bridgend + Merthyr Tydfil + Rhondda; Cynon; Taff South Glamorgan Vale of Glamorgan + Cardiff Clwyd Flintshire + Wrexham + Denbighshire Dyfed Carmarthenshire + Ceredigion + Pembrokeshire Gwent Blaenau Gwent + Caerphilly/2 + Monmouthshire + Newport + Torfaen Vale of Glamorgan Glamorganshire Missing VoB data (concentrated in 1871, 1901 and 1941) are filled with linear interpolation. Once we have data for all VoB entities (real or imputed), we caggregate them to obtain population data at the NUTS2 level using the conversion table reported in statisticalareasvob_gb.csv . Post-1981 data collection After 1981, the ONS provides data at the local authority level for each year. Same as before, we aggregate them to obtain population data at the NUTS2 level using the conversion table reported in [XX]. The conversion table is based on the local authority to NUTS crossover table and the Scotish Review of NUTS boundaries . Data harmonization As pre-1981 data are constructed using a collection of sources creating potential flaws or approximations. Hence, we found it desirable to compare the two datasets in 1981 (the only year of overlap) to compute a correction coefficient obtained as \\(\\frac{population~in~1981~using~ONS~data_{NUTS2}}{population~in~1981~using~VoB~data_{NUTS2}}\\) . We then apply this correction coefficient to all pre-1981 data to make sure that the time series is consistent for each NUTS2 despite the data source change. Note that for East Wales and Scotland, 1981 (and 1971 for East Wales) data are missing from VoB. We used the 1971 data and applied the national population growth rate to (roughly) estimate the VoB data and hence the correction coefficient.","title":"Variables"},{"location":"CHEATSHEET/","text":"CHEATSHEET \u00b6 Compressing prodigy gold .jsonl (from prodigy db-out ) \u00b6 Info When exporting ENT annotated data using prodigy db-out <dataset> , annotations belonging to the same text are not merged, causing issues when you want to use the data for another task (e.g. correction or REL annotation). The below recipe takes care to do the merge. FILE = \"\" # should be a .jsonl mv ${ FILE } ${ FILE } _tmp && cat ${ FILE } _tmp | grep -v '\"spans\":\\[\\]' | grep spans | jq -s -c 'group_by(.publication_number)[] | { publication_number: .[0].publication_number, text: .[0].text, tokens: .[0].tokens, spans:[.[].spans[]]}' >> ${ FILE } Head-child switch \u00b6 Info Original REL arc labelling convention went from attributes (e.g. LOC , CIT , OCC ) to patentees ( ASG , INV ), which was counter-intuitive in terms of head / child and performance metrics (although) tractable. The below recipe makes the switch between head and child to make downstream REL handling easier. for file in $( ls gold_rel_*.jsonl ) ; do sed 's/\\\"child/$tmp/g;s/\\\"head/\\\"child/g;s/$tmp/\\\"head/g' ${ file } >> ${ file } _corr ; done ; Parallel models training \u00b6 Info Training models takes time, it's better to train them in parallel. Don't start too many jobs at once. On a mac mini,each job takes up to 2 CPUs. LANG = de # support for en fr OFFICE = de # support dd fr gb us cat lib/format.txt | grep $OFFICE | parallel -j 2 --eta 'spacy train configs/${LANG}_t2vner.cfg --paths.train data/train_ent_{}.spacy --paths.dev data/train_ent_{}.spacy --output models/${LANG}_ent_{}' Extract sample for kepler \u00b6 OFFICE = \"\" # e.g. DD, DE, etc RATIO = # e.g. .2, .015 patentcity io extract-sample-kepler patentcity.patentcity.pc_v100rc1 data_tmp/sample_ ${ OFFICE } .csv --sample-ratio ${ RATIO } --office ${ OFFICE } --key-file credentials-patentcity.json","title":"Cheatsheet"},{"location":"CHEATSHEET/#cheatsheet","text":"","title":"CHEATSHEET"},{"location":"CHEATSHEET/#compressing-prodigy-gold-jsonl-from-prodigy-db-out","text":"Info When exporting ENT annotated data using prodigy db-out <dataset> , annotations belonging to the same text are not merged, causing issues when you want to use the data for another task (e.g. correction or REL annotation). The below recipe takes care to do the merge. FILE = \"\" # should be a .jsonl mv ${ FILE } ${ FILE } _tmp && cat ${ FILE } _tmp | grep -v '\"spans\":\\[\\]' | grep spans | jq -s -c 'group_by(.publication_number)[] | { publication_number: .[0].publication_number, text: .[0].text, tokens: .[0].tokens, spans:[.[].spans[]]}' >> ${ FILE }","title":"Compressing prodigy gold .jsonl (from prodigy db-out)"},{"location":"CHEATSHEET/#head-child-switch","text":"Info Original REL arc labelling convention went from attributes (e.g. LOC , CIT , OCC ) to patentees ( ASG , INV ), which was counter-intuitive in terms of head / child and performance metrics (although) tractable. The below recipe makes the switch between head and child to make downstream REL handling easier. for file in $( ls gold_rel_*.jsonl ) ; do sed 's/\\\"child/$tmp/g;s/\\\"head/\\\"child/g;s/$tmp/\\\"head/g' ${ file } >> ${ file } _corr ; done ;","title":"Head-child switch"},{"location":"CHEATSHEET/#parallel-models-training","text":"Info Training models takes time, it's better to train them in parallel. Don't start too many jobs at once. On a mac mini,each job takes up to 2 CPUs. LANG = de # support for en fr OFFICE = de # support dd fr gb us cat lib/format.txt | grep $OFFICE | parallel -j 2 --eta 'spacy train configs/${LANG}_t2vner.cfg --paths.train data/train_ent_{}.spacy --paths.dev data/train_ent_{}.spacy --output models/${LANG}_ent_{}'","title":"Parallel models training"},{"location":"CHEATSHEET/#extract-sample-for-kepler","text":"OFFICE = \"\" # e.g. DD, DE, etc RATIO = # e.g. .2, .015 patentcity io extract-sample-kepler patentcity.patentcity.pc_v100rc1 data_tmp/sample_ ${ OFFICE } .csv --sample-ratio ${ RATIO } --office ${ OFFICE } --key-file credentials-patentcity.json","title":"Extract sample for kepler"},{"location":"DATA/","text":"DATA \u00b6 The patentCity database is publicly available (CC-BY-4). Download patentCity database If you use the data, please cite Bergeaud and Verluise (2021) and De Rassenfosse, Kozak and Seliger (2019) BibTeX @techreport { bergeaudVerluise2021, title={ } , author= { Bergeaud, Antonin and Verluise, Cyril } , year= { 2021 } } @article { deRassenfosse2019, title={Geocoding of worldwide patent data } , author= { De Rassenfosse, Ga{\\'e } tan and Kozak, Jan and Seliger, Florian}, journal= { Scientific data } , volume= { 6 } , number= { 1 } , pages= { 1--15 } , year= { 2019 } , publisher= { Nature Publishing Group } } Chicago Bergeaud, Antonin and Cyril Verluise. \"\". 2021 De Rassenfosse, Gaetan, Jan Kozak, and Florian Seliger. \"Geocoding of worldwide patent data.\" Scientific data 6, no. 1 (2019): 1-15.","title":"Data"},{"location":"DATA/#data","text":"The patentCity database is publicly available (CC-BY-4). Download patentCity database If you use the data, please cite Bergeaud and Verluise (2021) and De Rassenfosse, Kozak and Seliger (2019) BibTeX @techreport { bergeaudVerluise2021, title={ } , author= { Bergeaud, Antonin and Verluise, Cyril } , year= { 2021 } } @article { deRassenfosse2019, title={Geocoding of worldwide patent data } , author= { De Rassenfosse, Ga{\\'e } tan and Kozak, Jan and Seliger, Florian}, journal= { Scientific data } , volume= { 6 } , number= { 1 } , pages= { 1--15 } , year= { 2019 } , publisher= { Nature Publishing Group } } Chicago Bergeaud, Antonin and Cyril Verluise. \"\". 2021 De Rassenfosse, Gaetan, Jan Kozak, and Florian Seliger. \"Geocoding of worldwide patent data.\" Scientific data 6, no. 1 (2019): 1-15.","title":"DATA"},{"location":"DD/","text":"OVERVIEW \u00b6 Background \u00b6 XX \ud83d\udcda Data \u00b6 Warning Between 1973 and 1976, patent images are missing (meaning no data at all). Patent office Time span (publication year) Kind code(s) DD 1950-1992 A, A1, A3, B Publication number (range) Data source Pre-processing E.g. Format # DD1-DD123499 Espacenet OCR DD20903A 1 DD123500-... Espacenet OCR DD142651A1 2 Done In total, we consider XX documents from 1950 to 1992. \ud83d\ude9c Extraction schema \u00b6 See the annotation guidelines . \ud83d\udd2e Models \u00b6 See the models card . Other \u00b6 See the geocoding , citizenship and date imputation documentation.","title":"Overview"},{"location":"DD/#overview","text":"","title":"OVERVIEW"},{"location":"DD/#background","text":"XX","title":"Background"},{"location":"DD/#data","text":"Warning Between 1973 and 1976, patent images are missing (meaning no data at all). Patent office Time span (publication year) Kind code(s) DD 1950-1992 A, A1, A3, B Publication number (range) Data source Pre-processing E.g. Format # DD1-DD123499 Espacenet OCR DD20903A 1 DD123500-... Espacenet OCR DD142651A1 2 Done In total, we consider XX documents from 1950 to 1992.","title":"\ud83d\udcda Data"},{"location":"DD/#extraction-schema","text":"See the annotation guidelines .","title":"\ud83d\ude9c Extraction schema"},{"location":"DD/#models","text":"See the models card .","title":"\ud83d\udd2e Models"},{"location":"DD/#other","text":"See the geocoding , citizenship and date imputation documentation.","title":"Other"},{"location":"DD_ANNOTATION_GUIDELINES/","text":"ANNOTATION GUIDELINES \u00b6 Warning GitHub markdown does not fully support visual annotation components (e.g. entity boxes) used below. We invite user interested in the annotation guidelines to download the documents and open it in a development environment supporting extended markdown syntax (e.g. MacDown, PyCharm, etc) and/or save it as a pdf. Preliminary comments \u00b6 The patent corpus we consider for East Germany (the German Democratic Republic) has 2 format categories and spans the period 1950-1992. Format 1 , from to DD1 to DD123499. \u00b6 This format spans the period 1951-1976. Information display \u00b6 The document has a header with its publication number (\" Patentschrift Nr \"). The assignee is referred to as \" Inhaber \" while the inventor is referred to as \" Erfinder \". When the same person is both the assignee and the inventor, he might referred to as \" Erfinder zugleich Inhaber \". Well often, a geographical indication is given with the name of the assignee or the inventor. Typically, this is the name of a city ( e.g Leipzig). It can be followed by the name of the country (especially when the latter is not Germany). The name of the city is not always given though ( cf DD79836). Within this format, some minor changes occur over time. For instance, the specifically German technological class is reported up until patent DD117152, after which only the international class (IPC) is reported on the document. Some patents will have a body of text in their first page, while others don't, but information we are interested in will always be in the header. Information extraction \u00b6 We extract 4 different \"entities\" from the header of DD patents in format category 1. Entity Content E.g ASG Assignee full name Inhaber: Rh\u00f4ne Poulenc S.A ASG , Paris (Frankreich). INV Inventor full name ( Erfinder ) Erfinder: Dr. Karl Jellinek INV , WD LOC Location of the assignee/inventor Erfinder: Jean Auguste Phelisse, Lyon (Frankreich) LOC . OCC Occupation of the assignee/inventor (academic title) Dr. OCC Elisabeth Kob, WD. These entities are tied together with 2 types of relations. Relation Content E.g. LOCATION Links an ASG / INV to a LOC Rh\u00f4ne Poulenc S.A ASG --> LOCATION --> Paris (Frankreich) LOC OCCUPATION Links an ASG / INV to an OCC Dr OCC <-- OCCUPATION <-- Elisabeth Kob ASG Format 2 , from DD123500 onwards. \u00b6 Information display \u00b6 In this new format, relevant information are given in slots associated with a number. For instance, the number 51 announces the (CPC) international technological class of the invention. The number 54 gives the title of the invention. The number 72 announces information about the inventor: identity and geographical information. The number 44 indicates the publication date. The number 71 announces the applicant/assignee but sometimes refers to another slot to signal that this particular slot already contains the name of the applicant ( e.g , DD126868, DD126858). In particular, a foreign assignee is more likely to be reported in line 73. Line 74 contains the name (and well often, the location) of the legal representative, which we do not tag. Information extraction \u00b6 We extract 4 different \"entities\" from the header of DD patents in format category 2. Entity Content E.g ASG Assignee full name Maschinenfabrik K\u00f6ppern GmbH & Co KG ASG , Hattingen, DE INV Inventor full name ( Erfinder ) (72) Bergendahl, Hans-Georg INV , DE LOC Location of the assignee/inventor Knieling, Norbert, Dipl-Phys., 12439 Berlin, DE LOC . OCC Occupation of the assignee/inventor (academic title) Knieling, Norbert, Dipl-Phys. OCC , 12439 Berlin, DE. These entities are tied together with 2 types of relations. Relation Content E.g. LOCATION Links an ASG / INV to a LOC Maschinenfabrik K\u00f6ppern GmbH & Co KG ASG --> LOCATION --> Hattingen, DE LOC OCCUPATION Links an ASG / INV to an OCC L\u00e4mmer, Hans-Georg ASG --> OCCUPATION --> Dipl-Ing. OCC Entities \u00b6 Format 1 \u00b6 INV \u00b6 General case \u00b6 The tag INV refers to the full name of an inventor. This is a person that is not referred to as the assignee and is specifically referred to as the inventor ( Erfinder ). Specific cases \u00b6 Inventor only : some early patents report an inventor but no assignee. We tag the inventor as it is mentioned nonetheless. See example 2. Secret inventor : in some patents, it is specifically mentioned that the inventor remains anonymous. In this case, we do not tag anything. See example 3. Inventor=Assignee : sometimes, the inventor and the assignee are the same person and the document won't repeat the name; this may be signalled by the phrase \" Erfinder zugleich Inhaber \". In this case, we tag the name only as the inventor, because a single group of words cannot be tagged twice. See example 4. Examples Standard Case with a person, from patent DD79836 Erfinder: Wilhelm Uhrig INV , WD Inventor only , from patent DD5076 Erfinder: Dr ALEXANDER PRANSCHKE INV , Schwarzheide. Dr ERWIN SAUTER INV , Schwarzheide. Inventor only , from patent DD4075 Erfinderbenennung ist ausgesetzt. Inventor=Assignee , from patent DD15399 Erfinder zugleich Inhaber: Zalter Glei\u00dfner INV , Wei\u00dfenfeis (Saale) ASG \u00b6 General case \u00b6 The tag ASG refers to the full name(s) of the person(s) or firm(s) who own(s) the patent rights. Specific cases \u00b6 Rechtstr\u00e4ger : Some patents distinguish between Inhaber and Rechtstr\u00e4ger : we keep tagging the Inhaber person as the assignee. See example 2. Examples Standard Case with a firm, from patent DD79836 Inhaber: Dr. Plate GmbH ASG , Bonn, WD. Rechtstr\u00e4ger , from patent DD33554 Erfinder: Manfred Gerlach, Dresden; Kurt J\u00e4ger, Dresden; Dipl-Ing. Gerhard Kasche, Dresden. Inhaber: Eigentum des Volkes ASG ; Kurt J\u00e4ger ASG , Dresden; Dipl-Ing. Gerhard Kasche ASG , Dresden. Rechtstr\u00e4ger: VEB Gasturbinenbau und Energiemaschinenentwicklung Pirna, Pirna. LOC \u00b6 General case \u00b6 The tag LOC refers to the full location sequence of an assignee or inventor. In some patents, no location is reported (see DD86584). Specific cases \u00b6 District : The patents might report the district within a given city, which we tag along. See example 3. Examples Standard Case with a location for the (foreign) assignee and a location for the (foreign) inventor, from patent DD76817 Erfinder: Abraham A.Goldberg, USA LOC . Inhaber: COLUMBIA BROADCASTING SYSTEM, INC., New York, USA LOC . Standard Case with German patentees, from patent DD69242 Erfinder: Dr-Ing. Walter Froede, Neckarsulm (WD) LOC . Inhaber: NSU-Motorenwenke AG, Neckarsulm (WD) LOC Wandel GmbH, Lindau (WD) LOC District from patent DD62143 Erfinder zugleich Inhaber: Dr. Wolfram Jenichen, Sch\u00f6now (b. Berlin) LOC . OCC \u00b6 General case \u00b6 This tag concerns the university title of inventors/assignees. When none is reported, we do not tag anything. Examples Standard Case with several inventors from patent DD1393 Erfinder: Dr. OCC GERHARD HANSEN, Dr OCC PAUL HEINZ KECK, Jena. Dipl.-Ing. OCC KARL ILMER, Jena. Format 2 \u00b6 INV \u00b6 General case \u00b6 The tag INV refers to the full name of an inventor. This is a person that is not referred to as the assignee and is specifically referred to as the inventor ( Erfinder ). Specific cases \u00b6 Secret inventor : some publications do not report the name of the inventor on purpose. This may be signalled by the sentence \" Erfinder: werden aug Antrag nicht genannt \". See example 2. Inventor=Assignee : sometimes, the inventor and the assignee are the same person and the document won't repeat the name; this may be signalled by the phrase \" siehe (72) \" in line 71 (where the assignee should be). In this case, we tag the name only as the inventor, because a single group of words cannot be tagged twice. See example 3. Examples Standard Case with several inventors, from patent DD251362 (72) Kolitsch, Andreas INV , Dr.; Richter, Edgar INV , Dr.; Mende, Edgar INV ; Polnik, Frank INV , DD Secret inventor , from patent DD126770 Erfinder: werden aug Antrag nicht genannt Inventor=Assignee , from patent DD148904 (71) siehe (72). (72) Trabert, Erich INV , DD ASG \u00b6 General case \u00b6 The tag ASG refers to the full name(s) of the person(s) or firm(s) who own(s) the patent rights. Specific cases \u00b6 Foreign Assignee : When the assignee is non-German, it might be reported in line (73) instead of (71). See example 2. Examples Standard Case with a government-run company, from patent DD133115 (71) Akademie der Wissenschaften der DDR, Zentralinstitut for Isotopen- und Strahlenforschung ASG , Leipzig , DD Foreign Assignee , from patent DD202259 (71) siehe (73) (73) ITERA COMPONENTS AB ASG , GOETEBORG, SE LOC \u00b6 General case \u00b6 The tag LOC refers to the full location sequence of an assignee or inventor. Typically, only the country will be reported for inventors, but greater details may be given for assignees. Here are a few abbreviations that are used throughout the patents. SU: Soviet Union HU: Hungary CS: Tchecoslovaquia BG: Bulgaria WD: West-Germany. Specific cases \u00b6 Full Address : There is quite a number of Format 2 patents which report the full address of an assignee or inventor, and in this case we tag it all. See example 2. Examples Standard Case with the country and the city from patent DD141623 (71) Akademie der Wissenschaften der DDR, Berlin, DD LOC . Full Address from patent DD251362 (71) Akademie der Wissenschaften der DDR, Otto-Nuschke Stra\u00dfe 22/23, Berlin 1080, DD LOC . OCC \u00b6 General case \u00b6 This tag concerns the university title of inventors/assignees. When none is reported, we do not tag anything. Examples Standard Case with several inventors from patent DD220001 (72): L\u00e4mmer, Hans-Georg, Ing-Dipl. OCC ; Sommer, Peter; Matzner, Dieter, Dipl-Ing. OCC , DD. Relationships \u00b6 See the common annotation guidelines . Examples \u00b6 Example 1: Format 1 (DD-1300) \u00b6 Example 2: Format 2 (DD-142651) \u00b6","title":"Annotation Guidelines"},{"location":"DD_ANNOTATION_GUIDELINES/#annotation-guidelines","text":"Warning GitHub markdown does not fully support visual annotation components (e.g. entity boxes) used below. We invite user interested in the annotation guidelines to download the documents and open it in a development environment supporting extended markdown syntax (e.g. MacDown, PyCharm, etc) and/or save it as a pdf.","title":"ANNOTATION GUIDELINES"},{"location":"DD_ANNOTATION_GUIDELINES/#preliminary-comments","text":"The patent corpus we consider for East Germany (the German Democratic Republic) has 2 format categories and spans the period 1950-1992.","title":"Preliminary comments"},{"location":"DD_ANNOTATION_GUIDELINES/#format-1-from-to-dd1-to-dd123499","text":"This format spans the period 1951-1976.","title":"Format 1, from to DD1 to DD123499."},{"location":"DD_ANNOTATION_GUIDELINES/#information-display","text":"The document has a header with its publication number (\" Patentschrift Nr \"). The assignee is referred to as \" Inhaber \" while the inventor is referred to as \" Erfinder \". When the same person is both the assignee and the inventor, he might referred to as \" Erfinder zugleich Inhaber \". Well often, a geographical indication is given with the name of the assignee or the inventor. Typically, this is the name of a city ( e.g Leipzig). It can be followed by the name of the country (especially when the latter is not Germany). The name of the city is not always given though ( cf DD79836). Within this format, some minor changes occur over time. For instance, the specifically German technological class is reported up until patent DD117152, after which only the international class (IPC) is reported on the document. Some patents will have a body of text in their first page, while others don't, but information we are interested in will always be in the header.","title":"Information display"},{"location":"DD_ANNOTATION_GUIDELINES/#information-extraction","text":"We extract 4 different \"entities\" from the header of DD patents in format category 1. Entity Content E.g ASG Assignee full name Inhaber: Rh\u00f4ne Poulenc S.A ASG , Paris (Frankreich). INV Inventor full name ( Erfinder ) Erfinder: Dr. Karl Jellinek INV , WD LOC Location of the assignee/inventor Erfinder: Jean Auguste Phelisse, Lyon (Frankreich) LOC . OCC Occupation of the assignee/inventor (academic title) Dr. OCC Elisabeth Kob, WD. These entities are tied together with 2 types of relations. Relation Content E.g. LOCATION Links an ASG / INV to a LOC Rh\u00f4ne Poulenc S.A ASG --> LOCATION --> Paris (Frankreich) LOC OCCUPATION Links an ASG / INV to an OCC Dr OCC <-- OCCUPATION <-- Elisabeth Kob ASG","title":"Information extraction"},{"location":"DD_ANNOTATION_GUIDELINES/#format-2-from-dd123500-onwards","text":"","title":"Format 2, from DD123500 onwards."},{"location":"DD_ANNOTATION_GUIDELINES/#information-display_1","text":"In this new format, relevant information are given in slots associated with a number. For instance, the number 51 announces the (CPC) international technological class of the invention. The number 54 gives the title of the invention. The number 72 announces information about the inventor: identity and geographical information. The number 44 indicates the publication date. The number 71 announces the applicant/assignee but sometimes refers to another slot to signal that this particular slot already contains the name of the applicant ( e.g , DD126868, DD126858). In particular, a foreign assignee is more likely to be reported in line 73. Line 74 contains the name (and well often, the location) of the legal representative, which we do not tag.","title":"Information display"},{"location":"DD_ANNOTATION_GUIDELINES/#information-extraction_1","text":"We extract 4 different \"entities\" from the header of DD patents in format category 2. Entity Content E.g ASG Assignee full name Maschinenfabrik K\u00f6ppern GmbH & Co KG ASG , Hattingen, DE INV Inventor full name ( Erfinder ) (72) Bergendahl, Hans-Georg INV , DE LOC Location of the assignee/inventor Knieling, Norbert, Dipl-Phys., 12439 Berlin, DE LOC . OCC Occupation of the assignee/inventor (academic title) Knieling, Norbert, Dipl-Phys. OCC , 12439 Berlin, DE. These entities are tied together with 2 types of relations. Relation Content E.g. LOCATION Links an ASG / INV to a LOC Maschinenfabrik K\u00f6ppern GmbH & Co KG ASG --> LOCATION --> Hattingen, DE LOC OCCUPATION Links an ASG / INV to an OCC L\u00e4mmer, Hans-Georg ASG --> OCCUPATION --> Dipl-Ing. OCC","title":"Information extraction"},{"location":"DD_ANNOTATION_GUIDELINES/#entities","text":"","title":"Entities"},{"location":"DD_ANNOTATION_GUIDELINES/#format-1","text":"","title":"Format 1"},{"location":"DD_ANNOTATION_GUIDELINES/#inv","text":"","title":"INV"},{"location":"DD_ANNOTATION_GUIDELINES/#general-case","text":"The tag INV refers to the full name of an inventor. This is a person that is not referred to as the assignee and is specifically referred to as the inventor ( Erfinder ).","title":"General case"},{"location":"DD_ANNOTATION_GUIDELINES/#specific-cases","text":"Inventor only : some early patents report an inventor but no assignee. We tag the inventor as it is mentioned nonetheless. See example 2. Secret inventor : in some patents, it is specifically mentioned that the inventor remains anonymous. In this case, we do not tag anything. See example 3. Inventor=Assignee : sometimes, the inventor and the assignee are the same person and the document won't repeat the name; this may be signalled by the phrase \" Erfinder zugleich Inhaber \". In this case, we tag the name only as the inventor, because a single group of words cannot be tagged twice. See example 4. Examples Standard Case with a person, from patent DD79836 Erfinder: Wilhelm Uhrig INV , WD Inventor only , from patent DD5076 Erfinder: Dr ALEXANDER PRANSCHKE INV , Schwarzheide. Dr ERWIN SAUTER INV , Schwarzheide. Inventor only , from patent DD4075 Erfinderbenennung ist ausgesetzt. Inventor=Assignee , from patent DD15399 Erfinder zugleich Inhaber: Zalter Glei\u00dfner INV , Wei\u00dfenfeis (Saale)","title":"Specific cases"},{"location":"DD_ANNOTATION_GUIDELINES/#asg","text":"","title":"ASG"},{"location":"DD_ANNOTATION_GUIDELINES/#general-case_1","text":"The tag ASG refers to the full name(s) of the person(s) or firm(s) who own(s) the patent rights.","title":"General case"},{"location":"DD_ANNOTATION_GUIDELINES/#specific-cases_1","text":"Rechtstr\u00e4ger : Some patents distinguish between Inhaber and Rechtstr\u00e4ger : we keep tagging the Inhaber person as the assignee. See example 2. Examples Standard Case with a firm, from patent DD79836 Inhaber: Dr. Plate GmbH ASG , Bonn, WD. Rechtstr\u00e4ger , from patent DD33554 Erfinder: Manfred Gerlach, Dresden; Kurt J\u00e4ger, Dresden; Dipl-Ing. Gerhard Kasche, Dresden. Inhaber: Eigentum des Volkes ASG ; Kurt J\u00e4ger ASG , Dresden; Dipl-Ing. Gerhard Kasche ASG , Dresden. Rechtstr\u00e4ger: VEB Gasturbinenbau und Energiemaschinenentwicklung Pirna, Pirna.","title":"Specific cases"},{"location":"DD_ANNOTATION_GUIDELINES/#loc","text":"","title":"LOC"},{"location":"DD_ANNOTATION_GUIDELINES/#general-case_2","text":"The tag LOC refers to the full location sequence of an assignee or inventor. In some patents, no location is reported (see DD86584).","title":"General case"},{"location":"DD_ANNOTATION_GUIDELINES/#specific-cases_2","text":"District : The patents might report the district within a given city, which we tag along. See example 3. Examples Standard Case with a location for the (foreign) assignee and a location for the (foreign) inventor, from patent DD76817 Erfinder: Abraham A.Goldberg, USA LOC . Inhaber: COLUMBIA BROADCASTING SYSTEM, INC., New York, USA LOC . Standard Case with German patentees, from patent DD69242 Erfinder: Dr-Ing. Walter Froede, Neckarsulm (WD) LOC . Inhaber: NSU-Motorenwenke AG, Neckarsulm (WD) LOC Wandel GmbH, Lindau (WD) LOC District from patent DD62143 Erfinder zugleich Inhaber: Dr. Wolfram Jenichen, Sch\u00f6now (b. Berlin) LOC .","title":"Specific cases"},{"location":"DD_ANNOTATION_GUIDELINES/#occ","text":"","title":"OCC"},{"location":"DD_ANNOTATION_GUIDELINES/#general-case_3","text":"This tag concerns the university title of inventors/assignees. When none is reported, we do not tag anything. Examples Standard Case with several inventors from patent DD1393 Erfinder: Dr. OCC GERHARD HANSEN, Dr OCC PAUL HEINZ KECK, Jena. Dipl.-Ing. OCC KARL ILMER, Jena.","title":"General case"},{"location":"DD_ANNOTATION_GUIDELINES/#format-2","text":"","title":"Format 2"},{"location":"DD_ANNOTATION_GUIDELINES/#inv_1","text":"","title":"INV"},{"location":"DD_ANNOTATION_GUIDELINES/#general-case_4","text":"The tag INV refers to the full name of an inventor. This is a person that is not referred to as the assignee and is specifically referred to as the inventor ( Erfinder ).","title":"General case"},{"location":"DD_ANNOTATION_GUIDELINES/#specific-cases_3","text":"Secret inventor : some publications do not report the name of the inventor on purpose. This may be signalled by the sentence \" Erfinder: werden aug Antrag nicht genannt \". See example 2. Inventor=Assignee : sometimes, the inventor and the assignee are the same person and the document won't repeat the name; this may be signalled by the phrase \" siehe (72) \" in line 71 (where the assignee should be). In this case, we tag the name only as the inventor, because a single group of words cannot be tagged twice. See example 3. Examples Standard Case with several inventors, from patent DD251362 (72) Kolitsch, Andreas INV , Dr.; Richter, Edgar INV , Dr.; Mende, Edgar INV ; Polnik, Frank INV , DD Secret inventor , from patent DD126770 Erfinder: werden aug Antrag nicht genannt Inventor=Assignee , from patent DD148904 (71) siehe (72). (72) Trabert, Erich INV , DD","title":"Specific cases"},{"location":"DD_ANNOTATION_GUIDELINES/#asg_1","text":"","title":"ASG"},{"location":"DD_ANNOTATION_GUIDELINES/#general-case_5","text":"The tag ASG refers to the full name(s) of the person(s) or firm(s) who own(s) the patent rights.","title":"General case"},{"location":"DD_ANNOTATION_GUIDELINES/#specific-cases_4","text":"Foreign Assignee : When the assignee is non-German, it might be reported in line (73) instead of (71). See example 2. Examples Standard Case with a government-run company, from patent DD133115 (71) Akademie der Wissenschaften der DDR, Zentralinstitut for Isotopen- und Strahlenforschung ASG , Leipzig , DD Foreign Assignee , from patent DD202259 (71) siehe (73) (73) ITERA COMPONENTS AB ASG , GOETEBORG, SE","title":"Specific cases"},{"location":"DD_ANNOTATION_GUIDELINES/#loc_1","text":"","title":"LOC"},{"location":"DD_ANNOTATION_GUIDELINES/#general-case_6","text":"The tag LOC refers to the full location sequence of an assignee or inventor. Typically, only the country will be reported for inventors, but greater details may be given for assignees. Here are a few abbreviations that are used throughout the patents. SU: Soviet Union HU: Hungary CS: Tchecoslovaquia BG: Bulgaria WD: West-Germany.","title":"General case"},{"location":"DD_ANNOTATION_GUIDELINES/#specific-cases_5","text":"Full Address : There is quite a number of Format 2 patents which report the full address of an assignee or inventor, and in this case we tag it all. See example 2. Examples Standard Case with the country and the city from patent DD141623 (71) Akademie der Wissenschaften der DDR, Berlin, DD LOC . Full Address from patent DD251362 (71) Akademie der Wissenschaften der DDR, Otto-Nuschke Stra\u00dfe 22/23, Berlin 1080, DD LOC .","title":"Specific cases"},{"location":"DD_ANNOTATION_GUIDELINES/#occ_1","text":"","title":"OCC"},{"location":"DD_ANNOTATION_GUIDELINES/#general-case_7","text":"This tag concerns the university title of inventors/assignees. When none is reported, we do not tag anything. Examples Standard Case with several inventors from patent DD220001 (72): L\u00e4mmer, Hans-Georg, Ing-Dipl. OCC ; Sommer, Peter; Matzner, Dieter, Dipl-Ing. OCC , DD.","title":"General case"},{"location":"DD_ANNOTATION_GUIDELINES/#relationships","text":"See the common annotation guidelines .","title":"Relationships"},{"location":"DD_ANNOTATION_GUIDELINES/#examples","text":"","title":"Examples"},{"location":"DD_ANNOTATION_GUIDELINES/#example-1-format-1-dd-1300","text":"","title":"Example 1: Format 1 (DD-1300)"},{"location":"DD_ANNOTATION_GUIDELINES/#example-2-format-2-dd-142651","text":"","title":"Example 2: Format 2 (DD-142651)"},{"location":"DD_DATE_IMPUTATION/","text":"DATE IMPUTATION \u00b6 Problem \u00b6 Before 1972 (incl), the publication date of DD patents is missing. frontier is fuzzy, patents publication numbers are not exactly chronological but nearly. This makes it hard to manually find the latest publication number for each vintage. Note The above figure reports the patent number (x-axis) and the publication year (ausgabe datum) labeled by hand of a random sample of 1k+ DD patents with missing date. Approach \u00b6 The idea is to look iteratively at each publication year and find the best threshold (in terms of f1) to delimit between the year and year+1. We obtain a stepwise prediction function where each threshold can be characterized by an f1-score indicating how \"good\" the threshold is. Results \u00b6 The overall accuracy of the prediction function is 93% on the training set (for the sake of simplicity, we don't have a test set) Date imputation \u00b6 Reading Patents with number below 3 are imputed publication year 1951, between 3 and 1723 are imputed publication year 1952, etc year threshold 1951 DD-3 1952 DD-1723 1953 DD-6164 1954 DD-8769 1955 DD-10939 1956 DD-12386 1957 DD-14208 1958 DD-16107 1959 DD-18028 1960 DD-20460 1961 DD-22493 1962 DD-24412 1963 DD-26646 1964 DD-34886 1965 DD-44171 1966 DD-53027 1967 DD-59516 1968 DD-65066 1969 DD-70534 1970 DD-78709 1971 DD-86784","title":"DD dates"},{"location":"DD_DATE_IMPUTATION/#date-imputation","text":"","title":"DATE IMPUTATION"},{"location":"DD_DATE_IMPUTATION/#problem","text":"Before 1972 (incl), the publication date of DD patents is missing. frontier is fuzzy, patents publication numbers are not exactly chronological but nearly. This makes it hard to manually find the latest publication number for each vintage. Note The above figure reports the patent number (x-axis) and the publication year (ausgabe datum) labeled by hand of a random sample of 1k+ DD patents with missing date.","title":"Problem"},{"location":"DD_DATE_IMPUTATION/#approach","text":"The idea is to look iteratively at each publication year and find the best threshold (in terms of f1) to delimit between the year and year+1. We obtain a stepwise prediction function where each threshold can be characterized by an f1-score indicating how \"good\" the threshold is.","title":"Approach"},{"location":"DD_DATE_IMPUTATION/#results","text":"The overall accuracy of the prediction function is 93% on the training set (for the sake of simplicity, we don't have a test set)","title":"Results"},{"location":"DD_DATE_IMPUTATION/#date-imputation_1","text":"Reading Patents with number below 3 are imputed publication year 1951, between 3 and 1723 are imputed publication year 1952, etc year threshold 1951 DD-3 1952 DD-1723 1953 DD-6164 1954 DD-8769 1955 DD-10939 1956 DD-12386 1957 DD-14208 1958 DD-16107 1959 DD-18028 1960 DD-20460 1961 DD-22493 1962 DD-24412 1963 DD-26646 1964 DD-34886 1965 DD-44171 1966 DD-53027 1967 DD-59516 1968 DD-65066 1969 DD-70534 1970 DD-78709 1971 DD-86784","title":"Date imputation"},{"location":"DD_MODEL_CARD/","text":"MODELS \u00b6 \u2139\ufe0f Model Overview \u00b6 Name de_ent_ddpatent01 & de_ent_ddpatent02 Language German (de) Pipeline ner Authors Bergeaud and Verluise Date (last) 02/2021 License MIT \ud83d\udc77 Training \u00b6 FORMAT = ddpatent01 # ddpatent02 spacy train configs/de_t2vner.cfg --paths.train data/train_ent_ ${ FORMAT } .spacy --paths.dev data/train_ent_ ${ FORMAT } .spacy --output models/de_ent_ ${ FORMAT } \ud83d\udd2e Model Performance \u00b6 de_ent_ddpatent01/model-best \u00b6 ALL ASG INV LOC OCC p 0.99 0.99 0.96 0.99 0.99 r 0.99 0.99 0.96 0.99 1 f 0.99 0.99 0.96 0.99 0.99 de_ent_ddpatent02/model-best \u00b6 ALL ASG INV LOC OCC p 0.95 0.94 0.95 0.98 0.94 r 0.94 0.87 0.97 0.95 0.94 f 0.95 0.91 0.96 0.96 0.94 \ud83c\udfaf Intended use \u00b6 de_ent_ddpatent0* have been specifically trained on DD patents. The model's performance are not guaranteed out of this scope. \ud83d\udd02 Versions and alternative approaches \u00b6 Version Comment 0.1 ner - spaCy v2 1.0 ner - spaCy v3","title":"Models"},{"location":"DD_MODEL_CARD/#models","text":"","title":"MODELS"},{"location":"DD_MODEL_CARD/#i-model-overview","text":"Name de_ent_ddpatent01 & de_ent_ddpatent02 Language German (de) Pipeline ner Authors Bergeaud and Verluise Date (last) 02/2021 License MIT","title":"\u2139\ufe0f Model Overview"},{"location":"DD_MODEL_CARD/#training","text":"FORMAT = ddpatent01 # ddpatent02 spacy train configs/de_t2vner.cfg --paths.train data/train_ent_ ${ FORMAT } .spacy --paths.dev data/train_ent_ ${ FORMAT } .spacy --output models/de_ent_ ${ FORMAT }","title":"\ud83d\udc77 Training"},{"location":"DD_MODEL_CARD/#model-performance","text":"","title":"\ud83d\udd2e Model Performance"},{"location":"DD_MODEL_CARD/#de_ent_ddpatent01model-best","text":"ALL ASG INV LOC OCC p 0.99 0.99 0.96 0.99 0.99 r 0.99 0.99 0.96 0.99 1 f 0.99 0.99 0.96 0.99 0.99","title":"de_ent_ddpatent01/model-best"},{"location":"DD_MODEL_CARD/#de_ent_ddpatent02model-best","text":"ALL ASG INV LOC OCC p 0.95 0.94 0.95 0.98 0.94 r 0.94 0.87 0.97 0.95 0.94 f 0.95 0.91 0.96 0.96 0.94","title":"de_ent_ddpatent02/model-best"},{"location":"DD_MODEL_CARD/#intended-use","text":"de_ent_ddpatent0* have been specifically trained on DD patents. The model's performance are not guaranteed out of this scope.","title":"\ud83c\udfaf Intended use"},{"location":"DD_MODEL_CARD/#versions-and-alternative-approaches","text":"Version Comment 0.1 ner - spaCy v2 1.0 ner - spaCy v3","title":"\ud83d\udd02 Versions and alternative approaches"},{"location":"DE/","text":"OVERVIEW \u00b6 Background \u00b6 The German Patent and Trade Mark Office (DPMO) was founded in 1877. The first patent was granted as early as July 2, 1877. There was (close to) no patent published between 1945 and 1950. The 1949-1992 period is characterised by the split of Germany in two distinct countries (BDR and DDR) and consequently the split of the patent system as well. After that date, the two offices reunified into the DPMO. \ud83d\udcda Data \u00b6 Patent office Time span (publication year) Kind code(s) DE 1877-1980 A1, B, B3, C, C1, D1 Publication number (range) Data source Pre-processing E.g. Format # DE1C-DE977922C Espacenet OCR DE283698C 1 DE1000001B-DE7927785 Espacenet OCR DE2454950C 2 Done In total, we consider 1,983,161 documents from 1877 to 1980. \ud83d\ude9c Extraction schema \u00b6 See the annotation guidelines . \ud83d\udd2e Models \u00b6 See the models card . Other \u00b6 See the geocoding , citizenship and date imputation documentation.","title":"Overview"},{"location":"DE/#overview","text":"","title":"OVERVIEW"},{"location":"DE/#background","text":"The German Patent and Trade Mark Office (DPMO) was founded in 1877. The first patent was granted as early as July 2, 1877. There was (close to) no patent published between 1945 and 1950. The 1949-1992 period is characterised by the split of Germany in two distinct countries (BDR and DDR) and consequently the split of the patent system as well. After that date, the two offices reunified into the DPMO.","title":"Background"},{"location":"DE/#data","text":"Patent office Time span (publication year) Kind code(s) DE 1877-1980 A1, B, B3, C, C1, D1 Publication number (range) Data source Pre-processing E.g. Format # DE1C-DE977922C Espacenet OCR DE283698C 1 DE1000001B-DE7927785 Espacenet OCR DE2454950C 2 Done In total, we consider 1,983,161 documents from 1877 to 1980.","title":"\ud83d\udcda Data"},{"location":"DE/#extraction-schema","text":"See the annotation guidelines .","title":"\ud83d\ude9c Extraction schema"},{"location":"DE/#models","text":"See the models card .","title":"\ud83d\udd2e Models"},{"location":"DE/#other","text":"See the geocoding , citizenship and date imputation documentation.","title":"Other"},{"location":"DE_ANNOTATION_GUIDELINES/","text":"ANNOTATION GUIDELINES \u00b6 Warning GitHub markdown does not fully support visual annotation components (e.g. entity boxes) used below. We invite user interested in the annotation guidelines to download the documents and open it in a development environment supporting extended markdown syntax (e.g. MacDown, PyCharm, etc) and/or save it as a pdf. Preliminary comments \u00b6 The patent corpus that we consider for Germany spans the period 1877-1980 and has 2 types of formats. Format 1 , from DE1C to DE977922C \u00b6 Information display \u00b6 For this format, the information is given at the top of the document, in a header, just below the seal of the Patentamt . This format experiences some evolution over time. From publication number DE1C (1877) to DE13105C (1881), the front page of the patent usually does not have any text (at least in the documents that were retrieved by Espacenet) and contain the following information (and in that order): the reference of the patent: \" Patentschrift No (...)\" the name and location of the assignee (either a person or a firm) E.g : \"S.Frank in Stolp (Pommern)\" the title of the (claimed) invention. E.g : \"Neuerungen an Tabakspfeifen\" (Innovations for pipes) a technological class number , sometimes with the title of this class. E.g : \"Klasse 44, Kurzwaaren\" (Class 44, Dry Goods). This classification is specific to Germany. From publication number DE13106C to DE977922C (1973), some changes are introduced with the relevant information being still located in the header. The main difference is that the technological class now comes right below the patent number, while the seal of the patent office is at the top of the document. Information about the assignee is unchanged, as well as the title of the invention which comes below. See example 2. More on format 1 Erfinder: From 1944 onwards, an important item is added right before the name of the assignee: a line specifies the name of the inventor ( Erfinder ) as well as his location. E.g : \"Bernhard Ziebell, Braunschweig\" or \"Eugen Stich in Mannheim\". A second line explicits this: \"(...) ist als Erfinder genannt worden... \". Technological class: In 1957, for the first time an \"international class\" is specified for the patent (as opposed to the German class). Information extraction \u00b6 We extract 5 different \"entities\" from the header of DE patents in format category 1. Entity Content E.g ASG Assignee full name ANTON KLEBER ASG in SAARBRUCKEN INV Inventor full name ( Erfinder ) Frutz Doring INV , Berlin-Frohnau ist als Erfinder genannt worden LOC Location of the assignee/inventor Demag Akt-Ges. in Duisburg LOC . OCC Occupation of the assignee/inventor (academic title) Dipl-Ing OCC Georg Werner Gaze, Ingolstadt CLAS Technological class (German system) KLASSE 49h GRUPPE 27 D 16736VI/49h CLAS These entities are tied together with 2 types of relations. Relation Content E.g. LOCATION Links an ASG / INV to a LOC MARIUS ALBERT de DION ASG --> LOCATION --> PUTEAUX (Seine, Frankr.) LOC OCCUPATION Links an ASG / INV to an OCC Dr. OCC <-- OCCUPATION <-- KARL HENKEL ASG Format 2 , from DE977923C to DE978074C and from DE1000001B onwards \u00b6 This format corresponds to two subformats: The first subformat starts with DE1000001B, in 1957. The second subformat starts with patent DE1283771, in 1968. Information display \u00b6 With the second subformat, we get back to a format that does not have a body of text. In the first frame of the header, one gets the following information: the reference of the patent ( Auslegeschrift # or Offenlegungsschrift #). the technological class number . E.g : \"Deutsche Kl.: 21c-22\" the publication date ( Auslegetag or Offenlegungstag ). E.g : \"Auslegetag: 9.September 1965\" In the second frame of the header, one gets the following information: the title of the invention ( Bezeichnung ). E.g : \"Bezeichnung: Wegwerfwindel\". the name and location of the assignee ( Anmelder ). E.g : \"Anmelder: The Procter&Gamble Co., Cincinnati, Ohio (U.St.A)\". the name and location of the inventor ( Erfinder ). E.g : \"Erfinder: Buell, Kenneth Barclay, Cincinnati, Ohio (U.St.A)\". It seems that the specifically German technological classifications are not even mentioned from 1975 onwards. When a person is located in Germany, the name of the city is typically accompanied by a zipcode ( e.g : \"7000 Stuttgart\", \"2000 Hamburg\", \"8000 M\u00fcnchen\", ...). More on format 2 Oddly, some patents issued after 1957 have publication number inferior to 1000000. Those patents are published ( ausgegeben ) in or after 1973 and up until 1980. Their format is almost identical to format 2. The only difference with format 2 is that the document is again presented as a Patentschrift (not an Offenlegungsschrift ) and the publication date is announced by the word Ausgabetag . Information extraction \u00b6 We extract 5 different \"entities\" from the header of DE patents in format category 2. Entity Content E.g. ASG Assignee full name Anmelder: Greer Hydraulics, Inc. ASG , Los Angeles, Calif. (V.St.A.) INV Inventor full name Erfinder: Knight, David George INV Sommershall, Chesterfield (Gro\u00dfbritannien) LOC Location of the Assignee/Inventor Anmelder: Sharp K.K., Osaka (Japan) LOC OCC Occupation of the Assignee/Inventor (academic title) Dietrich Jurgen, Dr.-Ing. OCC ; 7033 Herrenberg CLAS Technological class (German system) Deutsche Kl.: 42 i, 8/80 CLAS These entities are tied together with 2 types of relations. Relation Content E.g. LOCATION Links an ASG / INV to a LOC The Procter&Gamble Co. ASG --> LOCATION --> Cincinnati, Ohio (U.St.A) LOC OCCUPATION Links an ASG / INV to an OCC Spitzke, Wolfgang ASG --> OCCUPATION --> Ing.(grad.) OCC Entities \u00b6 Format 1 \u00b6 INV \u00b6 General case \u00b6 The tag INV refers to the full name of an inventor. This is a person that is not referred to as the assignee and is sometimes specifically referred to as the inventor ( Erfinder ). The document might introduce the inventor with phrases like \" ist als Erfinder genannt worden \" or \" als Erfinder benannt \", or simply with \" Erfinder : (name)\". Specific cases \u00b6 Inventor=Assignee : sometimes, the inventor and the assignee are the same person and the document does not repeat the name. In this case, we do not tag further. See example 2 from patent DE1575852A1. Academic title : in some cases, the inventor has an academic title (see example 3 from patent DE918881C). This title is not part of the tag INV but is part of a tag OCC (see below) Secret inventor : some publications do not report the name of the inventor on purpose. In such case, the patent includes the following sentence \" der Erfinder hat beantragt, nicht gennant zu werden \". See for example patent DE825754C. In such case, we do not label any inventor. Examples Standard Case , from patent DE869602C Bela Barenyi INV , Stuttgart-Rohr, ist als Erfinder genannt worden Inventor=Assignee , from patent DE1575852A1 Als Erfinder bennant: Erfinder ist der Anmelder Academic title , from patent DE918881C Ing. Karl Nowak INV , Wien ist als Erfinder gennant worden ASG \u00b6 General case \u00b6 The tag ASG refers to the full name(s) of the person(s) or firm(s) who own(s) the patent rights. Specific Cases \u00b6 Former name : Do not label the former name of the company when it is given. This is signalled by the German word \" vormals \". See example 3 from patent DE134077C. vertreten : in the rare cases where an assignee uses a third party to represent her, only label the assignee. See example 4. Examples Standard Case with a firm, from patent DE283698C SIEMENS-SCHUKERT WERKE G.M.B.H. ASG IN SIEMENSSTADT B. BERLIN Standard Case with several persons, from patent DE170522C AUGUST REINHOLD ILCHMANN ASG IN DRESDEN, GUSTAV ADOLF RAUER ASG IN DRESDEN-RADEBEUL UND EHREGOTT RICHTER ASG IN DRESDEN Specific Case 1 (Former Name) from patent DE134077C ELEKTRIZIT\u00c4T-AKTIEN-GESELLSCHAFT ASG VORMALS SCHUKERT&CO IN N\u00dcRNBERG vertreten from patent DE824442C Deutsche Bundesbahn ASG vertreten durch das Eisenbahn-Zentralamt Minden, Minden (Westf.) LOC \u00b6 General case \u00b6 The tag LOC refers to the full location sequence. It is usually the name of a city and a region (or state, or province) in which the city is located. Specific cases \u00b6 District : When the assignee is located in Germany, the document might go as far as to give a particular district within the assignee's city. See example 5. More rarely, only the district (without the city) is provided. See example 6. Former City : Some cities mentioned by sufficiently old patents might not exist anymore, at least as cities (they might have become part of a larger agglomeration at some point between the publication and today). Examples Standard Case with a standalone city, from patent DE13106C HERMANN SCHULZ in RATIBOR LOC Standard Case with a German city and its Land, from patent DE872632C Friedrich Stemmermann in Sinzheim bei B\u00fchl (Bad.) LOC Standard Case with a city and its country, from patent DE153621C GEORGE JAMES GOODALL IN PORTHILL (ENGL.) LOC . Standard Case with a city, a region/state and a country from patent DE887191C Scovill Manufacturing Company, Waterbury, Conn. (U.St.A) LOC . District , from patent DE283698C SIEMENS-SCHUKERT WERKE G.M.B.H IN SIEMENSSTADT B. BERLIN LOC . District , from patent DE93717C KALKER WERKZEUGMASCHINENFABRIK L.W.BREUER, SCHUMACHER&CO. IN KALK LOC . Former City , from patent DE78165C H.W. SOLFRIAN IN HOLSTERHAUSEN BEI EICKEL LOC N.B : Holsterhausen is now part of the city Herne. OCC \u00b6 General case \u00b6 The tag OCC refers to the academic title of an INV or ASG . It typically corresponds to a prefix before the name which is an abbreviation of a title (e.g. Dr., Ing. etc...). Examples from patent DE975335C Dr. OCC Wilhelm Michael, Ludwigshafen/Rhein, und Dr. OCC Wolfgang J\u00e4ckh, Heidelberg sind als Erfinder gennant worden CLAS \u00b6 General case \u00b6 The tag CLAS refers to the German technological class that usually appears on patents up until 1975. It can encompass more or less details. Do not include \" Deutsche Kl \" in the label. When two classifications are given (international and German) only label the German's (see examples 3 and 4) Do not label the description of the class (see example 1) Label also the subclass (see example 4 and 5) Examples standard case with a class number and its brief description, from patent DE4010C Klasse 44 CLAS KURZWAAREN standard case with a class number and a group number, from patent DE283698C KLASSE 21d GRUPPE 19 CLAS standard case with a German class code and an international class code, from patent DE1200408 Int.Cl.: H02f Deutsche Kl.: 21c-22 CLAS standard case with a German class code and an international class code with a subclass, from patent DE949207C KLASSE 49a GRUPPE 3603 CLAS INTERNAT. KLASSE B23b B 30976 lb/494 CLAS standard case with a class number, a group number and additional information from patent DE923434C KLASSE 20h GRUPPE 7 St 5364 II/ 20h CLAS Format 2 \u00b6 INV \u00b6 General case \u00b6 The tag INV refers to the full name of an inventor. This is a person that is refered to as Erfinder . It appears after the item Als Erfinder banannt: or simply after Erfinder: . Specific cases \u00b6 Examples standard case als erfinder benannt from patent DE2054787A1 Als Erfinder benannt: Ohyama, Yasishi INV ; Miyazawa, Saduyuki INV , Kyoto (Japan) ASG \u00b6 General case \u00b6 The tag ASG refers to the full name of an assignee, either a firm or a person. This is a person that is refered to as Anmelder . It appears after the item Anmelder: . When the assignee lives outside Germany, the patent also specifies the name of the patent attorney ( Vertreter ). We are not interested in this information and the associated entities ( LOC and OCC namely). Specific cases \u00b6 Examples standard case from patent DE2818594A1 Anmelder: Greer Hydraulics, Inc. , Los Angeles, Calif. (V.St.A.) LOC \u00b6 General case \u00b6 Similar to format 1. Specific cases \u00b6 full address: in some rare instances, the inventor or the assignee gives its full address at the top of the body (in addition to giving its city in the header). See example 2. In more frequent cases, the full address is given in the header (see example 3). Examples standard case from patent DE1201058B Anmelder: General Aniline & Film Corporation, New York, N.Y. (V.St.A) LOC full address from patent DE2745546A1 Anmelder: Katzer, Rudolf, Graz (Osterreich) LOC [...] Rudolf Katzer Klosterwiesgasse 29 8010 Graz . Osterreich LOC full address from patent DE1026733B Anmelder: Pintsch Bamag Aktiengesellschaft Berlin NW 87, Reuchlinstr. 10-17 LOC OCC \u00b6 General case \u00b6 XX Specific cases \u00b6 XX Examples standard case from patent DE1158387B Dr. techn. OCC Erns Fiala, Sindelfingen (Wurtt.) title after the name from patent DE2814877A1 Erfinder: Diekman, Peter, Dr. OCC , 2300 Kiel CLAS \u00b6 General case \u00b6 Similar to format 1. Specific cases \u00b6 Class KL: In some cases, the classe is given in the form: KL.XXXXXX, in such case, we label the \"KL.\" See example 2. Examples standard case from patent DE1218989B Deutsche Kl: 8f-3.51 CLAS Class KL. from patent DE1158387B KL.63C 42 CLAS INTERNAT.KL. B62 d CIT \u00b6 General case \u00b6 In some rare occasion, the origin of the firm is precised. This seems to only be the case for US firms. The CIT is either printed in full letter (example 1) or with abbreviations (example 2). Examples nach den Gestzen from patent DE1216661B Anmmelder: Revere Copper and Brass Incorporated, eine Gesellschaft nach den Gesetzen des Staates Maryland CIT , New York, N.J. (V.St.A.) in parenthesis from patent DE2500682A1 Anmelder: Process Systems, INc. ( N.D.Ges. d.Staates Nevada ), Salt Lake City, Utah (V.St.A.) Relationships \u00b6 See the common annotation guidelines . Examples \u00b6 Example 1: Format 1 before 1881 \u00b6 Example 2: format 1 without inventor \u00b6 Example 3: format 1 with inventor \u00b6 Example 4: format 2, first subformat \u00b6 Example 5: format 2, second subformat \u00b6","title":"Annotation Guidelines"},{"location":"DE_ANNOTATION_GUIDELINES/#annotation-guidelines","text":"Warning GitHub markdown does not fully support visual annotation components (e.g. entity boxes) used below. We invite user interested in the annotation guidelines to download the documents and open it in a development environment supporting extended markdown syntax (e.g. MacDown, PyCharm, etc) and/or save it as a pdf.","title":"ANNOTATION GUIDELINES"},{"location":"DE_ANNOTATION_GUIDELINES/#preliminary-comments","text":"The patent corpus that we consider for Germany spans the period 1877-1980 and has 2 types of formats.","title":"Preliminary comments"},{"location":"DE_ANNOTATION_GUIDELINES/#format-1-from-de1c-to-de977922c","text":"","title":"Format 1, from  DE1C to DE977922C"},{"location":"DE_ANNOTATION_GUIDELINES/#information-display","text":"For this format, the information is given at the top of the document, in a header, just below the seal of the Patentamt . This format experiences some evolution over time. From publication number DE1C (1877) to DE13105C (1881), the front page of the patent usually does not have any text (at least in the documents that were retrieved by Espacenet) and contain the following information (and in that order): the reference of the patent: \" Patentschrift No (...)\" the name and location of the assignee (either a person or a firm) E.g : \"S.Frank in Stolp (Pommern)\" the title of the (claimed) invention. E.g : \"Neuerungen an Tabakspfeifen\" (Innovations for pipes) a technological class number , sometimes with the title of this class. E.g : \"Klasse 44, Kurzwaaren\" (Class 44, Dry Goods). This classification is specific to Germany. From publication number DE13106C to DE977922C (1973), some changes are introduced with the relevant information being still located in the header. The main difference is that the technological class now comes right below the patent number, while the seal of the patent office is at the top of the document. Information about the assignee is unchanged, as well as the title of the invention which comes below. See example 2. More on format 1 Erfinder: From 1944 onwards, an important item is added right before the name of the assignee: a line specifies the name of the inventor ( Erfinder ) as well as his location. E.g : \"Bernhard Ziebell, Braunschweig\" or \"Eugen Stich in Mannheim\". A second line explicits this: \"(...) ist als Erfinder genannt worden... \". Technological class: In 1957, for the first time an \"international class\" is specified for the patent (as opposed to the German class).","title":"Information display"},{"location":"DE_ANNOTATION_GUIDELINES/#information-extraction","text":"We extract 5 different \"entities\" from the header of DE patents in format category 1. Entity Content E.g ASG Assignee full name ANTON KLEBER ASG in SAARBRUCKEN INV Inventor full name ( Erfinder ) Frutz Doring INV , Berlin-Frohnau ist als Erfinder genannt worden LOC Location of the assignee/inventor Demag Akt-Ges. in Duisburg LOC . OCC Occupation of the assignee/inventor (academic title) Dipl-Ing OCC Georg Werner Gaze, Ingolstadt CLAS Technological class (German system) KLASSE 49h GRUPPE 27 D 16736VI/49h CLAS These entities are tied together with 2 types of relations. Relation Content E.g. LOCATION Links an ASG / INV to a LOC MARIUS ALBERT de DION ASG --> LOCATION --> PUTEAUX (Seine, Frankr.) LOC OCCUPATION Links an ASG / INV to an OCC Dr. OCC <-- OCCUPATION <-- KARL HENKEL ASG","title":"Information extraction"},{"location":"DE_ANNOTATION_GUIDELINES/#format-2-from-de977923c-to-de978074c-and-from-de1000001b-onwards","text":"This format corresponds to two subformats: The first subformat starts with DE1000001B, in 1957. The second subformat starts with patent DE1283771, in 1968.","title":"Format 2, from DE977923C to DE978074C and from DE1000001B onwards"},{"location":"DE_ANNOTATION_GUIDELINES/#information-display_1","text":"With the second subformat, we get back to a format that does not have a body of text. In the first frame of the header, one gets the following information: the reference of the patent ( Auslegeschrift # or Offenlegungsschrift #). the technological class number . E.g : \"Deutsche Kl.: 21c-22\" the publication date ( Auslegetag or Offenlegungstag ). E.g : \"Auslegetag: 9.September 1965\" In the second frame of the header, one gets the following information: the title of the invention ( Bezeichnung ). E.g : \"Bezeichnung: Wegwerfwindel\". the name and location of the assignee ( Anmelder ). E.g : \"Anmelder: The Procter&Gamble Co., Cincinnati, Ohio (U.St.A)\". the name and location of the inventor ( Erfinder ). E.g : \"Erfinder: Buell, Kenneth Barclay, Cincinnati, Ohio (U.St.A)\". It seems that the specifically German technological classifications are not even mentioned from 1975 onwards. When a person is located in Germany, the name of the city is typically accompanied by a zipcode ( e.g : \"7000 Stuttgart\", \"2000 Hamburg\", \"8000 M\u00fcnchen\", ...). More on format 2 Oddly, some patents issued after 1957 have publication number inferior to 1000000. Those patents are published ( ausgegeben ) in or after 1973 and up until 1980. Their format is almost identical to format 2. The only difference with format 2 is that the document is again presented as a Patentschrift (not an Offenlegungsschrift ) and the publication date is announced by the word Ausgabetag .","title":"Information display"},{"location":"DE_ANNOTATION_GUIDELINES/#information-extraction_1","text":"We extract 5 different \"entities\" from the header of DE patents in format category 2. Entity Content E.g. ASG Assignee full name Anmelder: Greer Hydraulics, Inc. ASG , Los Angeles, Calif. (V.St.A.) INV Inventor full name Erfinder: Knight, David George INV Sommershall, Chesterfield (Gro\u00dfbritannien) LOC Location of the Assignee/Inventor Anmelder: Sharp K.K., Osaka (Japan) LOC OCC Occupation of the Assignee/Inventor (academic title) Dietrich Jurgen, Dr.-Ing. OCC ; 7033 Herrenberg CLAS Technological class (German system) Deutsche Kl.: 42 i, 8/80 CLAS These entities are tied together with 2 types of relations. Relation Content E.g. LOCATION Links an ASG / INV to a LOC The Procter&Gamble Co. ASG --> LOCATION --> Cincinnati, Ohio (U.St.A) LOC OCCUPATION Links an ASG / INV to an OCC Spitzke, Wolfgang ASG --> OCCUPATION --> Ing.(grad.) OCC","title":"Information extraction"},{"location":"DE_ANNOTATION_GUIDELINES/#entities","text":"","title":"Entities"},{"location":"DE_ANNOTATION_GUIDELINES/#format-1","text":"","title":"Format 1"},{"location":"DE_ANNOTATION_GUIDELINES/#inv","text":"","title":"INV"},{"location":"DE_ANNOTATION_GUIDELINES/#general-case","text":"The tag INV refers to the full name of an inventor. This is a person that is not referred to as the assignee and is sometimes specifically referred to as the inventor ( Erfinder ). The document might introduce the inventor with phrases like \" ist als Erfinder genannt worden \" or \" als Erfinder benannt \", or simply with \" Erfinder : (name)\".","title":"General case"},{"location":"DE_ANNOTATION_GUIDELINES/#specific-cases","text":"Inventor=Assignee : sometimes, the inventor and the assignee are the same person and the document does not repeat the name. In this case, we do not tag further. See example 2 from patent DE1575852A1. Academic title : in some cases, the inventor has an academic title (see example 3 from patent DE918881C). This title is not part of the tag INV but is part of a tag OCC (see below) Secret inventor : some publications do not report the name of the inventor on purpose. In such case, the patent includes the following sentence \" der Erfinder hat beantragt, nicht gennant zu werden \". See for example patent DE825754C. In such case, we do not label any inventor. Examples Standard Case , from patent DE869602C Bela Barenyi INV , Stuttgart-Rohr, ist als Erfinder genannt worden Inventor=Assignee , from patent DE1575852A1 Als Erfinder bennant: Erfinder ist der Anmelder Academic title , from patent DE918881C Ing. Karl Nowak INV , Wien ist als Erfinder gennant worden","title":"Specific cases"},{"location":"DE_ANNOTATION_GUIDELINES/#asg","text":"","title":"ASG"},{"location":"DE_ANNOTATION_GUIDELINES/#general-case_1","text":"The tag ASG refers to the full name(s) of the person(s) or firm(s) who own(s) the patent rights.","title":"General case"},{"location":"DE_ANNOTATION_GUIDELINES/#specific-cases_1","text":"Former name : Do not label the former name of the company when it is given. This is signalled by the German word \" vormals \". See example 3 from patent DE134077C. vertreten : in the rare cases where an assignee uses a third party to represent her, only label the assignee. See example 4. Examples Standard Case with a firm, from patent DE283698C SIEMENS-SCHUKERT WERKE G.M.B.H. ASG IN SIEMENSSTADT B. BERLIN Standard Case with several persons, from patent DE170522C AUGUST REINHOLD ILCHMANN ASG IN DRESDEN, GUSTAV ADOLF RAUER ASG IN DRESDEN-RADEBEUL UND EHREGOTT RICHTER ASG IN DRESDEN Specific Case 1 (Former Name) from patent DE134077C ELEKTRIZIT\u00c4T-AKTIEN-GESELLSCHAFT ASG VORMALS SCHUKERT&CO IN N\u00dcRNBERG vertreten from patent DE824442C Deutsche Bundesbahn ASG vertreten durch das Eisenbahn-Zentralamt Minden, Minden (Westf.)","title":"Specific Cases"},{"location":"DE_ANNOTATION_GUIDELINES/#loc","text":"","title":"LOC"},{"location":"DE_ANNOTATION_GUIDELINES/#general-case_2","text":"The tag LOC refers to the full location sequence. It is usually the name of a city and a region (or state, or province) in which the city is located.","title":"General case"},{"location":"DE_ANNOTATION_GUIDELINES/#specific-cases_2","text":"District : When the assignee is located in Germany, the document might go as far as to give a particular district within the assignee's city. See example 5. More rarely, only the district (without the city) is provided. See example 6. Former City : Some cities mentioned by sufficiently old patents might not exist anymore, at least as cities (they might have become part of a larger agglomeration at some point between the publication and today). Examples Standard Case with a standalone city, from patent DE13106C HERMANN SCHULZ in RATIBOR LOC Standard Case with a German city and its Land, from patent DE872632C Friedrich Stemmermann in Sinzheim bei B\u00fchl (Bad.) LOC Standard Case with a city and its country, from patent DE153621C GEORGE JAMES GOODALL IN PORTHILL (ENGL.) LOC . Standard Case with a city, a region/state and a country from patent DE887191C Scovill Manufacturing Company, Waterbury, Conn. (U.St.A) LOC . District , from patent DE283698C SIEMENS-SCHUKERT WERKE G.M.B.H IN SIEMENSSTADT B. BERLIN LOC . District , from patent DE93717C KALKER WERKZEUGMASCHINENFABRIK L.W.BREUER, SCHUMACHER&CO. IN KALK LOC . Former City , from patent DE78165C H.W. SOLFRIAN IN HOLSTERHAUSEN BEI EICKEL LOC N.B : Holsterhausen is now part of the city Herne.","title":"Specific cases"},{"location":"DE_ANNOTATION_GUIDELINES/#occ","text":"","title":"OCC"},{"location":"DE_ANNOTATION_GUIDELINES/#general-case_3","text":"The tag OCC refers to the academic title of an INV or ASG . It typically corresponds to a prefix before the name which is an abbreviation of a title (e.g. Dr., Ing. etc...). Examples from patent DE975335C Dr. OCC Wilhelm Michael, Ludwigshafen/Rhein, und Dr. OCC Wolfgang J\u00e4ckh, Heidelberg sind als Erfinder gennant worden","title":"General case"},{"location":"DE_ANNOTATION_GUIDELINES/#clas","text":"","title":"CLAS"},{"location":"DE_ANNOTATION_GUIDELINES/#general-case_4","text":"The tag CLAS refers to the German technological class that usually appears on patents up until 1975. It can encompass more or less details. Do not include \" Deutsche Kl \" in the label. When two classifications are given (international and German) only label the German's (see examples 3 and 4) Do not label the description of the class (see example 1) Label also the subclass (see example 4 and 5) Examples standard case with a class number and its brief description, from patent DE4010C Klasse 44 CLAS KURZWAAREN standard case with a class number and a group number, from patent DE283698C KLASSE 21d GRUPPE 19 CLAS standard case with a German class code and an international class code, from patent DE1200408 Int.Cl.: H02f Deutsche Kl.: 21c-22 CLAS standard case with a German class code and an international class code with a subclass, from patent DE949207C KLASSE 49a GRUPPE 3603 CLAS INTERNAT. KLASSE B23b B 30976 lb/494 CLAS standard case with a class number, a group number and additional information from patent DE923434C KLASSE 20h GRUPPE 7 St 5364 II/ 20h CLAS","title":"General case"},{"location":"DE_ANNOTATION_GUIDELINES/#format-2","text":"","title":"Format 2"},{"location":"DE_ANNOTATION_GUIDELINES/#inv_1","text":"","title":"INV"},{"location":"DE_ANNOTATION_GUIDELINES/#general-case_5","text":"The tag INV refers to the full name of an inventor. This is a person that is refered to as Erfinder . It appears after the item Als Erfinder banannt: or simply after Erfinder: .","title":"General case"},{"location":"DE_ANNOTATION_GUIDELINES/#specific-cases_3","text":"Examples standard case als erfinder benannt from patent DE2054787A1 Als Erfinder benannt: Ohyama, Yasishi INV ; Miyazawa, Saduyuki INV , Kyoto (Japan)","title":"Specific cases"},{"location":"DE_ANNOTATION_GUIDELINES/#asg_1","text":"","title":"ASG"},{"location":"DE_ANNOTATION_GUIDELINES/#general-case_6","text":"The tag ASG refers to the full name of an assignee, either a firm or a person. This is a person that is refered to as Anmelder . It appears after the item Anmelder: . When the assignee lives outside Germany, the patent also specifies the name of the patent attorney ( Vertreter ). We are not interested in this information and the associated entities ( LOC and OCC namely).","title":"General case"},{"location":"DE_ANNOTATION_GUIDELINES/#specific-cases_4","text":"Examples standard case from patent DE2818594A1 Anmelder: Greer Hydraulics, Inc. , Los Angeles, Calif. (V.St.A.)","title":"Specific cases"},{"location":"DE_ANNOTATION_GUIDELINES/#loc_1","text":"","title":"LOC"},{"location":"DE_ANNOTATION_GUIDELINES/#general-case_7","text":"Similar to format 1.","title":"General case"},{"location":"DE_ANNOTATION_GUIDELINES/#specific-cases_5","text":"full address: in some rare instances, the inventor or the assignee gives its full address at the top of the body (in addition to giving its city in the header). See example 2. In more frequent cases, the full address is given in the header (see example 3). Examples standard case from patent DE1201058B Anmelder: General Aniline & Film Corporation, New York, N.Y. (V.St.A) LOC full address from patent DE2745546A1 Anmelder: Katzer, Rudolf, Graz (Osterreich) LOC [...] Rudolf Katzer Klosterwiesgasse 29 8010 Graz . Osterreich LOC full address from patent DE1026733B Anmelder: Pintsch Bamag Aktiengesellschaft Berlin NW 87, Reuchlinstr. 10-17 LOC","title":"Specific cases"},{"location":"DE_ANNOTATION_GUIDELINES/#occ_1","text":"","title":"OCC"},{"location":"DE_ANNOTATION_GUIDELINES/#general-case_8","text":"XX","title":"General case"},{"location":"DE_ANNOTATION_GUIDELINES/#specific-cases_6","text":"XX Examples standard case from patent DE1158387B Dr. techn. OCC Erns Fiala, Sindelfingen (Wurtt.) title after the name from patent DE2814877A1 Erfinder: Diekman, Peter, Dr. OCC , 2300 Kiel","title":"Specific cases"},{"location":"DE_ANNOTATION_GUIDELINES/#clas_1","text":"","title":"CLAS"},{"location":"DE_ANNOTATION_GUIDELINES/#general-case_9","text":"Similar to format 1.","title":"General case"},{"location":"DE_ANNOTATION_GUIDELINES/#specific-cases_7","text":"Class KL: In some cases, the classe is given in the form: KL.XXXXXX, in such case, we label the \"KL.\" See example 2. Examples standard case from patent DE1218989B Deutsche Kl: 8f-3.51 CLAS Class KL. from patent DE1158387B KL.63C 42 CLAS INTERNAT.KL. B62 d","title":"Specific cases"},{"location":"DE_ANNOTATION_GUIDELINES/#cit","text":"","title":"CIT"},{"location":"DE_ANNOTATION_GUIDELINES/#general-case_10","text":"In some rare occasion, the origin of the firm is precised. This seems to only be the case for US firms. The CIT is either printed in full letter (example 1) or with abbreviations (example 2). Examples nach den Gestzen from patent DE1216661B Anmmelder: Revere Copper and Brass Incorporated, eine Gesellschaft nach den Gesetzen des Staates Maryland CIT , New York, N.J. (V.St.A.) in parenthesis from patent DE2500682A1 Anmelder: Process Systems, INc. ( N.D.Ges. d.Staates Nevada ), Salt Lake City, Utah (V.St.A.)","title":"General case"},{"location":"DE_ANNOTATION_GUIDELINES/#relationships","text":"See the common annotation guidelines .","title":"Relationships"},{"location":"DE_ANNOTATION_GUIDELINES/#examples","text":"","title":"Examples"},{"location":"DE_ANNOTATION_GUIDELINES/#example-1-format-1-before-1881","text":"","title":"Example 1: Format 1 before 1881"},{"location":"DE_ANNOTATION_GUIDELINES/#example-2-format-1-without-inventor","text":"","title":"Example 2: format 1 without inventor"},{"location":"DE_ANNOTATION_GUIDELINES/#example-3-format-1-with-inventor","text":"","title":"Example 3: format 1 with inventor"},{"location":"DE_ANNOTATION_GUIDELINES/#example-4-format-2-first-subformat","text":"","title":"Example 4: format 2, first subformat"},{"location":"DE_ANNOTATION_GUIDELINES/#example-5-format-2-second-subformat","text":"","title":"Example 5: format 2, second subformat"},{"location":"DE_DATE_IMPUTATION/","text":"DATE IMPUTATION \u00b6 Problem \u00b6 Before 1919 (incl), the publication date of DE patents is missing. Frontier is fuzzy, patents publication numbers are not exactly chronological but nearly. This makes it hard to manually find the latest publication number for each vintage. Number seem to be given based on the \"Patentdatum\" Approach \u00b6 We look in the corpus of patents to find the latest publication number for each given year from 1877 to 1920. We use the patent gazette published par the German patent offices (\"PatentBlat\") and consider the largest publication number specified under section \"Erteilungen\". The gazette is published weekly and we consider either week 52 or week 53 of each year from 1878 to 1919 (and 51 for 1918). From these benchmark patents, we carry forward the year of publication. Warning This method is not applicable for patents published earlier than 1883, hence for years 1877-1882, we manually look for patents with publication date in late December and arbitrarily select a benchmark. Results \u00b6 Publication year Benchmark publication number 1877 DE-1877-C* 1878 DE-3297-C* 1879 DE-8460-C* 1880 DE-12116-C* 1881 DE-16547-C* 1882 DE-20544-C* 1883 DE-26025-C 1884 DE-30543-C 1885 DE-34561-C 1886 DE-38569-C 1887 DE-42451-C 1888 DE-46348-C 1889 DE-50707-C 1890 DE-55460-C 1891 DE-61010-C 1892 DE-66910-C 1893 DE-73340-C 1894 DE-79528-C 1895 DE-85240-C 1896 DE-90750-C 1897 DE-96190-C 1898 DE-101760-C 1899 DE-109190-C (we use DE-109189-C as DE-109190-C is missing) 1900 DE-117765-C 1901 DE-128268-C 1902 DE-139092-C 1903 DE-149056-C 1904 DE-158245-C 1905 DE-167845-C 1906 DE-180900-C 1907 DE-194320-C 1908 DE-206135-C 1909 DE-218130-C 1910 DE-230230-C 1911 DE-242870-C 1912 DE-255770-C 1913 DE-269260-C 1914 DE-281820-C 1915 DE-290010-C 1916 DE-296016-C 1917 DE-303620-C 1918 DE-310930-C 1919 DE-318790-C","title":"DE dates"},{"location":"DE_DATE_IMPUTATION/#date-imputation","text":"","title":"DATE IMPUTATION"},{"location":"DE_DATE_IMPUTATION/#problem","text":"Before 1919 (incl), the publication date of DE patents is missing. Frontier is fuzzy, patents publication numbers are not exactly chronological but nearly. This makes it hard to manually find the latest publication number for each vintage. Number seem to be given based on the \"Patentdatum\"","title":"Problem"},{"location":"DE_DATE_IMPUTATION/#approach","text":"We look in the corpus of patents to find the latest publication number for each given year from 1877 to 1920. We use the patent gazette published par the German patent offices (\"PatentBlat\") and consider the largest publication number specified under section \"Erteilungen\". The gazette is published weekly and we consider either week 52 or week 53 of each year from 1878 to 1919 (and 51 for 1918). From these benchmark patents, we carry forward the year of publication. Warning This method is not applicable for patents published earlier than 1883, hence for years 1877-1882, we manually look for patents with publication date in late December and arbitrarily select a benchmark.","title":"Approach"},{"location":"DE_DATE_IMPUTATION/#results","text":"Publication year Benchmark publication number 1877 DE-1877-C* 1878 DE-3297-C* 1879 DE-8460-C* 1880 DE-12116-C* 1881 DE-16547-C* 1882 DE-20544-C* 1883 DE-26025-C 1884 DE-30543-C 1885 DE-34561-C 1886 DE-38569-C 1887 DE-42451-C 1888 DE-46348-C 1889 DE-50707-C 1890 DE-55460-C 1891 DE-61010-C 1892 DE-66910-C 1893 DE-73340-C 1894 DE-79528-C 1895 DE-85240-C 1896 DE-90750-C 1897 DE-96190-C 1898 DE-101760-C 1899 DE-109190-C (we use DE-109189-C as DE-109190-C is missing) 1900 DE-117765-C 1901 DE-128268-C 1902 DE-139092-C 1903 DE-149056-C 1904 DE-158245-C 1905 DE-167845-C 1906 DE-180900-C 1907 DE-194320-C 1908 DE-206135-C 1909 DE-218130-C 1910 DE-230230-C 1911 DE-242870-C 1912 DE-255770-C 1913 DE-269260-C 1914 DE-281820-C 1915 DE-290010-C 1916 DE-296016-C 1917 DE-303620-C 1918 DE-310930-C 1919 DE-318790-C","title":"Results"},{"location":"DE_MODEL_CARD/","text":"MODELS \u00b6 \u2139\ufe0f Model Overview \u00b6 Name de_ent_depatent01 & de_ent_depatent02 Language German (de) Pipeline ner Authors Bergeaud and Verluise Date (last**) 02/2020 License MIT \ud83d\udc77 Training \u00b6 FORMAT = depatent01 # depatent02 spacy train configs/de_t2vner.cfg --paths.train data/train_ent_ ${ FORMAT } .spacy --paths.dev data/train_ent_ ${ FORMAT } .spacy --output models/de_ent_ ${ FORMAT } \ud83d\udd2e Model Performance \u00b6 de_ent_depatent01/model-best \u00b6 ALL ASG CLAS INV LOC OCC p 0.99 0.98 0.99 0.99 1 0.97 r 0.99 0.99 1 0.96 1 0.98 f 0.99 0.98 1 0.98 1 0.97 de_ent_depatent02/model-best \u00b6 ALL ASG CIT CLAS INV LOC OCC p 0.99 0.99 0 0.99 0.98 0.99 0.97 r 0.98 0.98 0 1 0.99 0.98 0.97 f 0.98 0.98 0 0.99 0.99 0.98 0.97 \ud83c\udfaf Intended use \u00b6 de_ent_depatent0*_sm have been specifically trained on DE patents (resp DE1C-DE977922C and DE1000001B-). The model's performance are not guaranteed out of this scope. \ud83d\udd02 Versions and alternative approaches \u00b6 Version Comment 0.1 ner - spaCy v2 1.0 ner - spaCy v3","title":"Models"},{"location":"DE_MODEL_CARD/#models","text":"","title":"MODELS"},{"location":"DE_MODEL_CARD/#i-model-overview","text":"Name de_ent_depatent01 & de_ent_depatent02 Language German (de) Pipeline ner Authors Bergeaud and Verluise Date (last**) 02/2020 License MIT","title":"\u2139\ufe0f Model Overview"},{"location":"DE_MODEL_CARD/#training","text":"FORMAT = depatent01 # depatent02 spacy train configs/de_t2vner.cfg --paths.train data/train_ent_ ${ FORMAT } .spacy --paths.dev data/train_ent_ ${ FORMAT } .spacy --output models/de_ent_ ${ FORMAT }","title":"\ud83d\udc77 Training"},{"location":"DE_MODEL_CARD/#model-performance","text":"","title":"\ud83d\udd2e Model Performance"},{"location":"DE_MODEL_CARD/#de_ent_depatent01model-best","text":"ALL ASG CLAS INV LOC OCC p 0.99 0.98 0.99 0.99 1 0.97 r 0.99 0.99 1 0.96 1 0.98 f 0.99 0.98 1 0.98 1 0.97","title":"de_ent_depatent01/model-best"},{"location":"DE_MODEL_CARD/#de_ent_depatent02model-best","text":"ALL ASG CIT CLAS INV LOC OCC p 0.99 0.99 0 0.99 0.98 0.99 0.97 r 0.98 0.98 0 1 0.99 0.98 0.97 f 0.98 0.98 0 0.99 0.99 0.98 0.97","title":"de_ent_depatent02/model-best"},{"location":"DE_MODEL_CARD/#intended-use","text":"de_ent_depatent0*_sm have been specifically trained on DE patents (resp DE1C-DE977922C and DE1000001B-). The model's performance are not guaranteed out of this scope.","title":"\ud83c\udfaf Intended use"},{"location":"DE_MODEL_CARD/#versions-and-alternative-approaches","text":"Version Comment 0.1 ner - spaCy v2 1.0 ner - spaCy v3","title":"\ud83d\udd02 Versions and alternative approaches"},{"location":"FR/","text":"OVERVIEW \u00b6 Background \u00b6 The patent system was institutionalised in France as early as 1791. However, the French patents published before 1900 have not been made publicly available in a digitised format. Info The French INPI has manually built a database of inventors' locations spanning over the 19th century. This database is however not publicly available. We are not aware of prior work trying to constitute a database of the location of patentees filing in France for the 1900-1980 period. \ud83d\udcda Data source \u00b6 Patent office Time span (publication year) Kind code(s) FR 1902-1980 A, A1 Publication number (range) Data source Pre-processing E.g. Format # FR317502A-FR1569050A (excluded) Espacenet OCR FR328212A 1 FR1605567A-FR2427761A Espacenet OCR FR1595761A 2 Done In total, we consider 1,577,934 documents from 1902 to 1980. \ud83d\ude9c Extraction schema \u00b6 See the annotation guidelines . \ud83d\udd2e Models \u00b6 See the models card . Other \u00b6 See the geocoding and citizenship documentation.","title":"Overview"},{"location":"FR/#overview","text":"","title":"OVERVIEW"},{"location":"FR/#background","text":"The patent system was institutionalised in France as early as 1791. However, the French patents published before 1900 have not been made publicly available in a digitised format. Info The French INPI has manually built a database of inventors' locations spanning over the 19th century. This database is however not publicly available. We are not aware of prior work trying to constitute a database of the location of patentees filing in France for the 1900-1980 period.","title":"Background"},{"location":"FR/#data-source","text":"Patent office Time span (publication year) Kind code(s) FR 1902-1980 A, A1 Publication number (range) Data source Pre-processing E.g. Format # FR317502A-FR1569050A (excluded) Espacenet OCR FR328212A 1 FR1605567A-FR2427761A Espacenet OCR FR1595761A 2 Done In total, we consider 1,577,934 documents from 1902 to 1980.","title":"\ud83d\udcda Data source"},{"location":"FR/#extraction-schema","text":"See the annotation guidelines .","title":"\ud83d\ude9c Extraction schema"},{"location":"FR/#models","text":"See the models card .","title":"\ud83d\udd2e Models"},{"location":"FR/#other","text":"See the geocoding and citizenship documentation.","title":"Other"},{"location":"FR_ANNOTATION_GUIDELINES/","text":"ANNOTATION GUIDELINES \u00b6 Warning GitHub markdown does not fully support visual annotation components (e.g. entity boxes) used below. We invite user interested in the annotation guidelines to download the documents and open it in a development environment supporting extended markdown syntax (e.g. MacDown, PyCharm, etc) and/or save it as a pdf. The patent corpus that we consider for France spans the period 1902-1980 and has 2 types of formats. Preliminary comments \u00b6 The patent corpus that we consider for France has 2 types of formats and spans the period 1902-1980. The first format spans spans the period 1902-1969 (from FR317502A to FR1569050A) while the second format goes from 1969 to the end of our period of interest (from FR1569051A to FR1605567A and then from FR2000001A1). More on patents numbering The patent numbers from 1605567 to 2000000 do not seem to exist. The patents with letter seem to stop at FR1605566A and those with code A1 start at FR2000001. The code of those subsequent patents can also end in A5 if the publication is unique (otherwise, the A1 publication is associated with a later but basically identical B1 publication). Format 1 , from FR317502A to FR1569050A. \u00b6 Information display \u00b6 The information we are interested is in the header. The upper part of the header contains generic terms like the name of the institution and its seal, the patent's publication number and its technological class code. The lower part of the header contains a brief description of the content of the invention and the information about the assignee (name and location). Those two distinct information can be blended together in the same sentence or not. Finally a last sentence gives indicates the date at which the patent has been granted as well as the publication date. More on format 1 We notice some slight changes within this format across time. Technological class: up until FR1096200A, the patents provide a French technological class. From patent FR1096201A to patent FR1196800A, both the French technological class as well as the international technological class are mentioned in the header. Finally, starting with patent FR1196801A, only the international technlogical class is retained. Location: It appears only from FR328212A. The assignee's country of residence is then mentioned. Starting with the patent FR371349A, the county is mentioned when the assignee's country is France (otherwise, only the country is reported). Information extraction \u00b6 We extract 4 different \"entities\" from the header of FR patents in format category 1. Entity Content E.g ASG Assignee full name M. Robert John Jocelyn SWAN ASG r\u00e9sidant en Angleterre INV Inventor full name (Demande de brevet d\u00e9pos\u00e9e aux Etats-Unis d'Am\u00e9rique au nom de M. Ladislas Charles MATSCH INV ) LOC Location of the assignee/inventor M. Louis LEGRAND r\u00e9sidant en France LOC . CLAS Technological class (French system) XII Instruments de pr\u00e9cision 3 POIDS ET MESURES, INSTRUMENTS DE MATHEMMATIQUES CLAS Assignees (or inventors) and their corresponding geographic indication are tied together through the relation \"LOCATION\". Relation Content E.g. LOCATION Links an ASG / INV to a LOC M.Frederic PERDRIZET ASG --> LOCATION --> France (Gironde) LOC Format 2 , from FR1569051A to FR1605567A and then from FR2000001A1. \u00b6 Information display \u00b6 The main body of text disappears from the first page of the patent and information are presented in a more \"tabulated\" manner: there are lines and they are associated with a number. For instance, in all of those \"Format 2\" patents, the line with the number 54 gives the title of the invention. In this format: The \"D\u00e9posant\" refers to the assignee. It contains its name as well as its location (usually introduced by the expression \" r\u00e9sidant en/au/aux \"). The line \" Invention \" (or \" Invention de \") can be filled with the name of the inventor, although it is often empty (for instance, FR1595761A has an inventor, while FR2000001A1 does not). More on format 2 Attributes reported but not extracted: Mandataire: A \"Mandataire\" is a specilalised entity that files the patents on behalf of their client -the inventor. It appears in format 2. Technological class: The international technology class is reported Information extraction \u00b6 We extract 3 different \"entities\" from the header of FR patents in format category 2. Entity Content E.g ASG Assignee full name D\u00e9posant: Soci\u00e9t\u00e9 dite: SALZDETFURTH A.G ASG , r\u00e9sidant en R\u00e9publique F\u00e9d\u00e9rale d'Allemagne INV Inventor(s) full name Invention de: Takaya Endo INV , Shui Sato INV , Shoji Kikuchi INV , Koichi Takabe INV , Hiroyuki Imamura INV , Tamotsu Kozima INV et Tugumoto Usui INV LOC Location of the assignee/inventor D\u00e9posant: Soci\u00e9t\u00e9 dite: ROBERT BOSCH GBMH, r\u00e9sidant en R\u00e9publique F\u00e9d\u00e9rale d'Allemagne LOC . Assignees (or inventors) and their corresponding geographic indication are tied together through the relation \"LOCATION\". Relation Content E.g. LOCATION Links an ASG / INV to a LOC KONISHIROKU PHOTO INDUSTRY CO LTD ASG --> LOCATION --> Japon LOC Entities \u00b6 Format 1 \u00b6 ASG \u00b6 General case \u00b6 The tag ASG refers to the full name of an assignee, either a firm or a person. Specific cases \u00b6 Former name : When the assignee is a firm whose name changed over time, its former name might be reported along with its current one. We do not keep the former name. See example 4. Examples Standard Case with several persons, from patent FR504101 MM. Joseph MARTINENGO ASG et Jean-Baptiste GAUDON ASG r\u00e9sidant en France (Loire) Standard Case with a person and a firm, from patent FR60167E** M. Franz DOMALSKY ASG et SOCIETE DES ACIERIES DE LONGWY ASG r\u00e9sidant: le 1er en Sarre; la 2e en France (Seine) Standard Case with a firm, from patent FR953956 Soci\u00e9t\u00e9 dite: CURRAN INDUSTRIES, INCORPORATED ASG r\u00e9sidant aux Etats-Unis d'Am\u00e9rique Former name , from patent FR1103500 Soci\u00e9t\u00e9 anonyme dite: SOCIETE D'INSTALLATIONS GENERALES ET D'AGENCEMENTS (S.I.G.E.A.C) ASG [anciennement H.CAVECCHI ET FILS] r\u00e9sidant en France (Seine) INV \u00b6 The tag INV refers to the full name of an inventor (this person is explicity referred to as the inventor). Format 1 patents often don't have an inventor who is explicitly referred to as such (meaning, distinctively from the assignee). Examples Standard Case with several inventors, from patent FR1288300 Proc\u00e9d\u00e9 de fabrication des mati\u00e8res mousseuses contenant des groupes ur\u00e9thane (Invention: Rudolf MERTEN INV , G\u00fcnther LOEW INV et Erwin WINDEMUTH INV ) LOC \u00b6 Refers to an indication about the location. It is usually the name of a country when the assignee is not a resident of France. Otherwise, it may be the name of a county with the name of the country (France) in parentheses. N.B : It can happen that no location is associated with an assignee ( cf FR318016A). Examples Standard Case with a foreign country, from patent FR1196800 Soci\u00e9t\u00e9 am\u00e9ricaine dite: BENDIX AVIATION CORPORATION, r\u00e9sidant aux Etats-Unis d'Am\u00e9rique LOC . CLAS \u00b6 Technological class of the patent: the classification is specific to France. In some format 1 patents, only the CPC (international) class is reported, in which case we do not tag anything. Examples Standard Case without text, from patent FR842579 BREVET D'INVENTION Gr.10-Cl.4 CLAS Standard Case with text, from patent FR322801 BREVET D'INVENTION du 5 juillet 1902 IV. ARTS TEXTILES 6. TULLES, DENTLLES ET FILETS, BRODERIES CLAS Format 2 \u00b6 ASG \u00b6 General case \u00b6 The tag ASG refers to the full name of an assignee, either a firm or a person. The name of the assignee is found in line 71: \" D\u00e9posant: \". Specific cases \u00b6 Former name : When the assignee is a firm whose name changed over time, its former name might be reported along with its current one. We do not keep the former name. See example 2. Examples Standard Case with a firm, from patent FR2227040A1 D\u00e9posant: MARATHON OIL COMPANY ASG , r\u00e9sidant aux Etats-Unis d'Am\u00e9rique. Former name , from patent FR2183816A1 D\u00e9posant: Soci\u00e9t\u00e9 dite: FARBWERKE HOECHST A.G ASG` VORMALS MEISTER LUCIUS & BRUNING, r\u00e9sidant en R\u00e9publique F\u00e9d\u00e9rale d'Allemagne. INV \u00b6 General case \u00b6 The tag INV refers to the full name of an inventor. This is a person that is not referred to as the assignee and is specifically referred to as the inventor. Its name is typically found in line 72: \" Invention: \" or \" Invention de: \". Specific cases \u00b6 Inventor in lines 31-33 : Some patents do not report the name of the inventor in the usual line (72) but instead indicate it in lines 31-33 under the entry \"Priorit\u00e9 revendiqu\u00e9e\". See example 2. Examples Standard Case with several inventors, from patent FR2227040A1 Invention de: LaVaun S. Merrill Jr. INV , Dennis Eugene Drayer INV , William Barney Gogarty INV et George Arthur Pouska INV . Inventor in lines 31-33 , from patent FR2306539A1 Priorit\u00e9 revendiqu\u00e9e: Demande de brevet d\u00e9pos\u00e9e aux Etats-Unis d'Am\u00e9rique le 31 mars 1975 au nom de Anthony Sabatino INV . LOC \u00b6 General case \u00b6 Refers to an indication about the location. Again, when assignees are lcoated outside France, the geographic indication usually boils down to the name of the country. Specific cases \u00b6 Address : Sometimes, the patent document might give the full address of the assignee. This only happens for assignees located in France. For the sake of consistency, we only keep the name of the city (and associated zipcode when it is provided). See example 2. State of the Headquarters : Typically in the case of an American firm as the assignee, a patent might report the US state in which this firm is headquartered. Again, because the instances are rare and for the sake of consistency, we tag only he country of residence. See example 3. Examples Standard Case with a foreign (different from France) country, from patent FR2227040A1 D\u00e9posant: MARATHON OIL COMPANY, r\u00e9sidant aux Etats-Unis d'Am\u00e9rique LOC Address , from patent FR2132583A1 D\u00e9posant: GUILLON Marcel, 6, avenue Paderi, Regina Cottage, 06-Nice LOC State of the Headquarters , from patent FR2259617A1 D\u00e9posant: Organisme dit: UNIVERSITE DE PENNSYLVANIE. Constitu\u00e9e selon les lois de l'Etat de Pennsylvanie, r\u00e9sidant aux Etats-Unis d'Am\u00e9rique LOC . Relationships \u00b6 See the common annotation guidelines . Examples \u00b6 Example 1: Format 1 without geographic indications \u00b6 Example 2: Format 1 with a geographic indication (country only) \u00b6 Example 3: Format 1 with an inventor \u00b6 Example 4: Format 2 without an inventor and with a foreign (non French) assignee \u00b6 Example 5: Format 2 with an inventor and a county (French assignee) \u00b6","title":"Annotation Guidelines"},{"location":"FR_ANNOTATION_GUIDELINES/#annotation-guidelines","text":"Warning GitHub markdown does not fully support visual annotation components (e.g. entity boxes) used below. We invite user interested in the annotation guidelines to download the documents and open it in a development environment supporting extended markdown syntax (e.g. MacDown, PyCharm, etc) and/or save it as a pdf. The patent corpus that we consider for France spans the period 1902-1980 and has 2 types of formats.","title":"ANNOTATION GUIDELINES"},{"location":"FR_ANNOTATION_GUIDELINES/#preliminary-comments","text":"The patent corpus that we consider for France has 2 types of formats and spans the period 1902-1980. The first format spans spans the period 1902-1969 (from FR317502A to FR1569050A) while the second format goes from 1969 to the end of our period of interest (from FR1569051A to FR1605567A and then from FR2000001A1). More on patents numbering The patent numbers from 1605567 to 2000000 do not seem to exist. The patents with letter seem to stop at FR1605566A and those with code A1 start at FR2000001. The code of those subsequent patents can also end in A5 if the publication is unique (otherwise, the A1 publication is associated with a later but basically identical B1 publication).","title":"Preliminary comments"},{"location":"FR_ANNOTATION_GUIDELINES/#format-1-from-fr317502a-to-fr1569050a","text":"","title":"Format 1, from FR317502A to FR1569050A."},{"location":"FR_ANNOTATION_GUIDELINES/#information-display","text":"The information we are interested is in the header. The upper part of the header contains generic terms like the name of the institution and its seal, the patent's publication number and its technological class code. The lower part of the header contains a brief description of the content of the invention and the information about the assignee (name and location). Those two distinct information can be blended together in the same sentence or not. Finally a last sentence gives indicates the date at which the patent has been granted as well as the publication date. More on format 1 We notice some slight changes within this format across time. Technological class: up until FR1096200A, the patents provide a French technological class. From patent FR1096201A to patent FR1196800A, both the French technological class as well as the international technological class are mentioned in the header. Finally, starting with patent FR1196801A, only the international technlogical class is retained. Location: It appears only from FR328212A. The assignee's country of residence is then mentioned. Starting with the patent FR371349A, the county is mentioned when the assignee's country is France (otherwise, only the country is reported).","title":"Information display"},{"location":"FR_ANNOTATION_GUIDELINES/#information-extraction","text":"We extract 4 different \"entities\" from the header of FR patents in format category 1. Entity Content E.g ASG Assignee full name M. Robert John Jocelyn SWAN ASG r\u00e9sidant en Angleterre INV Inventor full name (Demande de brevet d\u00e9pos\u00e9e aux Etats-Unis d'Am\u00e9rique au nom de M. Ladislas Charles MATSCH INV ) LOC Location of the assignee/inventor M. Louis LEGRAND r\u00e9sidant en France LOC . CLAS Technological class (French system) XII Instruments de pr\u00e9cision 3 POIDS ET MESURES, INSTRUMENTS DE MATHEMMATIQUES CLAS Assignees (or inventors) and their corresponding geographic indication are tied together through the relation \"LOCATION\". Relation Content E.g. LOCATION Links an ASG / INV to a LOC M.Frederic PERDRIZET ASG --> LOCATION --> France (Gironde) LOC","title":"Information extraction"},{"location":"FR_ANNOTATION_GUIDELINES/#format-2-from-fr1569051a-to-fr1605567a-and-then-from-fr2000001a1","text":"","title":"Format 2, from FR1569051A to FR1605567A and then from FR2000001A1."},{"location":"FR_ANNOTATION_GUIDELINES/#information-display_1","text":"The main body of text disappears from the first page of the patent and information are presented in a more \"tabulated\" manner: there are lines and they are associated with a number. For instance, in all of those \"Format 2\" patents, the line with the number 54 gives the title of the invention. In this format: The \"D\u00e9posant\" refers to the assignee. It contains its name as well as its location (usually introduced by the expression \" r\u00e9sidant en/au/aux \"). The line \" Invention \" (or \" Invention de \") can be filled with the name of the inventor, although it is often empty (for instance, FR1595761A has an inventor, while FR2000001A1 does not). More on format 2 Attributes reported but not extracted: Mandataire: A \"Mandataire\" is a specilalised entity that files the patents on behalf of their client -the inventor. It appears in format 2. Technological class: The international technology class is reported","title":"Information display"},{"location":"FR_ANNOTATION_GUIDELINES/#information-extraction_1","text":"We extract 3 different \"entities\" from the header of FR patents in format category 2. Entity Content E.g ASG Assignee full name D\u00e9posant: Soci\u00e9t\u00e9 dite: SALZDETFURTH A.G ASG , r\u00e9sidant en R\u00e9publique F\u00e9d\u00e9rale d'Allemagne INV Inventor(s) full name Invention de: Takaya Endo INV , Shui Sato INV , Shoji Kikuchi INV , Koichi Takabe INV , Hiroyuki Imamura INV , Tamotsu Kozima INV et Tugumoto Usui INV LOC Location of the assignee/inventor D\u00e9posant: Soci\u00e9t\u00e9 dite: ROBERT BOSCH GBMH, r\u00e9sidant en R\u00e9publique F\u00e9d\u00e9rale d'Allemagne LOC . Assignees (or inventors) and their corresponding geographic indication are tied together through the relation \"LOCATION\". Relation Content E.g. LOCATION Links an ASG / INV to a LOC KONISHIROKU PHOTO INDUSTRY CO LTD ASG --> LOCATION --> Japon LOC","title":"Information extraction"},{"location":"FR_ANNOTATION_GUIDELINES/#entities","text":"","title":"Entities"},{"location":"FR_ANNOTATION_GUIDELINES/#format-1","text":"","title":"Format 1"},{"location":"FR_ANNOTATION_GUIDELINES/#asg","text":"","title":"ASG"},{"location":"FR_ANNOTATION_GUIDELINES/#general-case","text":"The tag ASG refers to the full name of an assignee, either a firm or a person.","title":"General case"},{"location":"FR_ANNOTATION_GUIDELINES/#specific-cases","text":"Former name : When the assignee is a firm whose name changed over time, its former name might be reported along with its current one. We do not keep the former name. See example 4. Examples Standard Case with several persons, from patent FR504101 MM. Joseph MARTINENGO ASG et Jean-Baptiste GAUDON ASG r\u00e9sidant en France (Loire) Standard Case with a person and a firm, from patent FR60167E** M. Franz DOMALSKY ASG et SOCIETE DES ACIERIES DE LONGWY ASG r\u00e9sidant: le 1er en Sarre; la 2e en France (Seine) Standard Case with a firm, from patent FR953956 Soci\u00e9t\u00e9 dite: CURRAN INDUSTRIES, INCORPORATED ASG r\u00e9sidant aux Etats-Unis d'Am\u00e9rique Former name , from patent FR1103500 Soci\u00e9t\u00e9 anonyme dite: SOCIETE D'INSTALLATIONS GENERALES ET D'AGENCEMENTS (S.I.G.E.A.C) ASG [anciennement H.CAVECCHI ET FILS] r\u00e9sidant en France (Seine)","title":"Specific cases"},{"location":"FR_ANNOTATION_GUIDELINES/#inv","text":"The tag INV refers to the full name of an inventor (this person is explicity referred to as the inventor). Format 1 patents often don't have an inventor who is explicitly referred to as such (meaning, distinctively from the assignee). Examples Standard Case with several inventors, from patent FR1288300 Proc\u00e9d\u00e9 de fabrication des mati\u00e8res mousseuses contenant des groupes ur\u00e9thane (Invention: Rudolf MERTEN INV , G\u00fcnther LOEW INV et Erwin WINDEMUTH INV )","title":"INV"},{"location":"FR_ANNOTATION_GUIDELINES/#loc","text":"Refers to an indication about the location. It is usually the name of a country when the assignee is not a resident of France. Otherwise, it may be the name of a county with the name of the country (France) in parentheses. N.B : It can happen that no location is associated with an assignee ( cf FR318016A). Examples Standard Case with a foreign country, from patent FR1196800 Soci\u00e9t\u00e9 am\u00e9ricaine dite: BENDIX AVIATION CORPORATION, r\u00e9sidant aux Etats-Unis d'Am\u00e9rique LOC .","title":"LOC"},{"location":"FR_ANNOTATION_GUIDELINES/#clas","text":"Technological class of the patent: the classification is specific to France. In some format 1 patents, only the CPC (international) class is reported, in which case we do not tag anything. Examples Standard Case without text, from patent FR842579 BREVET D'INVENTION Gr.10-Cl.4 CLAS Standard Case with text, from patent FR322801 BREVET D'INVENTION du 5 juillet 1902 IV. ARTS TEXTILES 6. TULLES, DENTLLES ET FILETS, BRODERIES CLAS","title":"CLAS"},{"location":"FR_ANNOTATION_GUIDELINES/#format-2","text":"","title":"Format 2"},{"location":"FR_ANNOTATION_GUIDELINES/#asg_1","text":"","title":"ASG"},{"location":"FR_ANNOTATION_GUIDELINES/#general-case_1","text":"The tag ASG refers to the full name of an assignee, either a firm or a person. The name of the assignee is found in line 71: \" D\u00e9posant: \".","title":"General case"},{"location":"FR_ANNOTATION_GUIDELINES/#specific-cases_1","text":"Former name : When the assignee is a firm whose name changed over time, its former name might be reported along with its current one. We do not keep the former name. See example 2. Examples Standard Case with a firm, from patent FR2227040A1 D\u00e9posant: MARATHON OIL COMPANY ASG , r\u00e9sidant aux Etats-Unis d'Am\u00e9rique. Former name , from patent FR2183816A1 D\u00e9posant: Soci\u00e9t\u00e9 dite: FARBWERKE HOECHST A.G ASG` VORMALS MEISTER LUCIUS & BRUNING, r\u00e9sidant en R\u00e9publique F\u00e9d\u00e9rale d'Allemagne.","title":"Specific cases"},{"location":"FR_ANNOTATION_GUIDELINES/#inv_1","text":"","title":"INV"},{"location":"FR_ANNOTATION_GUIDELINES/#general-case_2","text":"The tag INV refers to the full name of an inventor. This is a person that is not referred to as the assignee and is specifically referred to as the inventor. Its name is typically found in line 72: \" Invention: \" or \" Invention de: \".","title":"General case"},{"location":"FR_ANNOTATION_GUIDELINES/#specific-cases_2","text":"Inventor in lines 31-33 : Some patents do not report the name of the inventor in the usual line (72) but instead indicate it in lines 31-33 under the entry \"Priorit\u00e9 revendiqu\u00e9e\". See example 2. Examples Standard Case with several inventors, from patent FR2227040A1 Invention de: LaVaun S. Merrill Jr. INV , Dennis Eugene Drayer INV , William Barney Gogarty INV et George Arthur Pouska INV . Inventor in lines 31-33 , from patent FR2306539A1 Priorit\u00e9 revendiqu\u00e9e: Demande de brevet d\u00e9pos\u00e9e aux Etats-Unis d'Am\u00e9rique le 31 mars 1975 au nom de Anthony Sabatino INV .","title":"Specific cases"},{"location":"FR_ANNOTATION_GUIDELINES/#loc_1","text":"","title":"LOC"},{"location":"FR_ANNOTATION_GUIDELINES/#general-case_3","text":"Refers to an indication about the location. Again, when assignees are lcoated outside France, the geographic indication usually boils down to the name of the country.","title":"General case"},{"location":"FR_ANNOTATION_GUIDELINES/#specific-cases_3","text":"Address : Sometimes, the patent document might give the full address of the assignee. This only happens for assignees located in France. For the sake of consistency, we only keep the name of the city (and associated zipcode when it is provided). See example 2. State of the Headquarters : Typically in the case of an American firm as the assignee, a patent might report the US state in which this firm is headquartered. Again, because the instances are rare and for the sake of consistency, we tag only he country of residence. See example 3. Examples Standard Case with a foreign (different from France) country, from patent FR2227040A1 D\u00e9posant: MARATHON OIL COMPANY, r\u00e9sidant aux Etats-Unis d'Am\u00e9rique LOC Address , from patent FR2132583A1 D\u00e9posant: GUILLON Marcel, 6, avenue Paderi, Regina Cottage, 06-Nice LOC State of the Headquarters , from patent FR2259617A1 D\u00e9posant: Organisme dit: UNIVERSITE DE PENNSYLVANIE. Constitu\u00e9e selon les lois de l'Etat de Pennsylvanie, r\u00e9sidant aux Etats-Unis d'Am\u00e9rique LOC .","title":"Specific cases"},{"location":"FR_ANNOTATION_GUIDELINES/#relationships","text":"See the common annotation guidelines .","title":"Relationships"},{"location":"FR_ANNOTATION_GUIDELINES/#examples","text":"","title":"Examples"},{"location":"FR_ANNOTATION_GUIDELINES/#example-1-format-1-without-geographic-indications","text":"","title":"Example 1: Format 1 without geographic indications"},{"location":"FR_ANNOTATION_GUIDELINES/#example-2-format-1-with-a-geographic-indication-country-only","text":"","title":"Example 2: Format 1 with a geographic indication (country only)"},{"location":"FR_ANNOTATION_GUIDELINES/#example-3-format-1-with-an-inventor","text":"","title":"Example 3: Format 1 with an inventor"},{"location":"FR_ANNOTATION_GUIDELINES/#example-4-format-2-without-an-inventor-and-with-a-foreign-non-french-assignee","text":"","title":"Example 4: Format 2 without an inventor and with a foreign (non French) assignee"},{"location":"FR_ANNOTATION_GUIDELINES/#example-5-format-2-with-an-inventor-and-a-county-french-assignee","text":"","title":"Example 5: Format 2 with an inventor and a county (French assignee)"},{"location":"FR_MODEL_CARD/","text":"OVERVIEW \u00b6 \u2139\ufe0f Model Overview \u00b6 Name fr_ent_frpatent01 & fr_ent_frpatent02 Language French (fr) Pipeline ner Authors Bergeaud and Verluise Date (last) 02/2021 License MIT \ud83d\udc77 Training \u00b6 FORMAT = frpatent01 # frpatent02 spacy train configs/fr_t2vner.cfg --paths.train data/train_ent_ ${ FORMAT } .spacy --paths.dev data/train_ent_ ${ FORMAT } .spacy --output models/de_ent_ ${ FORMAT } \ud83d\udd2e Model performance \u00b6 fr_ent_frpatent01/model-best \u00b6 ALL ASG CLAS INV LOC p 0.97 0.99 0.93 0.99 0.99 r 0.97 0.99 0.93 1 0.99 f 0.97 0.99 0.93 0.99 0.99 fr_ent_frpatent02/model-best \u00b6 ALL ASG INV LOC p 0.98 0.98 0.99 0.99 r 0.98 0.98 0.98 0.99 f 0.98 0.98 0.98 0.99 \ud83c\udfaf Intended use \u00b6 en_ent_frpatent0* have been specifically trained on FR patents (resp FR317502A-FR1569050A and FR1605567A-FR2427761A). The model's performance are not guaranteed out of this scope. \ud83d\udd02 Versions and alternative approaches \u00b6 Version Comment 0.1 ent - v2 spaCy 1.0 ent - v3 spaCy","title":"Models"},{"location":"FR_MODEL_CARD/#overview","text":"","title":"OVERVIEW"},{"location":"FR_MODEL_CARD/#i-model-overview","text":"Name fr_ent_frpatent01 & fr_ent_frpatent02 Language French (fr) Pipeline ner Authors Bergeaud and Verluise Date (last) 02/2021 License MIT","title":"\u2139\ufe0f Model Overview"},{"location":"FR_MODEL_CARD/#training","text":"FORMAT = frpatent01 # frpatent02 spacy train configs/fr_t2vner.cfg --paths.train data/train_ent_ ${ FORMAT } .spacy --paths.dev data/train_ent_ ${ FORMAT } .spacy --output models/de_ent_ ${ FORMAT }","title":"\ud83d\udc77 Training"},{"location":"FR_MODEL_CARD/#model-performance","text":"","title":"\ud83d\udd2e Model performance"},{"location":"FR_MODEL_CARD/#fr_ent_frpatent01model-best","text":"ALL ASG CLAS INV LOC p 0.97 0.99 0.93 0.99 0.99 r 0.97 0.99 0.93 1 0.99 f 0.97 0.99 0.93 0.99 0.99","title":"fr_ent_frpatent01/model-best"},{"location":"FR_MODEL_CARD/#fr_ent_frpatent02model-best","text":"ALL ASG INV LOC p 0.98 0.98 0.99 0.99 r 0.98 0.98 0.98 0.99 f 0.98 0.98 0.98 0.99","title":"fr_ent_frpatent02/model-best"},{"location":"FR_MODEL_CARD/#intended-use","text":"en_ent_frpatent0* have been specifically trained on FR patents (resp FR317502A-FR1569050A and FR1605567A-FR2427761A). The model's performance are not guaranteed out of this scope.","title":"\ud83c\udfaf Intended use"},{"location":"FR_MODEL_CARD/#versions-and-alternative-approaches","text":"Version Comment 0.1 ent - v2 spaCy 1.0 ent - v3 spaCy","title":"\ud83d\udd02 Versions and alternative approaches"},{"location":"GB/","text":"GB \u00b6 Background \u00b6 Although evidence of an earlier version of patents can be found in 1449, the British patent system starts in 1623 (Plasseraud and Savignon, 1983). There were no official publications prior to 1852. To our knowledges, most patent publications earlier than 1894 have not been digitized, and some are still missing from 1894 to 1900. \ud83d\udcda Data source \u00b6 Patent office Time span (publication year) Kind code(s) GB 1893-1980 A Publication number (range) Data source Pre-processing E.g. Format # GB189317126A-GB2000001A (excluded) Espacenet OCR GB309428A 1 GB2000001A-GB2023380A Espacenet OCR GB2016002A 2 Done In total, we consider 1,780,385 documents from 1894 to 1980. \ud83d\ude9c Extraction schema \u00b6 See the annotation guidelines . \ud83d\udd2e Models \u00b6 See the models card . Other \u00b6 See the geocoding and citizenship documentation.","title":"Overview"},{"location":"GB/#gb","text":"","title":"GB"},{"location":"GB/#background","text":"Although evidence of an earlier version of patents can be found in 1449, the British patent system starts in 1623 (Plasseraud and Savignon, 1983). There were no official publications prior to 1852. To our knowledges, most patent publications earlier than 1894 have not been digitized, and some are still missing from 1894 to 1900.","title":"Background"},{"location":"GB/#data-source","text":"Patent office Time span (publication year) Kind code(s) GB 1893-1980 A Publication number (range) Data source Pre-processing E.g. Format # GB189317126A-GB2000001A (excluded) Espacenet OCR GB309428A 1 GB2000001A-GB2023380A Espacenet OCR GB2016002A 2 Done In total, we consider 1,780,385 documents from 1894 to 1980.","title":"\ud83d\udcda Data source"},{"location":"GB/#extraction-schema","text":"See the annotation guidelines .","title":"\ud83d\ude9c Extraction schema"},{"location":"GB/#models","text":"See the models card .","title":"\ud83d\udd2e Models"},{"location":"GB/#other","text":"See the geocoding and citizenship documentation.","title":"Other"},{"location":"GB_ANNOTATION_GUIDELINES/","text":"ANNOTATION GUIDELINES \u00b6 Warning GitHub markdown does not fully support visual annotation components (e.g. entity boxes) used below. We invite user interested in the annotation guidelines to download the documents and open it in a development environment supporting extended markdown syntax (e.g. MacDown, PyCharm, etc) and/or save it as a pdf. Preliminary comments \u00b6 The patent corpus that we consider for GB has two types of formats and spans the period 1893-1980. The formatting of UK patent documents have evolved in time but only modestly. Typically, until patent number GB2000001, the first paragraph of the text contains most of the relevant information, which are completed by the header, whose content changes slightly over time. See Figures 1, 2 and 3 for different examples. From GB2000001 onward, the information are located in the front-page of the patent in a structured way (see Figure 4 for an example). This only concerns 23,889 patent documents as we stop the analysis in 1980. More on GB patents numbering Prior to 1916, patent number is given by a number preceded by the year of application From 1916, patents are numbered from 100001 to 1605470 and then from 2000001 onward. The last application we consider is 2023380 Format 1 , from 1894 to 1979 \u00b6 In the first format, from 1894 to 1979, all the information is given in the first paragraph, which starts by \"I, \" or \"We, \" and usually ends with \"do hereby declare the nature of this invention to be as follows\" or \"for which we pray that a patent may be granted to us...\" We extract 5 different \"entities\" from the body of GB patents. Entity Content E.g. PERS Person full name Maxim Hanson Hersey PERS , Lighting Engineer ORG Firm full name We, The Convex Incandescent Mantle Company Limited ORG , Manufacturers CIT The origin of the firm or citizenship of the person a subject of the king of Great Britain and Ireland CIT , LOC Location of the person/firm Maxim Hanson Hersey, Lighting Engineer, of 145, Bethune Road, Amhurst Park, London N. LOC . OCC Occupation of the person Maxim Hanson Hersey, Lighting Engineer OCC . These entities are tied together with 3 types of relations. Relation Content E.g. CITIZENSHIP Links an ORG / PERS to its CIT Maxim Hanson Hersey PERS --> CITIZENSHIP --> subject of the king of Great Britain and Ireland CIT LOCATION Links an ORG / PERS to its LOC Maxim Hanson Hersey PERS --> LOCATION --> 145, Bethune Road, Amhurst Park, London N. LOC OCCUPATION Links an PERS to its OCC Maxim Hanson Hersey PERS --> OCCUPATION --> Lighting Engineer OCC Specific labelling issues In some cases the text of the patent is repeated twice in the same document, once for the provisionnal specification and once for the complete specification (see e.g. GB132951A). In such case, all relevant entities must be labelled, even if this means labelling the same entities twice. -In some cases, the name of the inventor, the name of the assignee and even its address can appear at the end of the patent. Those entities must not be labelled (e.g. GB509140A). Other meta-data in GB patents The header contains some specific information including: the publication date the acceptance date the application number the publication number the title the technological class the name of the inventor(s) - in some instance Format 2 \u00b6 In the second format, restricted to the year 1979, the information are structured in the front page of the patent. For these patents, the identity of the inventor and the assignee are clearly stated, but only the location of the assignee is given. Entities \u00b6 Format 1 \u00b6 PERS \u00b6 General case \u00b6 The tag PERS refers to the full name of a patentee person which can or cannot be directly presented as the inventor. This name usually follows \"I, \" or \"We, \" and is given in capital letters. Specific cases \u00b6 Inventor name in the header : The name of the inventor can also be specified in the header, preceded by the mention \"Inventor(s):\" and usually in capital letters. In this case, we label the inventor(s) as PERS . See example 2. Third party : In the rare case where the inventor uses a third party to file the application (deceased, mandated), we don't tag the third party person. See example 3 where we do not tag \"HAROLD WADE\" as a PERS because the context tells us that he is not the inventor. Examples standard case , from patent GB150481 We, ANTHONY FULFORD READ PERS , 18, Fown Terrace, Brighton, Manufacturers' Agent, and HAROLD NORMAL READ PERS , 18 Down Terrace, Brighton, Manufacturer's Agent. inventor name in the header , from patent GB1222048 Inventors WALTER BUNGARD PERS and HANS ZEHNPFENNIG PERS Improvements in or relating to bearings and bearing liners We, T.H. GOLDSCHMIDT A.G., a body corporate organised under the Laws of Germany, third party , from patent GB191413361 (A communication from CHARLES LOUIS MICHOD PERS , Manufacturer, of Chicago Heights, Illinois, United States of. America.) I, HAROLD WADE, Chartered Patent Agent, of 111 and 112, Hatton Garden, London, E.C., do hereby declare... dead , from patent GB1046893 We, LEVI CLEWS PERS of 140, Finch Road, Birmingham 19, a British Subject, and FRANCES MABEL GROVES, a British subject, of 41 Ettington Road, Aston, Birmingham 6, legal representative of the late Alfred Groves PERS deceased, a British subject of 140 Finch Road, Birmingham 19, do hereby declare... assignees of , from patent GB664753** We, EASTMAN KODAK COMPANY, a Corporation organised under the laws of the State of New Jersey, United States of Aiuevica, of 343, State Street, Rochester, New York, United States of America (Assignees of Fred Waller PERS , a citizen of the United States of America, of 1925, New York Avenue, Huntington Station, New York, United States of America) ORG \u00b6 General case \u00b6 The tag ORG refers to the full name of the organisation which owns the patent. This name usually follows \"We, \" and is given in capital letters. Specific cases \u00b6 Third party : Similarly to the tag PERS , we do not tag a third party as an ORG if the context tells us that this is not a patentee. Former name : Do not label the former name of the company when it is given. See example 3. Examples standard case , from patent GB848511 We, LONZA ELECTRIC AND CHEMICAL WORKS LIMITED ORG , a Swiss Body Corporate of Aeschenvorstadt 72, Basel, do hereby declare the invention for which we pray... standard case , from patent GB757350 We, W.S. BARRETT & SON LIMITED ORG a British Company of 106-108, West Street, Boston, Lincolnshire, do hereby declare... former name , from patent GB786015 We, THE SCHOLL MFG Co LIMITED ORG , formerly The Scholl Manufacturing Company Limited, a British Company, of 190 St John Street, London, E.C l, England, do hereby declare... CIT \u00b6 General case \u00b6 The tag CIT refers to the citizenship of a PERS or by the origin of a ORG . In the first case, it is usually given in the form \"A British citizen\" or \"A subject of the King of Britain\". In the second case, it is usually given in the form \"A company of Sweden\". The full sequence must be tagged, that is, including \"a citizen\", \"a subject\" or \"a company\". Specific cases \u00b6 ORG from US : When a company is registered in the US, the sequence can be long and include the state of origin. See example 3. Examples origin of ORG , from patent GB784551 We, PROGRESS MERCANTILE COMPANY LIMITED, a British Company CIT , formerly of 19 Malden Crescent London, N.W.1 ... origin of PERS , from patent GB500752 I, HAROLD FREDERICK MAGNUS, of 79 to 82, Fore Street, London E.C.2, British Subject CIT , do hereby declare... ORG from the US , from patent GB388752 We, ASSOCIATED TELEPHONE & TELEGRAPH COMPANY, of 1033, West Van Buren Street, Chicago, Illinois, United States of America, a corporation organised under the laws of the State of Delaware, United States of America CIT , do hereby declare... OCC \u00b6 General case \u00b6 The tag OCC refers to the occupation of a PERS or in some rare case of the type of a firm. Examples OCC of PERS from patent GB163765 I, HENRY ART KING, Mechanical Draftsman OCC , residing at No. 2012, Linden Avenue et the City of Baltimore, and State of Maryland... OCC of PERS and ORG from patent GB145878 We, M. HOWLETT AND COMPANY LIMITED, of 140 Hockley Hill, Birmingham, Manufacturers OCC , and JAMES DOLPHIN of 23, Carless Avenue, Harborne, Birmingham, Works Manager OCC , do hereby declare... LOC \u00b6 General case \u00b6 The tag LOC refers to the full location sequence either of a tag PERS or a tag ORG . The address can be given as a full sequence with street number, street name, city, county and country. It can also be simply given by the name of the city/town/village and county (see example 2), or by a postcode (see example 3). In some cases, the location refers to a specific building (see example 4) or university (example 5) and in some other cases, the name of a nearby city is specified (see example 6). Specific cases \u00b6 Non-patentee location : the tag LOC should only be used to label the address of the inventor or the assignee based on the context (i.e. an entity PERS or ORG ). Examples full address , from patent GB1910000882 Improvements in or relating to Tobacco Pipes, Cigar and Cigarette Holders. I, FRANK WOOD, of 4, Rawes Street, Burnley, in the County of lancaster LOC , Commission Agent, do hereby ... city+ , from patent GB850480 We, DEPARTMENT of MINES, a Department of the Provincial Government of Quebec, Quebec City, Province of Quebec, Canada LOC ,, do hereby... post-code from patent GB1254482 Improved Cylinder Lock Mechanism. We OY WARTSILA AB, a Finnish Company of Box 10230, Helsinki 10, Finland LOC , do hereby... building+ , from patent GB937358 We, MARCONI'S WIRELESS TELEGRAPH COMPANY LIIMITED of English Electric House, Strand, London, W.C.2 LOC , a British Company, do hereby declare... university , from patent GB332692 I, ARTHUR SIMEON WATT, a citizen of the United States of America, of Ohio University, in the City of columbus, State of Ohio, United States of America LOC , do hereby declare... former address , from patent GB1018822 I, HUSSAIN ALI MOONTASIR, a citizen of the British Commonwealth, of 29, Beechwood Avenue, Kew, Surrey LOC , (formerly of 409, Mistery Chambers opposite Strand Cinema, Colaba, Bombay 5, India), do hereby declare... nearby city , from patent GB1114180** I, DENNIS ROBERT CHASE, a British Subject, of 29 St John's Road, Locksheath, Near Southampton, Hampshire LOC . Relationships \u00b6 See the common annotation guidelines . Examples \u00b6 Figure 1: GB309428A \u00b6 Figure 2: GB979428A \u00b6 Figure 3: GB1309428A \u00b6 Figure 3: GB2016002A \u00b6","title":"Annotation Guidelines"},{"location":"GB_ANNOTATION_GUIDELINES/#annotation-guidelines","text":"Warning GitHub markdown does not fully support visual annotation components (e.g. entity boxes) used below. We invite user interested in the annotation guidelines to download the documents and open it in a development environment supporting extended markdown syntax (e.g. MacDown, PyCharm, etc) and/or save it as a pdf.","title":"ANNOTATION GUIDELINES"},{"location":"GB_ANNOTATION_GUIDELINES/#preliminary-comments","text":"The patent corpus that we consider for GB has two types of formats and spans the period 1893-1980. The formatting of UK patent documents have evolved in time but only modestly. Typically, until patent number GB2000001, the first paragraph of the text contains most of the relevant information, which are completed by the header, whose content changes slightly over time. See Figures 1, 2 and 3 for different examples. From GB2000001 onward, the information are located in the front-page of the patent in a structured way (see Figure 4 for an example). This only concerns 23,889 patent documents as we stop the analysis in 1980. More on GB patents numbering Prior to 1916, patent number is given by a number preceded by the year of application From 1916, patents are numbered from 100001 to 1605470 and then from 2000001 onward. The last application we consider is 2023380","title":"Preliminary comments"},{"location":"GB_ANNOTATION_GUIDELINES/#format-1-from-1894-to-1979","text":"In the first format, from 1894 to 1979, all the information is given in the first paragraph, which starts by \"I, \" or \"We, \" and usually ends with \"do hereby declare the nature of this invention to be as follows\" or \"for which we pray that a patent may be granted to us...\" We extract 5 different \"entities\" from the body of GB patents. Entity Content E.g. PERS Person full name Maxim Hanson Hersey PERS , Lighting Engineer ORG Firm full name We, The Convex Incandescent Mantle Company Limited ORG , Manufacturers CIT The origin of the firm or citizenship of the person a subject of the king of Great Britain and Ireland CIT , LOC Location of the person/firm Maxim Hanson Hersey, Lighting Engineer, of 145, Bethune Road, Amhurst Park, London N. LOC . OCC Occupation of the person Maxim Hanson Hersey, Lighting Engineer OCC . These entities are tied together with 3 types of relations. Relation Content E.g. CITIZENSHIP Links an ORG / PERS to its CIT Maxim Hanson Hersey PERS --> CITIZENSHIP --> subject of the king of Great Britain and Ireland CIT LOCATION Links an ORG / PERS to its LOC Maxim Hanson Hersey PERS --> LOCATION --> 145, Bethune Road, Amhurst Park, London N. LOC OCCUPATION Links an PERS to its OCC Maxim Hanson Hersey PERS --> OCCUPATION --> Lighting Engineer OCC Specific labelling issues In some cases the text of the patent is repeated twice in the same document, once for the provisionnal specification and once for the complete specification (see e.g. GB132951A). In such case, all relevant entities must be labelled, even if this means labelling the same entities twice. -In some cases, the name of the inventor, the name of the assignee and even its address can appear at the end of the patent. Those entities must not be labelled (e.g. GB509140A). Other meta-data in GB patents The header contains some specific information including: the publication date the acceptance date the application number the publication number the title the technological class the name of the inventor(s) - in some instance","title":"Format 1, from 1894 to 1979"},{"location":"GB_ANNOTATION_GUIDELINES/#format-2","text":"In the second format, restricted to the year 1979, the information are structured in the front page of the patent. For these patents, the identity of the inventor and the assignee are clearly stated, but only the location of the assignee is given.","title":"Format 2"},{"location":"GB_ANNOTATION_GUIDELINES/#entities","text":"","title":"Entities"},{"location":"GB_ANNOTATION_GUIDELINES/#format-1","text":"","title":"Format 1"},{"location":"GB_ANNOTATION_GUIDELINES/#pers","text":"","title":"PERS"},{"location":"GB_ANNOTATION_GUIDELINES/#general-case","text":"The tag PERS refers to the full name of a patentee person which can or cannot be directly presented as the inventor. This name usually follows \"I, \" or \"We, \" and is given in capital letters.","title":"General case"},{"location":"GB_ANNOTATION_GUIDELINES/#specific-cases","text":"Inventor name in the header : The name of the inventor can also be specified in the header, preceded by the mention \"Inventor(s):\" and usually in capital letters. In this case, we label the inventor(s) as PERS . See example 2. Third party : In the rare case where the inventor uses a third party to file the application (deceased, mandated), we don't tag the third party person. See example 3 where we do not tag \"HAROLD WADE\" as a PERS because the context tells us that he is not the inventor. Examples standard case , from patent GB150481 We, ANTHONY FULFORD READ PERS , 18, Fown Terrace, Brighton, Manufacturers' Agent, and HAROLD NORMAL READ PERS , 18 Down Terrace, Brighton, Manufacturer's Agent. inventor name in the header , from patent GB1222048 Inventors WALTER BUNGARD PERS and HANS ZEHNPFENNIG PERS Improvements in or relating to bearings and bearing liners We, T.H. GOLDSCHMIDT A.G., a body corporate organised under the Laws of Germany, third party , from patent GB191413361 (A communication from CHARLES LOUIS MICHOD PERS , Manufacturer, of Chicago Heights, Illinois, United States of. America.) I, HAROLD WADE, Chartered Patent Agent, of 111 and 112, Hatton Garden, London, E.C., do hereby declare... dead , from patent GB1046893 We, LEVI CLEWS PERS of 140, Finch Road, Birmingham 19, a British Subject, and FRANCES MABEL GROVES, a British subject, of 41 Ettington Road, Aston, Birmingham 6, legal representative of the late Alfred Groves PERS deceased, a British subject of 140 Finch Road, Birmingham 19, do hereby declare... assignees of , from patent GB664753** We, EASTMAN KODAK COMPANY, a Corporation organised under the laws of the State of New Jersey, United States of Aiuevica, of 343, State Street, Rochester, New York, United States of America (Assignees of Fred Waller PERS , a citizen of the United States of America, of 1925, New York Avenue, Huntington Station, New York, United States of America)","title":"Specific cases"},{"location":"GB_ANNOTATION_GUIDELINES/#org","text":"","title":"ORG"},{"location":"GB_ANNOTATION_GUIDELINES/#general-case_1","text":"The tag ORG refers to the full name of the organisation which owns the patent. This name usually follows \"We, \" and is given in capital letters.","title":"General case"},{"location":"GB_ANNOTATION_GUIDELINES/#specific-cases_1","text":"Third party : Similarly to the tag PERS , we do not tag a third party as an ORG if the context tells us that this is not a patentee. Former name : Do not label the former name of the company when it is given. See example 3. Examples standard case , from patent GB848511 We, LONZA ELECTRIC AND CHEMICAL WORKS LIMITED ORG , a Swiss Body Corporate of Aeschenvorstadt 72, Basel, do hereby declare the invention for which we pray... standard case , from patent GB757350 We, W.S. BARRETT & SON LIMITED ORG a British Company of 106-108, West Street, Boston, Lincolnshire, do hereby declare... former name , from patent GB786015 We, THE SCHOLL MFG Co LIMITED ORG , formerly The Scholl Manufacturing Company Limited, a British Company, of 190 St John Street, London, E.C l, England, do hereby declare...","title":"Specific cases"},{"location":"GB_ANNOTATION_GUIDELINES/#cit","text":"","title":"CIT"},{"location":"GB_ANNOTATION_GUIDELINES/#general-case_2","text":"The tag CIT refers to the citizenship of a PERS or by the origin of a ORG . In the first case, it is usually given in the form \"A British citizen\" or \"A subject of the King of Britain\". In the second case, it is usually given in the form \"A company of Sweden\". The full sequence must be tagged, that is, including \"a citizen\", \"a subject\" or \"a company\".","title":"General case"},{"location":"GB_ANNOTATION_GUIDELINES/#specific-cases_2","text":"ORG from US : When a company is registered in the US, the sequence can be long and include the state of origin. See example 3. Examples origin of ORG , from patent GB784551 We, PROGRESS MERCANTILE COMPANY LIMITED, a British Company CIT , formerly of 19 Malden Crescent London, N.W.1 ... origin of PERS , from patent GB500752 I, HAROLD FREDERICK MAGNUS, of 79 to 82, Fore Street, London E.C.2, British Subject CIT , do hereby declare... ORG from the US , from patent GB388752 We, ASSOCIATED TELEPHONE & TELEGRAPH COMPANY, of 1033, West Van Buren Street, Chicago, Illinois, United States of America, a corporation organised under the laws of the State of Delaware, United States of America CIT , do hereby declare...","title":"Specific cases"},{"location":"GB_ANNOTATION_GUIDELINES/#occ","text":"","title":"OCC"},{"location":"GB_ANNOTATION_GUIDELINES/#general-case_3","text":"The tag OCC refers to the occupation of a PERS or in some rare case of the type of a firm. Examples OCC of PERS from patent GB163765 I, HENRY ART KING, Mechanical Draftsman OCC , residing at No. 2012, Linden Avenue et the City of Baltimore, and State of Maryland... OCC of PERS and ORG from patent GB145878 We, M. HOWLETT AND COMPANY LIMITED, of 140 Hockley Hill, Birmingham, Manufacturers OCC , and JAMES DOLPHIN of 23, Carless Avenue, Harborne, Birmingham, Works Manager OCC , do hereby declare...","title":"General case"},{"location":"GB_ANNOTATION_GUIDELINES/#loc","text":"","title":"LOC"},{"location":"GB_ANNOTATION_GUIDELINES/#general-case_4","text":"The tag LOC refers to the full location sequence either of a tag PERS or a tag ORG . The address can be given as a full sequence with street number, street name, city, county and country. It can also be simply given by the name of the city/town/village and county (see example 2), or by a postcode (see example 3). In some cases, the location refers to a specific building (see example 4) or university (example 5) and in some other cases, the name of a nearby city is specified (see example 6).","title":"General case"},{"location":"GB_ANNOTATION_GUIDELINES/#specific-cases_3","text":"Non-patentee location : the tag LOC should only be used to label the address of the inventor or the assignee based on the context (i.e. an entity PERS or ORG ). Examples full address , from patent GB1910000882 Improvements in or relating to Tobacco Pipes, Cigar and Cigarette Holders. I, FRANK WOOD, of 4, Rawes Street, Burnley, in the County of lancaster LOC , Commission Agent, do hereby ... city+ , from patent GB850480 We, DEPARTMENT of MINES, a Department of the Provincial Government of Quebec, Quebec City, Province of Quebec, Canada LOC ,, do hereby... post-code from patent GB1254482 Improved Cylinder Lock Mechanism. We OY WARTSILA AB, a Finnish Company of Box 10230, Helsinki 10, Finland LOC , do hereby... building+ , from patent GB937358 We, MARCONI'S WIRELESS TELEGRAPH COMPANY LIIMITED of English Electric House, Strand, London, W.C.2 LOC , a British Company, do hereby declare... university , from patent GB332692 I, ARTHUR SIMEON WATT, a citizen of the United States of America, of Ohio University, in the City of columbus, State of Ohio, United States of America LOC , do hereby declare... former address , from patent GB1018822 I, HUSSAIN ALI MOONTASIR, a citizen of the British Commonwealth, of 29, Beechwood Avenue, Kew, Surrey LOC , (formerly of 409, Mistery Chambers opposite Strand Cinema, Colaba, Bombay 5, India), do hereby declare... nearby city , from patent GB1114180** I, DENNIS ROBERT CHASE, a British Subject, of 29 St John's Road, Locksheath, Near Southampton, Hampshire LOC .","title":"Specific cases"},{"location":"GB_ANNOTATION_GUIDELINES/#relationships","text":"See the common annotation guidelines .","title":"Relationships"},{"location":"GB_ANNOTATION_GUIDELINES/#examples","text":"","title":"Examples"},{"location":"GB_ANNOTATION_GUIDELINES/#figure-1-gb309428a","text":"","title":"Figure 1: GB309428A"},{"location":"GB_ANNOTATION_GUIDELINES/#figure-2-gb979428a","text":"","title":"Figure 2: GB979428A"},{"location":"GB_ANNOTATION_GUIDELINES/#figure-3-gb1309428a","text":"","title":"Figure 3: GB1309428A"},{"location":"GB_ANNOTATION_GUIDELINES/#figure-3-gb2016002a","text":"","title":"Figure 3: GB2016002A"},{"location":"GB_MODEL_CARD/","text":"MODELS \u00b6 \u2139\ufe0f Model Overview \u00b6 Name en_ent_gbpatent01 Language English (en) Pipeline ner Authors Bergeaud and Verluise Date (last) 02/2021 License MIT \ud83d\udc77 Training \u00b6 FORMAT = gbpatent01 spacy train configs/en_t2vner.cfg --paths.train data/train_ent_ ${ FORMAT } .spacy --paths.dev data/train_ent_ ${ FORMAT } .spacy --output models/en_ent_ ${ FORMAT } \ud83d\udd2e Model Performance \u00b6 en_ent_gbpatent01/model-best \u00b6 ALL ASG CIT INV LOC OCC p 0.93 0.93 0.96 0.95 0.92 0.9 r 0.94 0.92 0.96 0.96 0.92 0.86 f 0.94 0.93 0.96 0.96 0.92 0.88 \ud83c\udfaf Intended use \u00b6 en_ent_gbpatent01 has been specifically trained on GB patents GB189317126A to GB2000001A (excluded). The model's performance are not guaranteed out of this scope. \ud83d\udd02 Versions and alternative approaches \u00b6 Version Comment 0.1 ent - v2 spaCy 1.0 ent - v3 spaCy","title":"Models"},{"location":"GB_MODEL_CARD/#models","text":"","title":"MODELS"},{"location":"GB_MODEL_CARD/#i-model-overview","text":"Name en_ent_gbpatent01 Language English (en) Pipeline ner Authors Bergeaud and Verluise Date (last) 02/2021 License MIT","title":"\u2139\ufe0f Model Overview"},{"location":"GB_MODEL_CARD/#training","text":"FORMAT = gbpatent01 spacy train configs/en_t2vner.cfg --paths.train data/train_ent_ ${ FORMAT } .spacy --paths.dev data/train_ent_ ${ FORMAT } .spacy --output models/en_ent_ ${ FORMAT }","title":"\ud83d\udc77 Training"},{"location":"GB_MODEL_CARD/#model-performance","text":"","title":"\ud83d\udd2e Model Performance"},{"location":"GB_MODEL_CARD/#en_ent_gbpatent01model-best","text":"ALL ASG CIT INV LOC OCC p 0.93 0.93 0.96 0.95 0.92 0.9 r 0.94 0.92 0.96 0.96 0.92 0.86 f 0.94 0.93 0.96 0.96 0.92 0.88","title":"en_ent_gbpatent01/model-best"},{"location":"GB_MODEL_CARD/#intended-use","text":"en_ent_gbpatent01 has been specifically trained on GB patents GB189317126A to GB2000001A (excluded). The model's performance are not guaranteed out of this scope.","title":"\ud83c\udfaf Intended use"},{"location":"GB_MODEL_CARD/#versions-and-alternative-approaches","text":"Version Comment 0.1 ent - v2 spaCy 1.0 ent - v3 spaCy","title":"\ud83d\udd02 Versions and alternative approaches"},{"location":"LICENSE_CODE/","text":"Copyright 2021 Cyril VERLUISE and Antonin BERGEAUD Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.","title":"Code"},{"location":"LICENSE_DATA/","text":"Creative Commons Attribution 4.0 International \u00b6 Creative Commons Corporation (\u201cCreative Commons\u201d) is not a law firm and does not provide legal services or legal advice. Distribution of Creative Commons public licenses does not create a lawyer-client or other relationship. Creative Commons makes its licenses and related information available on an \u201cas-is\u201d basis. Creative Commons gives no warranties regarding its licenses, any material licensed under their terms and conditions, or any related information. Creative Commons disclaims all liability for damages resulting from their use to the fullest extent possible. Using Creative Commons Public Licenses \u00b6 Creative Commons public licenses provide a standard set of terms and conditions that creators and other rights holders may use to share original works of authorship and other material subject to copyright and certain other rights specified in the public license below. The following considerations are for informational purposes only, are not exhaustive, and do not form part of our licenses. Considerations for licensors: Our public licenses are intended for use by those authorized to give the public permission to use material in ways otherwise restricted by copyright and certain other rights. Our licenses are irrevocable. Licensors should read and understand the terms and conditions of the license they choose before applying it. Licensors should also secure all rights necessary before applying our licenses so that the public can reuse the material as expected. Licensors should clearly mark any material not subject to the license. This includes other CC-licensed material, or material used under an exception or limitation to copyright. More considerations for licensors . Considerations for the public: By using one of our public licenses, a licensor grants the public permission to use the licensed material under specified terms and conditions. If the licensor\u2019s permission is not necessary for any reason\u2013for example, because of any applicable exception or limitation to copyright\u2013then that use is not regulated by the license. Our licenses grant only permissions under copyright and certain other rights that a licensor has authority to grant. Use of the licensed material may still be restricted for other reasons, including because others have copyright or other rights in the material. A licensor may make special requests, such as asking that all changes be marked or described. Although not required by our licenses, you are encouraged to respect those requests where reasonable. More considerations for the public . Creative Commons Attribution 4.0 International Public License \u00b6 By exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution 4.0 International Public License (\"Public License\"). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions. Section 1 \u2013 Definitions. \u00b6 a. Adapted Material means material subject to Copyright and Similar Rights that is derived from or based upon the Licensed Material and in which the Licensed Material is translated, altered, arranged, transformed, or otherwise modified in a manner requiring permission under the Copyright and Similar Rights held by the Licensor. For purposes of this Public License, where the Licensed Material is a musical work, performance, or sound recording, Adapted Material is always produced where the Licensed Material is synched in timed relation with a moving image. b. Adapter's License means the license You apply to Your Copyright and Similar Rights in Your contributions to Adapted Material in accordance with the terms and conditions of this Public License. c. Copyright and Similar Rights means copyright and/or similar rights closely related to copyright including, without limitation, performance, broadcast, sound recording, and Sui Generis Database Rights, without regard to how the rights are labeled or categorized. For purposes of this Public License, the rights specified in Section 2(b)(1)-(2) are not Copyright and Similar Rights. d. Effective Technological Measures means those measures that, in the absence of proper authority, may not be circumvented under laws fulfilling obligations under Article 11 of the WIPO Copyright Treaty adopted on December 20, 1996, and/or similar international agreements. e. Exceptions and Limitations means fair use, fair dealing, and/or any other exception or limitation to Copyright and Similar Rights that applies to Your use of the Licensed Material. f. Licensed Material means the artistic or literary work, database, or other material to which the Licensor applied this Public License. g. Licensed Rights means the rights granted to You subject to the terms and conditions of this Public License, which are limited to all Copyright and Similar Rights that apply to Your use of the Licensed Material and that the Licensor has authority to license. h. Licensor means the individual(s) or entity(ies) granting rights under this Public License. i. Share means to provide material to the public by any means or process that requires permission under the Licensed Rights, such as reproduction, public display, public performance, distribution, dissemination, communication, or importation, and to make material available to the public including in ways that members of the public may access the material from a place and at a time individually chosen by them. j. Sui Generis Database Rights means rights other than copyright resulting from Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, as amended and/or succeeded, as well as other essentially equivalent rights anywhere in the world. k. You means the individual or entity exercising the Licensed Rights under this Public License. Your has a corresponding meaning. Section 2 \u2013 Scope. \u00b6 a. License grant. Subject to the terms and conditions of this Public License, the Licensor hereby grants You a worldwide, royalty-free, non-sublicensable, non-exclusive, irrevocable license to exercise the Licensed Rights in the Licensed Material to: A. reproduce and Share the Licensed Material, in whole or in part; and B. produce, reproduce, and Share Adapted Material. Exceptions and Limitations. For the avoidance of doubt, where Exceptions and Limitations apply to Your use, this Public License does not apply, and You do not need to comply with its terms and conditions. Term. The term of this Public License is specified in Section 6(a). Media and formats; technical modifications allowed. The Licensor authorizes You to exercise the Licensed Rights in all media and formats whether now known or hereafter created, and to make technical modifications necessary to do so. The Licensor waives and/or agrees not to assert any right or authority to forbid You from making technical modifications necessary to exercise the Licensed Rights, including technical modifications necessary to circumvent Effective Technological Measures. For purposes of this Public License, simply making modifications authorized by this Section 2(a)(4) never produces Adapted Material. Downstream recipients. A. Offer from the Licensor \u2013 Licensed Material. Every recipient of the Licensed Material automatically receives an offer from the Licensor to exercise the Licensed Rights under the terms and conditions of this Public License. B. No downstream restrictions. You may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, the Licensed Material if doing so restricts exercise of the Licensed Rights by any recipient of the Licensed Material. No endorsement. Nothing in this Public License constitutes or may be construed as permission to assert or imply that You are, or that Your use of the Licensed Material is, connected with, or sponsored, endorsed, or granted official status by, the Licensor or others designated to receive attribution as provided in Section 3(a)(1)(A)(i). b. Other rights. Moral rights, such as the right of integrity, are not licensed under this Public License, nor are publicity, privacy, and/or other similar personality rights; however, to the extent possible, the Licensor waives and/or agrees not to assert any such rights held by the Licensor to the limited extent necessary to allow You to exercise the Licensed Rights, but not otherwise. Patent and trademark rights are not licensed under this Public License. To the extent possible, the Licensor waives any right to collect royalties from You for the exercise of the Licensed Rights, whether directly or through a collecting society under any voluntary or waivable statutory or compulsory licensing scheme. In all other cases the Licensor expressly reserves any right to collect such royalties. Section 3 \u2013 License Conditions. \u00b6 Your exercise of the Licensed Rights is expressly made subject to the following conditions. a. Attribution. If You Share the Licensed Material (including in modified form), You must: A. retain the following if it is supplied by the Licensor with the Licensed Material: i . identification of the creator ( s ) of the Licensed Material and any others designated to receive attribution , in any reasonable manner requested by the Licensor ( including by pseudonym if designated ); ii . a copyright notice ; iii . a notice that refers to this Public License ; iv . a notice that refers to the disclaimer of warranties ; v . a URI or hyperlink to the Licensed Material to the extent reasonably practicable ; B. indicate if You modified the Licensed Material and retain an indication of any previous modifications; and C. indicate the Licensed Material is licensed under this Public License, and include the text of, or the URI or hyperlink to, this Public License. You may satisfy the conditions in Section 3(a)(1) in any reasonable manner based on the medium, means, and context in which You Share the Licensed Material. For example, it may be reasonable to satisfy the conditions by providing a URI or hyperlink to a resource that includes the required information. If requested by the Licensor, You must remove any of the information required by Section 3(a)(1)(A) to the extent reasonably practicable. If You Share Adapted Material You produce, the Adapter's License You apply must not prevent recipients of the Adapted Material from complying with this Public License. Section 4 \u2013 Sui Generis Database Rights. \u00b6 Where the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material: a. for the avoidance of doubt, Section 2(a)(1) grants You the right to extract, reuse, reproduce, and Share all or a substantial portion of the contents of the database; b. if You include all or a substantial portion of the database contents in a database in which You have Sui Generis Database Rights, then the database in which You have Sui Generis Database Rights (but not its individual contents) is Adapted Material; and c. You must comply with the conditions in Section 3(a) if You Share all or a substantial portion of the contents of the database. For the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights. Section 5 \u2013 Disclaimer of Warranties and Limitation of Liability. \u00b6 a. Unless otherwise separately undertaken by the Licensor, to the extent possible, the Licensor offers the Licensed Material as-is and as-available, and makes no representations or warranties of any kind concerning the Licensed Material, whether express, implied, statutory, or other. This includes, without limitation, warranties of title, merchantability, fitness for a particular purpose, non-infringement, absence of latent or other defects, accuracy, or the presence or absence of errors, whether or not known or discoverable. Where disclaimers of warranties are not allowed in full or in part, this disclaimer may not apply to You. b. To the extent possible, in no event will the Licensor be liable to You on any legal theory (including, without limitation, negligence) or otherwise for any direct, special, indirect, incidental, consequential, punitive, exemplary, or other losses, costs, expenses, or damages arising out of this Public License or use of the Licensed Material, even if the Licensor has been advised of the possibility of such losses, costs, expenses, or damages. Where a limitation of liability is not allowed in full or in part, this limitation may not apply to You. c. The disclaimer of warranties and limitation of liability provided above shall be interpreted in a manner that, to the extent possible, most closely approximates an absolute disclaimer and waiver of all liability. Section 6 \u2013 Term and Termination. \u00b6 a. This Public License applies for the term of the Copyright and Similar Rights licensed here. However, if You fail to comply with this Public License, then Your rights under this Public License terminate automatically. b. Where Your right to use the Licensed Material has terminated under Section 6(a), it reinstates: automatically as of the date the violation is cured, provided it is cured within 30 days of Your discovery of the violation; or upon express reinstatement by the Licensor. For the avoidance of doubt, this Section 6(b) does not affect any right the Licensor may have to seek remedies for Your violations of this Public License. c. For the avoidance of doubt, the Licensor may also offer the Licensed Material under separate terms or conditions or stop distributing the Licensed Material at any time; however, doing so will not terminate this Public License. d. Sections 1, 5, 6, 7, and 8 survive termination of this Public License. Section 7 \u2013 Other Terms and Conditions. \u00b6 a. The Licensor shall not be bound by any additional or different terms or conditions communicated by You unless expressly agreed. b. Any arrangements, understandings, or agreements regarding the Licensed Material not stated herein are separate from and independent of the terms and conditions of this Public License. Section 8 \u2013 Interpretation. \u00b6 a. For the avoidance of doubt, this Public License does not, and shall not be interpreted to, reduce, limit, restrict, or impose conditions on any use of the Licensed Material that could lawfully be made without permission under this Public License. b. To the extent possible, if any provision of this Public License is deemed unenforceable, it shall be automatically reformed to the minimum extent necessary to make it enforceable. If the provision cannot be reformed, it shall be severed from this Public License without affecting the enforceability of the remaining terms and conditions. c. No term or condition of this Public License will be waived and no failure to comply consented to unless expressly agreed to by the Licensor. d. Nothing in this Public License constitutes or may be interpreted as a limitation upon, or waiver of, any privileges and immunities that apply to the Licensor or You, including from the legal processes of any jurisdiction or authority. Creative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the \u201cLicensor.\u201d Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies , Creative Commons does not authorize the use of the trademark \u201cCreative Commons\u201d or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses. Creative Commons may be contacted at creativecommons.org","title":"Data"},{"location":"LICENSE_DATA/#creative-commons-attribution-40-international","text":"Creative Commons Corporation (\u201cCreative Commons\u201d) is not a law firm and does not provide legal services or legal advice. Distribution of Creative Commons public licenses does not create a lawyer-client or other relationship. Creative Commons makes its licenses and related information available on an \u201cas-is\u201d basis. Creative Commons gives no warranties regarding its licenses, any material licensed under their terms and conditions, or any related information. Creative Commons disclaims all liability for damages resulting from their use to the fullest extent possible.","title":"Creative Commons Attribution 4.0 International"},{"location":"LICENSE_DATA/#using-creative-commons-public-licenses","text":"Creative Commons public licenses provide a standard set of terms and conditions that creators and other rights holders may use to share original works of authorship and other material subject to copyright and certain other rights specified in the public license below. The following considerations are for informational purposes only, are not exhaustive, and do not form part of our licenses. Considerations for licensors: Our public licenses are intended for use by those authorized to give the public permission to use material in ways otherwise restricted by copyright and certain other rights. Our licenses are irrevocable. Licensors should read and understand the terms and conditions of the license they choose before applying it. Licensors should also secure all rights necessary before applying our licenses so that the public can reuse the material as expected. Licensors should clearly mark any material not subject to the license. This includes other CC-licensed material, or material used under an exception or limitation to copyright. More considerations for licensors . Considerations for the public: By using one of our public licenses, a licensor grants the public permission to use the licensed material under specified terms and conditions. If the licensor\u2019s permission is not necessary for any reason\u2013for example, because of any applicable exception or limitation to copyright\u2013then that use is not regulated by the license. Our licenses grant only permissions under copyright and certain other rights that a licensor has authority to grant. Use of the licensed material may still be restricted for other reasons, including because others have copyright or other rights in the material. A licensor may make special requests, such as asking that all changes be marked or described. Although not required by our licenses, you are encouraged to respect those requests where reasonable. More considerations for the public .","title":"Using Creative Commons Public Licenses"},{"location":"LICENSE_DATA/#creative-commons-attribution-40-international-public-license","text":"By exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution 4.0 International Public License (\"Public License\"). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.","title":"Creative Commons Attribution 4.0 International Public License"},{"location":"LICENSE_DATA/#section-1-definitions","text":"a. Adapted Material means material subject to Copyright and Similar Rights that is derived from or based upon the Licensed Material and in which the Licensed Material is translated, altered, arranged, transformed, or otherwise modified in a manner requiring permission under the Copyright and Similar Rights held by the Licensor. For purposes of this Public License, where the Licensed Material is a musical work, performance, or sound recording, Adapted Material is always produced where the Licensed Material is synched in timed relation with a moving image. b. Adapter's License means the license You apply to Your Copyright and Similar Rights in Your contributions to Adapted Material in accordance with the terms and conditions of this Public License. c. Copyright and Similar Rights means copyright and/or similar rights closely related to copyright including, without limitation, performance, broadcast, sound recording, and Sui Generis Database Rights, without regard to how the rights are labeled or categorized. For purposes of this Public License, the rights specified in Section 2(b)(1)-(2) are not Copyright and Similar Rights. d. Effective Technological Measures means those measures that, in the absence of proper authority, may not be circumvented under laws fulfilling obligations under Article 11 of the WIPO Copyright Treaty adopted on December 20, 1996, and/or similar international agreements. e. Exceptions and Limitations means fair use, fair dealing, and/or any other exception or limitation to Copyright and Similar Rights that applies to Your use of the Licensed Material. f. Licensed Material means the artistic or literary work, database, or other material to which the Licensor applied this Public License. g. Licensed Rights means the rights granted to You subject to the terms and conditions of this Public License, which are limited to all Copyright and Similar Rights that apply to Your use of the Licensed Material and that the Licensor has authority to license. h. Licensor means the individual(s) or entity(ies) granting rights under this Public License. i. Share means to provide material to the public by any means or process that requires permission under the Licensed Rights, such as reproduction, public display, public performance, distribution, dissemination, communication, or importation, and to make material available to the public including in ways that members of the public may access the material from a place and at a time individually chosen by them. j. Sui Generis Database Rights means rights other than copyright resulting from Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, as amended and/or succeeded, as well as other essentially equivalent rights anywhere in the world. k. You means the individual or entity exercising the Licensed Rights under this Public License. Your has a corresponding meaning.","title":"Section 1 \u2013 Definitions."},{"location":"LICENSE_DATA/#section-2-scope","text":"a. License grant. Subject to the terms and conditions of this Public License, the Licensor hereby grants You a worldwide, royalty-free, non-sublicensable, non-exclusive, irrevocable license to exercise the Licensed Rights in the Licensed Material to: A. reproduce and Share the Licensed Material, in whole or in part; and B. produce, reproduce, and Share Adapted Material. Exceptions and Limitations. For the avoidance of doubt, where Exceptions and Limitations apply to Your use, this Public License does not apply, and You do not need to comply with its terms and conditions. Term. The term of this Public License is specified in Section 6(a). Media and formats; technical modifications allowed. The Licensor authorizes You to exercise the Licensed Rights in all media and formats whether now known or hereafter created, and to make technical modifications necessary to do so. The Licensor waives and/or agrees not to assert any right or authority to forbid You from making technical modifications necessary to exercise the Licensed Rights, including technical modifications necessary to circumvent Effective Technological Measures. For purposes of this Public License, simply making modifications authorized by this Section 2(a)(4) never produces Adapted Material. Downstream recipients. A. Offer from the Licensor \u2013 Licensed Material. Every recipient of the Licensed Material automatically receives an offer from the Licensor to exercise the Licensed Rights under the terms and conditions of this Public License. B. No downstream restrictions. You may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, the Licensed Material if doing so restricts exercise of the Licensed Rights by any recipient of the Licensed Material. No endorsement. Nothing in this Public License constitutes or may be construed as permission to assert or imply that You are, or that Your use of the Licensed Material is, connected with, or sponsored, endorsed, or granted official status by, the Licensor or others designated to receive attribution as provided in Section 3(a)(1)(A)(i). b. Other rights. Moral rights, such as the right of integrity, are not licensed under this Public License, nor are publicity, privacy, and/or other similar personality rights; however, to the extent possible, the Licensor waives and/or agrees not to assert any such rights held by the Licensor to the limited extent necessary to allow You to exercise the Licensed Rights, but not otherwise. Patent and trademark rights are not licensed under this Public License. To the extent possible, the Licensor waives any right to collect royalties from You for the exercise of the Licensed Rights, whether directly or through a collecting society under any voluntary or waivable statutory or compulsory licensing scheme. In all other cases the Licensor expressly reserves any right to collect such royalties.","title":"Section 2 \u2013 Scope."},{"location":"LICENSE_DATA/#section-3-license-conditions","text":"Your exercise of the Licensed Rights is expressly made subject to the following conditions. a. Attribution. If You Share the Licensed Material (including in modified form), You must: A. retain the following if it is supplied by the Licensor with the Licensed Material: i . identification of the creator ( s ) of the Licensed Material and any others designated to receive attribution , in any reasonable manner requested by the Licensor ( including by pseudonym if designated ); ii . a copyright notice ; iii . a notice that refers to this Public License ; iv . a notice that refers to the disclaimer of warranties ; v . a URI or hyperlink to the Licensed Material to the extent reasonably practicable ; B. indicate if You modified the Licensed Material and retain an indication of any previous modifications; and C. indicate the Licensed Material is licensed under this Public License, and include the text of, or the URI or hyperlink to, this Public License. You may satisfy the conditions in Section 3(a)(1) in any reasonable manner based on the medium, means, and context in which You Share the Licensed Material. For example, it may be reasonable to satisfy the conditions by providing a URI or hyperlink to a resource that includes the required information. If requested by the Licensor, You must remove any of the information required by Section 3(a)(1)(A) to the extent reasonably practicable. If You Share Adapted Material You produce, the Adapter's License You apply must not prevent recipients of the Adapted Material from complying with this Public License.","title":"Section 3 \u2013 License Conditions."},{"location":"LICENSE_DATA/#section-4-sui-generis-database-rights","text":"Where the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material: a. for the avoidance of doubt, Section 2(a)(1) grants You the right to extract, reuse, reproduce, and Share all or a substantial portion of the contents of the database; b. if You include all or a substantial portion of the database contents in a database in which You have Sui Generis Database Rights, then the database in which You have Sui Generis Database Rights (but not its individual contents) is Adapted Material; and c. You must comply with the conditions in Section 3(a) if You Share all or a substantial portion of the contents of the database. For the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.","title":"Section 4 \u2013 Sui Generis Database Rights."},{"location":"LICENSE_DATA/#section-5-disclaimer-of-warranties-and-limitation-of-liability","text":"a. Unless otherwise separately undertaken by the Licensor, to the extent possible, the Licensor offers the Licensed Material as-is and as-available, and makes no representations or warranties of any kind concerning the Licensed Material, whether express, implied, statutory, or other. This includes, without limitation, warranties of title, merchantability, fitness for a particular purpose, non-infringement, absence of latent or other defects, accuracy, or the presence or absence of errors, whether or not known or discoverable. Where disclaimers of warranties are not allowed in full or in part, this disclaimer may not apply to You. b. To the extent possible, in no event will the Licensor be liable to You on any legal theory (including, without limitation, negligence) or otherwise for any direct, special, indirect, incidental, consequential, punitive, exemplary, or other losses, costs, expenses, or damages arising out of this Public License or use of the Licensed Material, even if the Licensor has been advised of the possibility of such losses, costs, expenses, or damages. Where a limitation of liability is not allowed in full or in part, this limitation may not apply to You. c. The disclaimer of warranties and limitation of liability provided above shall be interpreted in a manner that, to the extent possible, most closely approximates an absolute disclaimer and waiver of all liability.","title":"Section 5 \u2013 Disclaimer of Warranties and Limitation of Liability."},{"location":"LICENSE_DATA/#section-6-term-and-termination","text":"a. This Public License applies for the term of the Copyright and Similar Rights licensed here. However, if You fail to comply with this Public License, then Your rights under this Public License terminate automatically. b. Where Your right to use the Licensed Material has terminated under Section 6(a), it reinstates: automatically as of the date the violation is cured, provided it is cured within 30 days of Your discovery of the violation; or upon express reinstatement by the Licensor. For the avoidance of doubt, this Section 6(b) does not affect any right the Licensor may have to seek remedies for Your violations of this Public License. c. For the avoidance of doubt, the Licensor may also offer the Licensed Material under separate terms or conditions or stop distributing the Licensed Material at any time; however, doing so will not terminate this Public License. d. Sections 1, 5, 6, 7, and 8 survive termination of this Public License.","title":"Section 6 \u2013 Term and Termination."},{"location":"LICENSE_DATA/#section-7-other-terms-and-conditions","text":"a. The Licensor shall not be bound by any additional or different terms or conditions communicated by You unless expressly agreed. b. Any arrangements, understandings, or agreements regarding the Licensed Material not stated herein are separate from and independent of the terms and conditions of this Public License.","title":"Section 7 \u2013 Other Terms and Conditions."},{"location":"LICENSE_DATA/#section-8-interpretation","text":"a. For the avoidance of doubt, this Public License does not, and shall not be interpreted to, reduce, limit, restrict, or impose conditions on any use of the Licensed Material that could lawfully be made without permission under this Public License. b. To the extent possible, if any provision of this Public License is deemed unenforceable, it shall be automatically reformed to the minimum extent necessary to make it enforceable. If the provision cannot be reformed, it shall be severed from this Public License without affecting the enforceability of the remaining terms and conditions. c. No term or condition of this Public License will be waived and no failure to comply consented to unless expressly agreed to by the Licensor. d. Nothing in this Public License constitutes or may be interpreted as a limitation upon, or waiver of, any privileges and immunities that apply to the Licensor or You, including from the legal processes of any jurisdiction or authority. Creative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the \u201cLicensor.\u201d Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies , Creative Commons does not authorize the use of the trademark \u201cCreative Commons\u201d or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses. Creative Commons may be contacted at creativecommons.org","title":"Section 8 \u2013 Interpretation."},{"location":"RECIPE_PATENTCITY/","text":"RECIPE PATENTCITY \u00b6 Note The below snippets provide guidance for the main steps of the PatentCity pipeline. Serialize data\ufe0f \u00b6 Get data \u00b6 Preped data not available # get raw data gsutil -m cp \"gs://patentcity_dev/v1/*patent*.txt.tar.gz\" ./ # Unpack data cat lib/formats.txt | parallel --eta 'tar -xvzf {}.txt.tar.gz -C ./{}' # then, you can go for a week-end # Prepare data cat lib/formats.txt | parallel --eta -j 2 'patentcity brew v1.grind {}/*.txt >> {}.jsonl && gzip {}.jsonl' Preped data available gsutil -m cp \"gs://patentcity_dev/v1/*.jsonl.gz\" ./ # should dl ddpatent01.jsonl.gz, ddpatent02.jsonl.gz, etc Extract patentees (and add topping) \u00b6 # Extract entities (brew data) cat lib/formats.txt | parallel --eta -j 3 'MODEL=$(ls -d models/**/model-best | grep {} ) && patentcity brew v1 {}.jsonl.gz ${MODEL} configs/rel_{}.yaml --batch-size 500 >> entrel_{}.jsonl' # Number of job for a 8 CPUs 32Gb ram machine # Merge all format belonging to the same office in one single file for OFFICE in dd de fr gb us ; do echo ${ OFFICE } && cat entrel_ ${ OFFICE } patent*.jsonl >> entrel_ ${ OFFICE } patentxx.jsonl ; done ; # Add topping ls entrel_*patentxx.jsonl | parallel --eta -j 2 'mv {} {}_tmp && patentcity brew v1.topping --config-file configs/top_xxpatentxx.yaml {}_tmp >> {} ' # Note: it can be memory greedy, you might want to limit the nb or jobs and/or the nb of workers # Check output not corrupted ls entrel_*patentxx.jsonl | parallel \"wc -l {}*\" Get LOC data \u00b6 All # Get loc data ls entrel_*patentxx.jsonl | cut -d_ -f2 | parallel --eta 'patentcity geo prep entrel_{} | sort -u >> loc_{.}.txt' # Prep geoc data ls loc_*patentxx.txt | parallel --eta 'mv {} {}_tmp && patentcity utils prep-searchtext {}_tmp configs/{.}.yaml >> {}' Not geocoded yet # Note: This is useful when you geocode the dataset in more than one pass (for example because of limited quotas) # Below we assume that part of dataset has already been geocoded using HERE (loc_*patentxx.here.txt files) and we want to geocode the rest (wrt the full list of loc in loc_*patentxx.txt) using GMAPS (in loc_*patentxx.tbd.txt). ls loc_*patentxx.txt | parallel --eta 'comm -13 <(sort {.}.here.txt) <(sort {}) >> {.}.tbd.txt' Most reccurent loc ls entrel_*patentxx.jsonl | cut -d_ -f2 | parallel --eta 'patentcity geo prep entrel_{} | sort | uniq -c >> loc_{.}.count.txt' ls loc_*patentxx.count.txt | cut -d. -f 1 ,2 | parallel --eta 'mv {}.txt {}.txt_tmp && patentcity utils prep-searchtext {}.txt_tmp configs/{.}.yaml >> {}.txt' for FILE in $( ls loc_*patentxx.count.txt | cut -d. -f 1 ) ; do cat ${ FILE } .count.txt | sort -nr | awk '{$1=\"\"; print $0}' | cut -c2- >> ${ FILE } .sorted.txt ; done ; # nb sorted in descending order # Now assume that you want to get 250k addresses to geocode, covering as many occurences as possible and making sure that they have not been geocoded yet # Below, we get the 275k most cited addresses (unconditional) and we keep only those which are no yet done (ie in tbd as well) # Nb requires a bit of fine tuning to make sure that we have the right nbr of lines: rm -f tmp && head -n 275000 loc_${FORMAT}.sorted.txt >> tmp && comm -13 <(sort loc_${FORMAT}.tbd.txt) <(sort tmp) | wc -l FORMAT = \"uspatentxx\" rm -f tmp && head -n 275000 loc_ ${ FORMAT } .sorted.txt >> tmp && comm -13 < ( sort loc_ ${ FORMAT } .tbd.txt ) < ( sort tmp ) | sort -r >> loc_ ${ FORMAT } .tbd.txt_00 HERE nomatch ROUND = \"\" # e.g. 00 for OFFICE in dd de fr gb us ; do patentcity utils get-recid-nomatch geoc_ ${ OFFICE } patentxx.here.csv_ ${ ROUND } .gz loc_ ${ OFFICE } patentxx.tbd.txt_ ${ ROUND } >> loc_ ${ OFFICE } patentxx.here.nomatch.txt_ ${ ROUND } ; done ; Geocode dataset \u00b6 Danger Take care, geocoding is not free, especially using GMAPS. Keep calm and plan your budget, you might want to ask for a grant and/or chunk the data and process it month-by-month as you free-tier gets automatically refilled. You might also want to first start with the batch geocoding API from HERE (which offers much more generous free plan) and use gmaps only for the no-match. NB: HERE batch geocoding API is supported by patentcity. HERE # Make sure that there is the appropriate header, ie recId|searchText # if not, you can use sthg in the flavor of # ls loc_*patentxx.tbd.txt_00* | parallel --eta 'mv {} {}_tmp && echo \"recId|searchText\" >> {} && cat {}_tmp >> {}' APIKEY = \"\" FILE = \"\" # e.g. loc_ddpatentxx.tbd.txt_00 CNTFOCUS = \"\" # e.g. deu echo \"FILE: ${ FILE } CNTFOCUS: ${ CNTFOCUS } \" patentcity geo here.post ${ FILE } ${ APIKEY } ${ CNTFOCUS } # print REQUESTID to stdout # monitor status REQUESTID = \"\" patentcity geo here.status $REQUESTID $APIKEY # get data and rename OUTPUTDIR = \"tmp\" mkdir -p ${ OUTPUTDIR } patentcity geo here.get ${ REQUESTID } ${ APIKEY } --output-dir ${ OUTPUTDIR } && RESULT = $( ls ${ OUTPUTDIR } / ${ REQUESTID } ) && mv ${ OUTPUTDIR } / ${ REQUESTID } / $RESULT ./ \" $( echo ${ FILE } | sed -e 's/tbd/here/g; s/txt/csv/g; s/loc/geoc/g' ) \" && echo \"Saved as $( echo ${ FILE } | sed -e 's/tbd/here/g; s/txt/csv/g; s/loc/geoc/g' ) !\" GMAPS # Geocode using GMAPS # 1-by-1 APIKEY = \"\" OFFICE = \"\" # see above REGION = \"\" # see above (nb uk for gb) ROUND = \"\" # e.g. 00 echo \"OFFICE: ${ OFFICE } REGION: ${ REGION } ROUND: ${ ROUND } \" echo \"loc_ ${ OFFICE } patentxx.here.nomatch.txt_ ${ ROUND } has $( wc -l loc_ ${ OFFICE } patentxx.here.nomatch.txt_ ${ ROUND } ) line(s)\" # better safe than sorry patentcity geo gmaps.get loc_ ${ OFFICE } patentxx.here.nomatch.txt_ ${ ROUND } ${ APIKEY } ${ REGION } >> geoc_ ${ OFFICE } patentxx.gmaps.txt_ ${ ROUND } Manual annotations # Generate manual annotations using Prodigy XX # Generate manual annotations for country codes FORMAT = \"\" # e.g. ddpatentxx patentcity utils disamb-countrycodes loc_ ${ FORMAT } .txt >> lib/loc_ ${ FORMAT } .disamb.txt # Add manual geoc FORMAT = \"\" # e.g. frpatentxx, ddpatentxx DISAMBFILE = \"\" # e.g. lib/loc_${FORMAT}.disamb.txt GEOCINDEX = \"\" # e.g. lib/geoc_${FORMAT}.disamb.index.txt lib/geoc_iso.disamb.index.txt FLAVOR = \"\" # HERE or GMAPS patentcity geo add.disamb ${ DISAMBFILE } ${ GEOCINDEX } --flavor ${ FLAVOR } >> geoc_ ${ FORMAT } .manual.txt # DISAMBFILE is a list of disambiguated loc together with their *original* hash (sep by the standard inDelim) # GEOCINDEX is the list of geoc of disambigated loc (e.g. \"r\u00e9publique f\u00e9d\u00e9rale d'allemagne\") # FLAVOR is HERE or GMAPS depending on the flavor of GEOCINDEX # The output is a GMAPS like file (md5|{}) Prep geocoded data \u00b6 # Harmonize GMAPS and MANUAL as HERE geocoded data parallel --eta 'test -f geoc_{1}patentxx.gmaps.txt_{2}.gz && patentcity geo gmaps.harmonize geoc_{1}patentxx.gmaps.txt_{2}.gz --out-format csv >> geoc_{1}patentxx.gmaps.csv_{2} && gzip geoc_{1}patentxx.gmaps.csv_{2}' ::: dd de fr gb us ::: 00 01 02 MANUALDISAMB = \"fr\" for OFFICE in ${ MANUALDISAMB } ; do patentcity geo gmaps.harmonize geoc_ ${ OFFICE } patentxx.manual.txt.gz --out-format csv >> geoc_ ${ OFFICE } patentxx.manual.csv && gzip geoc_ ${ OFFICE } patentxx.manual.csv ; done ; # Stack geocoded data # we assume that there have been several rounds of geocoding (e.g. due to limited credits) and each round result is suffixed by 0x (e.g. geoc_ddpatentxx.gmaps.csv_00.gz parallel --eta 'zcat $(ls geoc_{1}patentxx.{2}.csv_*.gz | head -n 1) | head -n 1 >> geoc_{1}patentxx.{2}.csv_xx' ::: dd de fr gb us ::: gmaps here parallel --eta 'zcat geoc_{1}patentxx.{2}.csv_*.gz | grep -v \"recId\" | sort -u >> geoc_{1}patentxx.{2}.csv_xx' ::: dd de fr gb us ::: gmaps here gzip geoc_*patentxx.*.csv_xx # overwrite existing file if any # Add statistical areas parallel -j2 --eta 'patentcity geo add.statisticalareas geoc_{1}patentxx.{2}.csv_xx.gz \"assets/statisticalareas_*.csv\" >> geoc_{1}patentxx.{2}.csv_xx' ::: dd de fr gb us ::: gmaps here parallel -j2 --eta 'patentcity geo add.statisticalareas geoc_{1}patentxx.manual.csv.gz \"assets/statisticalareas_*.csv\" >> geoc_{1}patentxx.manual.csv' ::: dd fr gzip geoc_*patentxx.*.csv_xx # overwrite existing file if any gzip geoc_*patentxx.manual.csv # overwrite existing file if any Add geocoded data \u00b6 level up Incorporating data is hard on memory. Upgrade to a 32Gb memory machine for this stage. # Incorporate geocoded data # HERE and GMAPS for OFFICE in dd de fr gb us ; do echo ${ OFFICE } patentcity geo add entrel_ ${ OFFICE } patentxx.jsonl.gz geoc_ ${ OFFICE } patentxx.here.csv_xx.gz --source HERE >> entrelgeoc_ ${ OFFICE } patentxx.jsonl_tmp && patentcity geo add entrelgeoc_ ${ OFFICE } patentxx.jsonl_tmp geoc_ ${ OFFICE } patentxx.gmaps.csv_xx.gz --source GMAPS >> entrelgeoc_ ${ OFFICE } patentxx.jsonl && rm entrelgeoc_ ${ OFFICE } patentxx.jsonl_tmp ; done ; MANUALDISAMB = \"dd fr\" # we add dd which is already in HERE like format for OFFICE in ${ MANUALDISAMB } ; do mv entrelgeoc_ ${ OFFICE } patentxx.jsonl entrelgeoc_ ${ OFFICE } patentxx.jsonl_tmp && patentcity geo add entrelgeoc_ ${ OFFICE } patentxx.jsonl_tmp geoc_ ${ OFFICE } patentxx.manual.csv.gz --source MANUAL >> entrelgeoc_ ${ OFFICE } patentxx.jsonl && rm entrelgeoc_ ${ OFFICE } patentxx.jsonl_tmp ; done ; # Add origin for file in $( ls entrelgeoc_*patentxx.jsonl ) ; do mv ${ file } ${ file } _tmp && jq -c --arg origin PC '. + {origin: $origin}' ${ file } _tmp >> ${ file } && rm ${ file } _tmp ; done ; # Prep var name ls entrelgeoc_*patentxx.jsonl | parallel --eta \"\"\"mv {} {}_tmp && sed 's/\\\"seqNumber\\\":/\\\"loc_seqNumber\\\":/g; s/\\\"seqLength\\\":/\\\"loc_seqLength\\\":/g; s/\\\"latitude\\\":/\\\"loc_latitude\\\":/g; s/\\\"longitude\\\":/\\\"loc_longitude\\\":/g; s/\\\"locationLabel\\\":/\\\"loc_locationLabel\\\":/g; s/\\\"addressLines\\\":/\\\"loc_addressLines\\\":/g; s/\\\"street\\\":/\\\"loc_street\\\":/g; s/\\\"houseNumber\\\":/\\\"loc_houseNumber\\\":/g; s/\\\"building\\\":/\\\"loc_building\\\":/g; s/\\\"subdistrict\\\":/\\\"loc_subdistrict\\\":/g; s/\\\"district\\\":/\\\"loc_district\\\":/g; s/\\\"city\\\":/\\\"loc_city\\\":/g; s/\\\"postalCode\\\":/\\\"loc_postalCode\\\":/g; s/\\\"county\\\":/\\\"loc_county\\\":/g; s/\\\"state\\\":/\\\"loc_state\\\":/g; s/\\\"country\\\":/\\\"loc_country\\\":/g; s/\\\"relevance\\\":/\\\"loc_relevance\\\":/g; s/\\\"matchType\\\":/\\\"loc_matchType\\\":/g; s/\\\"matchCode\\\":/\\\"loc_matchCode\\\":/g; s/\\\"matchLevel\\\":/\\\"loc_matchLevel\\\":/g; s/\\\"matchQualityStreet\\\":/\\\"loc_matchQualityStreet\\\":/g; s/\\\"matchQualityHouseNumber\\\":/\\\"loc_matchQualityHouseNumber\\\":/g; s/\\\"matchQualityBuilding\\\":/\\\"loc_matchQualityBuilding\\\":/g; s/\\\"matchQualityDistrict\\\":/\\\"loc_matchQualityDistrict\\\":/g; s/\\\"matchQualityCity\\\":/\\\"loc_matchQualityCity\\\":/g; s/\\\"matchQualityPostalCode\\\":/\\\"loc_matchQualityPostalCode\\\":/g; s/\\\"matchQualityCounty\\\":/\\\"loc_matchQualityCounty\\\":/g; s/\\\"matchQualityState\\\":/\\\"loc_matchQualityState\\\":/g; s/\\\"matchQualityCountry\\\":/\\\"loc_matchQualityCountry\\\":/g; s/\\\"statisticalArea1\\\":/\\\"loc_statisticalArea1\\\":/g; s/\\\"statisticalArea1Code\\\":/\\\"loc_statisticalArea1Code\\\":/g; s/\\\"statisticalArea2\\\":/\\\"loc_statisticalArea2\\\":/g; s/\\\"statisticalArea2Code\\\":/\\\"loc_statisticalArea2Code\\\":/g; s/\\\"statisticalArea3\\\":/\\\"loc_statisticalArea3\\\":/g; s/\\\"statisticalArea3Code\\\":/\\\"loc_statisticalArea3Code\\\":/g; s/\\\"key\\\":/\\\"loc_key\\\":/g ' {}_tmp >> {} \"\"\" rm entrelgeoc_*patentxx.jsonl_tmp # Sync data gsutil -m rsync ./ gs://patentcity_dev/v1/ Build data \u00b6 patentcity + wgp KEYFILE = \"\" # \"credentials-patentcity.json\" URIPC = \"\" # \"gs://patentcity_dev/v1/entrelgeoc_*patentxx.jsonl\" URIWGP = \"\" # \"gs://gder_dev/v100rc5/patentcity*.jsonl.gz\" STAGETABLE = \"\" #e.g \"patentcity:tmp.v100rc5\" RELEASETABLE = \"\" # \"patentcity:patentcity.v100rc5\" bq load --source_format NEWLINE_DELIMITED_JSON --replace --ignore_unknown_values --max_bad_records 10000 ${ STAGETABLE } ${ URIPC } schema/patentcity_v1.sm.json bq load --source_format NEWLINE_DELIMITED_JSON --noreplace --ignore_unknown_values --max_bad_records 1000 ${ STAGETABLE } ${ URIWGP } schema/patentcity_v1.sm.json # Augment data patentcity io augment-patentcity $( echo ${ STAGETABLE } | sed -e 's/:/./' ) $( echo ${ STAGETABLE } | sed -e 's/:/./' ) --credentials ${ KEYFILE } # Impute missing dates #for OFFICE in dd de; do # patentcity utils expand-pubdate-imputation lib/pubdate_${OFFICE}patentxx.imputation.csv --output pubdate_${OFFICE}patentxx.imputation.expanded.csv; #done; # gsutil -m cp \"pubdate_*patentxx.imputation.expanded.csv\" gs://patentcity_dev/v1/ for OFFICE in dd de ; do bq load --source_format CSV --replace --ignore_unknown_values --max_bad_records 1000 patentcity:tmp.de_pubdate_imputation \"gs://patentcity_dev/v1/pubdate_ ${ OFFICE } patentxx.imputation.expanded.csv\" schema/date_imputation.json python patentcity io impute-publication-date $( echo ${ STAGETABLE } | sed -e 's/:/./' ) patentcity.tmp. ${ OFFICE } _pubdate_imputation --country-code ${ OFFICE : u } --credentials ${ KEYFILE } ; done ; # Deduplicate data (pc, wgp25 and wgp45 have a small overlap) patentcity io deduplicate $( echo ${ STAGETABLE } | sed -e 's/:/./' ) $( echo ${ STAGETABLE } | sed -e 's/:/./' ) $KEYFILE # Expand (we use the family of publications in the dataset to expand to publications in the same family but not yet in the dataset) patentcity io family-expansion $( echo ${ STAGETABLE } | sed -e 's/:/./' ) $( echo ${ STAGETABLE } _expansion | sed -e 's/:/./' ) $KEYFILE schema/patentcity_v1.json gsutil -m rm \"gs://tmp/family_expansion_*.jsonl.gz\" bq extract --destination_format NEWLINE_DELIMITED_JSON --compression GZIP ${ STAGETABLE } _expansion \"gs://tmp/family_expansion_*.jsonl.gz\" bq load --source_format NEWLINE_DELIMITED_JSON --noreplace --ignore_unknown_values --max_bad_records 1000 $STAGETABLE \"gs://tmp/family_expansion_*.jsonl.gz\" # Filter kind codes (we have kind codes that do not correspond to utility patents - we filter them out) patentcity io filter-kind-codes $( echo ${ STAGETABLE } | sed -e 's/:/./' ) $( echo ${ RELEASETABLE } | sed -e 's/:/./' ) $KEYFILE patentcity only #STAGETABLE=\"patentcity:tmp.tmp\" URI = \"\" # e.g \"gs://patentcity_dev/v1/entrelgeoc_*patentxx.jsonl\" RELEASETABLE = \"\" # e.g. \"patentcity:patentcity.pc_v100rc5\" KEYFILE = \"\" # e.g. \"credentials-patentcity.json\" # Load data bq load --source_format NEWLINE_DELIMITED_JSON --replace --ignore_unknown_values --max_bad_records 10000 ${ RELEASETABLE } ${ URI } schema/patentcity_v1.sm.json","title":"PatentCity"},{"location":"RECIPE_PATENTCITY/#recipe-patentcity","text":"Note The below snippets provide guidance for the main steps of the PatentCity pipeline.","title":"RECIPE PATENTCITY"},{"location":"RECIPE_PATENTCITY/#serialize-data","text":"","title":"Serialize data\ufe0f"},{"location":"RECIPE_PATENTCITY/#get-data","text":"Preped data not available # get raw data gsutil -m cp \"gs://patentcity_dev/v1/*patent*.txt.tar.gz\" ./ # Unpack data cat lib/formats.txt | parallel --eta 'tar -xvzf {}.txt.tar.gz -C ./{}' # then, you can go for a week-end # Prepare data cat lib/formats.txt | parallel --eta -j 2 'patentcity brew v1.grind {}/*.txt >> {}.jsonl && gzip {}.jsonl' Preped data available gsutil -m cp \"gs://patentcity_dev/v1/*.jsonl.gz\" ./ # should dl ddpatent01.jsonl.gz, ddpatent02.jsonl.gz, etc","title":"Get data"},{"location":"RECIPE_PATENTCITY/#extract-patentees-and-add-topping","text":"# Extract entities (brew data) cat lib/formats.txt | parallel --eta -j 3 'MODEL=$(ls -d models/**/model-best | grep {} ) && patentcity brew v1 {}.jsonl.gz ${MODEL} configs/rel_{}.yaml --batch-size 500 >> entrel_{}.jsonl' # Number of job for a 8 CPUs 32Gb ram machine # Merge all format belonging to the same office in one single file for OFFICE in dd de fr gb us ; do echo ${ OFFICE } && cat entrel_ ${ OFFICE } patent*.jsonl >> entrel_ ${ OFFICE } patentxx.jsonl ; done ; # Add topping ls entrel_*patentxx.jsonl | parallel --eta -j 2 'mv {} {}_tmp && patentcity brew v1.topping --config-file configs/top_xxpatentxx.yaml {}_tmp >> {} ' # Note: it can be memory greedy, you might want to limit the nb or jobs and/or the nb of workers # Check output not corrupted ls entrel_*patentxx.jsonl | parallel \"wc -l {}*\"","title":"Extract patentees (and add topping)"},{"location":"RECIPE_PATENTCITY/#get-loc-data","text":"All # Get loc data ls entrel_*patentxx.jsonl | cut -d_ -f2 | parallel --eta 'patentcity geo prep entrel_{} | sort -u >> loc_{.}.txt' # Prep geoc data ls loc_*patentxx.txt | parallel --eta 'mv {} {}_tmp && patentcity utils prep-searchtext {}_tmp configs/{.}.yaml >> {}' Not geocoded yet # Note: This is useful when you geocode the dataset in more than one pass (for example because of limited quotas) # Below we assume that part of dataset has already been geocoded using HERE (loc_*patentxx.here.txt files) and we want to geocode the rest (wrt the full list of loc in loc_*patentxx.txt) using GMAPS (in loc_*patentxx.tbd.txt). ls loc_*patentxx.txt | parallel --eta 'comm -13 <(sort {.}.here.txt) <(sort {}) >> {.}.tbd.txt' Most reccurent loc ls entrel_*patentxx.jsonl | cut -d_ -f2 | parallel --eta 'patentcity geo prep entrel_{} | sort | uniq -c >> loc_{.}.count.txt' ls loc_*patentxx.count.txt | cut -d. -f 1 ,2 | parallel --eta 'mv {}.txt {}.txt_tmp && patentcity utils prep-searchtext {}.txt_tmp configs/{.}.yaml >> {}.txt' for FILE in $( ls loc_*patentxx.count.txt | cut -d. -f 1 ) ; do cat ${ FILE } .count.txt | sort -nr | awk '{$1=\"\"; print $0}' | cut -c2- >> ${ FILE } .sorted.txt ; done ; # nb sorted in descending order # Now assume that you want to get 250k addresses to geocode, covering as many occurences as possible and making sure that they have not been geocoded yet # Below, we get the 275k most cited addresses (unconditional) and we keep only those which are no yet done (ie in tbd as well) # Nb requires a bit of fine tuning to make sure that we have the right nbr of lines: rm -f tmp && head -n 275000 loc_${FORMAT}.sorted.txt >> tmp && comm -13 <(sort loc_${FORMAT}.tbd.txt) <(sort tmp) | wc -l FORMAT = \"uspatentxx\" rm -f tmp && head -n 275000 loc_ ${ FORMAT } .sorted.txt >> tmp && comm -13 < ( sort loc_ ${ FORMAT } .tbd.txt ) < ( sort tmp ) | sort -r >> loc_ ${ FORMAT } .tbd.txt_00 HERE nomatch ROUND = \"\" # e.g. 00 for OFFICE in dd de fr gb us ; do patentcity utils get-recid-nomatch geoc_ ${ OFFICE } patentxx.here.csv_ ${ ROUND } .gz loc_ ${ OFFICE } patentxx.tbd.txt_ ${ ROUND } >> loc_ ${ OFFICE } patentxx.here.nomatch.txt_ ${ ROUND } ; done ;","title":"Get LOC data"},{"location":"RECIPE_PATENTCITY/#geocode-dataset","text":"Danger Take care, geocoding is not free, especially using GMAPS. Keep calm and plan your budget, you might want to ask for a grant and/or chunk the data and process it month-by-month as you free-tier gets automatically refilled. You might also want to first start with the batch geocoding API from HERE (which offers much more generous free plan) and use gmaps only for the no-match. NB: HERE batch geocoding API is supported by patentcity. HERE # Make sure that there is the appropriate header, ie recId|searchText # if not, you can use sthg in the flavor of # ls loc_*patentxx.tbd.txt_00* | parallel --eta 'mv {} {}_tmp && echo \"recId|searchText\" >> {} && cat {}_tmp >> {}' APIKEY = \"\" FILE = \"\" # e.g. loc_ddpatentxx.tbd.txt_00 CNTFOCUS = \"\" # e.g. deu echo \"FILE: ${ FILE } CNTFOCUS: ${ CNTFOCUS } \" patentcity geo here.post ${ FILE } ${ APIKEY } ${ CNTFOCUS } # print REQUESTID to stdout # monitor status REQUESTID = \"\" patentcity geo here.status $REQUESTID $APIKEY # get data and rename OUTPUTDIR = \"tmp\" mkdir -p ${ OUTPUTDIR } patentcity geo here.get ${ REQUESTID } ${ APIKEY } --output-dir ${ OUTPUTDIR } && RESULT = $( ls ${ OUTPUTDIR } / ${ REQUESTID } ) && mv ${ OUTPUTDIR } / ${ REQUESTID } / $RESULT ./ \" $( echo ${ FILE } | sed -e 's/tbd/here/g; s/txt/csv/g; s/loc/geoc/g' ) \" && echo \"Saved as $( echo ${ FILE } | sed -e 's/tbd/here/g; s/txt/csv/g; s/loc/geoc/g' ) !\" GMAPS # Geocode using GMAPS # 1-by-1 APIKEY = \"\" OFFICE = \"\" # see above REGION = \"\" # see above (nb uk for gb) ROUND = \"\" # e.g. 00 echo \"OFFICE: ${ OFFICE } REGION: ${ REGION } ROUND: ${ ROUND } \" echo \"loc_ ${ OFFICE } patentxx.here.nomatch.txt_ ${ ROUND } has $( wc -l loc_ ${ OFFICE } patentxx.here.nomatch.txt_ ${ ROUND } ) line(s)\" # better safe than sorry patentcity geo gmaps.get loc_ ${ OFFICE } patentxx.here.nomatch.txt_ ${ ROUND } ${ APIKEY } ${ REGION } >> geoc_ ${ OFFICE } patentxx.gmaps.txt_ ${ ROUND } Manual annotations # Generate manual annotations using Prodigy XX # Generate manual annotations for country codes FORMAT = \"\" # e.g. ddpatentxx patentcity utils disamb-countrycodes loc_ ${ FORMAT } .txt >> lib/loc_ ${ FORMAT } .disamb.txt # Add manual geoc FORMAT = \"\" # e.g. frpatentxx, ddpatentxx DISAMBFILE = \"\" # e.g. lib/loc_${FORMAT}.disamb.txt GEOCINDEX = \"\" # e.g. lib/geoc_${FORMAT}.disamb.index.txt lib/geoc_iso.disamb.index.txt FLAVOR = \"\" # HERE or GMAPS patentcity geo add.disamb ${ DISAMBFILE } ${ GEOCINDEX } --flavor ${ FLAVOR } >> geoc_ ${ FORMAT } .manual.txt # DISAMBFILE is a list of disambiguated loc together with their *original* hash (sep by the standard inDelim) # GEOCINDEX is the list of geoc of disambigated loc (e.g. \"r\u00e9publique f\u00e9d\u00e9rale d'allemagne\") # FLAVOR is HERE or GMAPS depending on the flavor of GEOCINDEX # The output is a GMAPS like file (md5|{})","title":"Geocode dataset"},{"location":"RECIPE_PATENTCITY/#prep-geocoded-data","text":"# Harmonize GMAPS and MANUAL as HERE geocoded data parallel --eta 'test -f geoc_{1}patentxx.gmaps.txt_{2}.gz && patentcity geo gmaps.harmonize geoc_{1}patentxx.gmaps.txt_{2}.gz --out-format csv >> geoc_{1}patentxx.gmaps.csv_{2} && gzip geoc_{1}patentxx.gmaps.csv_{2}' ::: dd de fr gb us ::: 00 01 02 MANUALDISAMB = \"fr\" for OFFICE in ${ MANUALDISAMB } ; do patentcity geo gmaps.harmonize geoc_ ${ OFFICE } patentxx.manual.txt.gz --out-format csv >> geoc_ ${ OFFICE } patentxx.manual.csv && gzip geoc_ ${ OFFICE } patentxx.manual.csv ; done ; # Stack geocoded data # we assume that there have been several rounds of geocoding (e.g. due to limited credits) and each round result is suffixed by 0x (e.g. geoc_ddpatentxx.gmaps.csv_00.gz parallel --eta 'zcat $(ls geoc_{1}patentxx.{2}.csv_*.gz | head -n 1) | head -n 1 >> geoc_{1}patentxx.{2}.csv_xx' ::: dd de fr gb us ::: gmaps here parallel --eta 'zcat geoc_{1}patentxx.{2}.csv_*.gz | grep -v \"recId\" | sort -u >> geoc_{1}patentxx.{2}.csv_xx' ::: dd de fr gb us ::: gmaps here gzip geoc_*patentxx.*.csv_xx # overwrite existing file if any # Add statistical areas parallel -j2 --eta 'patentcity geo add.statisticalareas geoc_{1}patentxx.{2}.csv_xx.gz \"assets/statisticalareas_*.csv\" >> geoc_{1}patentxx.{2}.csv_xx' ::: dd de fr gb us ::: gmaps here parallel -j2 --eta 'patentcity geo add.statisticalareas geoc_{1}patentxx.manual.csv.gz \"assets/statisticalareas_*.csv\" >> geoc_{1}patentxx.manual.csv' ::: dd fr gzip geoc_*patentxx.*.csv_xx # overwrite existing file if any gzip geoc_*patentxx.manual.csv # overwrite existing file if any","title":"Prep geocoded data"},{"location":"RECIPE_PATENTCITY/#add-geocoded-data","text":"level up Incorporating data is hard on memory. Upgrade to a 32Gb memory machine for this stage. # Incorporate geocoded data # HERE and GMAPS for OFFICE in dd de fr gb us ; do echo ${ OFFICE } patentcity geo add entrel_ ${ OFFICE } patentxx.jsonl.gz geoc_ ${ OFFICE } patentxx.here.csv_xx.gz --source HERE >> entrelgeoc_ ${ OFFICE } patentxx.jsonl_tmp && patentcity geo add entrelgeoc_ ${ OFFICE } patentxx.jsonl_tmp geoc_ ${ OFFICE } patentxx.gmaps.csv_xx.gz --source GMAPS >> entrelgeoc_ ${ OFFICE } patentxx.jsonl && rm entrelgeoc_ ${ OFFICE } patentxx.jsonl_tmp ; done ; MANUALDISAMB = \"dd fr\" # we add dd which is already in HERE like format for OFFICE in ${ MANUALDISAMB } ; do mv entrelgeoc_ ${ OFFICE } patentxx.jsonl entrelgeoc_ ${ OFFICE } patentxx.jsonl_tmp && patentcity geo add entrelgeoc_ ${ OFFICE } patentxx.jsonl_tmp geoc_ ${ OFFICE } patentxx.manual.csv.gz --source MANUAL >> entrelgeoc_ ${ OFFICE } patentxx.jsonl && rm entrelgeoc_ ${ OFFICE } patentxx.jsonl_tmp ; done ; # Add origin for file in $( ls entrelgeoc_*patentxx.jsonl ) ; do mv ${ file } ${ file } _tmp && jq -c --arg origin PC '. + {origin: $origin}' ${ file } _tmp >> ${ file } && rm ${ file } _tmp ; done ; # Prep var name ls entrelgeoc_*patentxx.jsonl | parallel --eta \"\"\"mv {} {}_tmp && sed 's/\\\"seqNumber\\\":/\\\"loc_seqNumber\\\":/g; s/\\\"seqLength\\\":/\\\"loc_seqLength\\\":/g; s/\\\"latitude\\\":/\\\"loc_latitude\\\":/g; s/\\\"longitude\\\":/\\\"loc_longitude\\\":/g; s/\\\"locationLabel\\\":/\\\"loc_locationLabel\\\":/g; s/\\\"addressLines\\\":/\\\"loc_addressLines\\\":/g; s/\\\"street\\\":/\\\"loc_street\\\":/g; s/\\\"houseNumber\\\":/\\\"loc_houseNumber\\\":/g; s/\\\"building\\\":/\\\"loc_building\\\":/g; s/\\\"subdistrict\\\":/\\\"loc_subdistrict\\\":/g; s/\\\"district\\\":/\\\"loc_district\\\":/g; s/\\\"city\\\":/\\\"loc_city\\\":/g; s/\\\"postalCode\\\":/\\\"loc_postalCode\\\":/g; s/\\\"county\\\":/\\\"loc_county\\\":/g; s/\\\"state\\\":/\\\"loc_state\\\":/g; s/\\\"country\\\":/\\\"loc_country\\\":/g; s/\\\"relevance\\\":/\\\"loc_relevance\\\":/g; s/\\\"matchType\\\":/\\\"loc_matchType\\\":/g; s/\\\"matchCode\\\":/\\\"loc_matchCode\\\":/g; s/\\\"matchLevel\\\":/\\\"loc_matchLevel\\\":/g; s/\\\"matchQualityStreet\\\":/\\\"loc_matchQualityStreet\\\":/g; s/\\\"matchQualityHouseNumber\\\":/\\\"loc_matchQualityHouseNumber\\\":/g; s/\\\"matchQualityBuilding\\\":/\\\"loc_matchQualityBuilding\\\":/g; s/\\\"matchQualityDistrict\\\":/\\\"loc_matchQualityDistrict\\\":/g; s/\\\"matchQualityCity\\\":/\\\"loc_matchQualityCity\\\":/g; s/\\\"matchQualityPostalCode\\\":/\\\"loc_matchQualityPostalCode\\\":/g; s/\\\"matchQualityCounty\\\":/\\\"loc_matchQualityCounty\\\":/g; s/\\\"matchQualityState\\\":/\\\"loc_matchQualityState\\\":/g; s/\\\"matchQualityCountry\\\":/\\\"loc_matchQualityCountry\\\":/g; s/\\\"statisticalArea1\\\":/\\\"loc_statisticalArea1\\\":/g; s/\\\"statisticalArea1Code\\\":/\\\"loc_statisticalArea1Code\\\":/g; s/\\\"statisticalArea2\\\":/\\\"loc_statisticalArea2\\\":/g; s/\\\"statisticalArea2Code\\\":/\\\"loc_statisticalArea2Code\\\":/g; s/\\\"statisticalArea3\\\":/\\\"loc_statisticalArea3\\\":/g; s/\\\"statisticalArea3Code\\\":/\\\"loc_statisticalArea3Code\\\":/g; s/\\\"key\\\":/\\\"loc_key\\\":/g ' {}_tmp >> {} \"\"\" rm entrelgeoc_*patentxx.jsonl_tmp # Sync data gsutil -m rsync ./ gs://patentcity_dev/v1/","title":"Add geocoded data"},{"location":"RECIPE_PATENTCITY/#build-data","text":"patentcity + wgp KEYFILE = \"\" # \"credentials-patentcity.json\" URIPC = \"\" # \"gs://patentcity_dev/v1/entrelgeoc_*patentxx.jsonl\" URIWGP = \"\" # \"gs://gder_dev/v100rc5/patentcity*.jsonl.gz\" STAGETABLE = \"\" #e.g \"patentcity:tmp.v100rc5\" RELEASETABLE = \"\" # \"patentcity:patentcity.v100rc5\" bq load --source_format NEWLINE_DELIMITED_JSON --replace --ignore_unknown_values --max_bad_records 10000 ${ STAGETABLE } ${ URIPC } schema/patentcity_v1.sm.json bq load --source_format NEWLINE_DELIMITED_JSON --noreplace --ignore_unknown_values --max_bad_records 1000 ${ STAGETABLE } ${ URIWGP } schema/patentcity_v1.sm.json # Augment data patentcity io augment-patentcity $( echo ${ STAGETABLE } | sed -e 's/:/./' ) $( echo ${ STAGETABLE } | sed -e 's/:/./' ) --credentials ${ KEYFILE } # Impute missing dates #for OFFICE in dd de; do # patentcity utils expand-pubdate-imputation lib/pubdate_${OFFICE}patentxx.imputation.csv --output pubdate_${OFFICE}patentxx.imputation.expanded.csv; #done; # gsutil -m cp \"pubdate_*patentxx.imputation.expanded.csv\" gs://patentcity_dev/v1/ for OFFICE in dd de ; do bq load --source_format CSV --replace --ignore_unknown_values --max_bad_records 1000 patentcity:tmp.de_pubdate_imputation \"gs://patentcity_dev/v1/pubdate_ ${ OFFICE } patentxx.imputation.expanded.csv\" schema/date_imputation.json python patentcity io impute-publication-date $( echo ${ STAGETABLE } | sed -e 's/:/./' ) patentcity.tmp. ${ OFFICE } _pubdate_imputation --country-code ${ OFFICE : u } --credentials ${ KEYFILE } ; done ; # Deduplicate data (pc, wgp25 and wgp45 have a small overlap) patentcity io deduplicate $( echo ${ STAGETABLE } | sed -e 's/:/./' ) $( echo ${ STAGETABLE } | sed -e 's/:/./' ) $KEYFILE # Expand (we use the family of publications in the dataset to expand to publications in the same family but not yet in the dataset) patentcity io family-expansion $( echo ${ STAGETABLE } | sed -e 's/:/./' ) $( echo ${ STAGETABLE } _expansion | sed -e 's/:/./' ) $KEYFILE schema/patentcity_v1.json gsutil -m rm \"gs://tmp/family_expansion_*.jsonl.gz\" bq extract --destination_format NEWLINE_DELIMITED_JSON --compression GZIP ${ STAGETABLE } _expansion \"gs://tmp/family_expansion_*.jsonl.gz\" bq load --source_format NEWLINE_DELIMITED_JSON --noreplace --ignore_unknown_values --max_bad_records 1000 $STAGETABLE \"gs://tmp/family_expansion_*.jsonl.gz\" # Filter kind codes (we have kind codes that do not correspond to utility patents - we filter them out) patentcity io filter-kind-codes $( echo ${ STAGETABLE } | sed -e 's/:/./' ) $( echo ${ RELEASETABLE } | sed -e 's/:/./' ) $KEYFILE patentcity only #STAGETABLE=\"patentcity:tmp.tmp\" URI = \"\" # e.g \"gs://patentcity_dev/v1/entrelgeoc_*patentxx.jsonl\" RELEASETABLE = \"\" # e.g. \"patentcity:patentcity.pc_v100rc5\" KEYFILE = \"\" # e.g. \"credentials-patentcity.json\" # Load data bq load --source_format NEWLINE_DELIMITED_JSON --replace --ignore_unknown_values --max_bad_records 10000 ${ RELEASETABLE } ${ URI } schema/patentcity_v1.sm.json","title":"Build data"},{"location":"RECIPE_WGP/","text":"RECIPE WGP \u00b6 Note The below snippets provide guidance for the main steps of the WGP pipeline. Join individuals and geocoded addresses \u00b6 Warning For some reasons, the flavor 25 join yields inconsistent results. We don't know why. As a turn around, we use the addresses collected by de Rassenfosse et al (2019) but we do not use their geocoding files. We geocode the addresses ourselves. wgp45 # Load individual - location_id crossover bq load --replace --source_format CSV --autodetect patentcity:external.person_location_id gs://gder_dev/person_location_id.csv.gz # Build Geoc index (patent city flavor) patentcity utils get-gmaps-index-wgp --flavor 45 addresses_florian45.csv >> addresses_florian45.jsonl patentcity geo gmaps.harmonize addresses_florian45.jsonl --out-format csv >> addresses_florian45_patentcity.csv mv addresses_florian45_patentcity.csv addresses_florian45_patentcity.tmp.csv && csvstack -n source -g GMAPS addresses_florian45_patentcity.tmp.csv >> addresses_florian45_patentcity.csv mv addresses_florian45_patentcity.csv addresses_florian45_patentcity.tmp.csv && csvstack -n origin -g WGP45 addresses_florian45_patentcity.tmp.csv >> addresses_florian45_patentcity.csv # Add statistical areas mv addresses_florian45_patentcity.csv addresses_florian45_patentcity.tmp.csv && patentcity geo add.statisticalareas addresses_florian45_patentcity.tmp.csv \"assets/statisticalareas_*.csv\" >> addresses_florian45_patentcity.csv # Load addresses gzip addresses_florian45_patentcity.csv gsutil -m cp \"addresses*patentcity.csv.gz\" gs://gder_dev/ bq load --replace --autodetect --source_format CSV --max_bad_records 100 patentcity:external.addresses_florian45_patentcity gs://gder_dev/addresses_florian45_patentcity.csv.gz # Join KEY_FILE = \"credentials-patentcity.json\" patentcity io build-wgp-as-patentcity patentcity.external.addresses_florian45_patentcity patentcity.external.person_location_id --tls206-table patentcity.external.tls206 --tls207-table patentcity.external.tls207 --patstat-patent-properties-table patentcity.external.patstat_patent_properties --destination-table patentcity.tmp.patentcity45 --flavor 45 --credentials $KEY_FILE wgp25 (fixed) # Load individual - recid crossover # TODO add `recId` to inventor_applicant_location_id.csv >> inventor_applicant_recid.csv bq load --replace --source_format CSV --autodetect patentcity:external.inventor_applicant_recid gs://gder_dev/inventor_applicant_recid.csv.gz # Build Geoc index (patent city flavor) ## extract data for OFFICE in DE FR GB US ; do python patentcity/io.py get-wgp25-recid $OFFICE patentcity.external.inventor_applicant_recid patentcity.tmp.loc_ ${ (L)OFFICE } patentwgp25 credentials-patentcity.json ; bq extract --destination_format CSV -F \"|\" patentcity:tmp.loc_ ${ (L)OFFICE } patentwgp25 gs://gder_dev/loc_ ${ (L)OFFICE } patentwgp25.txt ; done ; # Geocode ## follow the same procedure as for PatentCity see RECIPE_PATENTCITY.md ## harmonize HERE and GMAPS outputs ls geoc_*patentwgp25.gmaps.txt | cut -d. -f1,2 | parallel --eta 'patentcity geo gmaps.harmonize {}.txt --out-format csv >> {}.csv' ## remove extra recId field (returned by HERE) ls geoc_*patentwgp25.here.csv.gz | parallel --eta 'mv {} {.}.tmp.gz && csvcut -C 4 {.}.tmp.gz >> {.} && gzip {.}' # add source and origin ls geoc_*patentwgp25.here.csv.gz | parallel --eta 'mv {} {.}.tmp.gz && csvstack -n source -g HERE {.}.tmp.gz >> {.} && gzip {.}' ls geoc_*patentwgp25.gmaps.csv.gz | parallel --eta 'mv {} {.}.tmp.gz && csvstack -n source -g GMAPS {.}.tmp.gz >> {.} && gzip {.}' # pack everything together in addresses_cyril25_patentcity.csv zcat geoc_depatentwgp25.gmaps.csv.gz | head -n 1 >> addresses_cyril25_patentcity.csv # this is just the header zcat geoc_*patentwgp25.*.csv*.gz | grep -v \"recId\" | sort -u >> addresses_cyril25_patentcity.csv gzip addresses_cyril25_patentcity.csv # add origin mv addresses_cyril25_patentcity.csv.gz addresses_cyril25_patentcity.csv.tmp.gz && csvstack -n origin -g WGP25 addresses_cyril25_patentcity.csv.tmp.gz >> addresses_cyril25_patentcity.csv # Add statistical areas mv addresses_cyril25_patentcity.csv addresses_cyril25_patentcity.tmp.csv && patentcity geo add.statisticalareas addresses_cyril25_patentcity.tmp.csv \"assets/statisticalareas_*.csv\" >> addresses_cyril25_patentcity.csv gzip addresses_cyril25_patentcity.csv # Load addresses gsutil -m cp \"addresses*patentcity.csv.gz\" gs://gder_dev/ bq load --replace --autodetect --source_format CSV --max_bad_records 100 patentcity:external.addresses_cyril25_patentcity gs://gder_dev/addresses_cyril25_patentcity.csv.gz # Join KEY_FILE = \"credentials-patentcity.json\" patentcity io build-wgp-as-patentcity patentcity.external.addresses_cyril25_patentcity patentcity.external.inventor_applicant_recid --patstat-patent-properties-table patentcity.external.patstat_patent_properties --destination-table patentcity.tmp.patentcity25 --flavor 25 --credentials $KEY_FILE wgp25 (broken) # Load individual - location_id crossover bq load --replace --source_format CSV --autodetect patentcity:external.inventor_applicant_location_id gs://gder_dev/inventor_applicant_location_id.csv.gz # Build Geoc index (patent city flavor) patentcity utils get-gmaps-index-wgp --flavor 25 addresses_florian25.csv >> addresses_florian25.jsonl patentcity geo gmaps.harmonize addresses_florian25.jsonl --out-format csv >> addresses_florian25_patentcity.csv mv addresses_florian25_patentcity.csv addresses_florian25_patentcity.tmp.csv && csvstack -n source -g GMAPS addresses_florian25_patentcity.tmp.csv >> addresses_florian25_patentcity.csv mv addresses_florian25_patentcity.csv addresses_florian25_patentcity.tmp.csv && csvstack -n origin -g WGP25 addresses_florian25_patentcity.tmp.csv >> addresses_florian25_patentcity.csv # Load addresses gsutil -m cp \"addresses*patentcity.csv.gz\" gs://gder_dev/ bq load --replace --autodetect --source_format CSV --max_bad_records 100 patentcity:external.addresses_florian25_patentcity gs://gder_dev/addresses_florian25_patentcity.csv.gz # Join KEY_FILE = \"credentials-patentcity.json\" patentcity io build-wgp-as-patentcity patentcity.external.addresses_florian25_patentcity patentcity.external.inventor_applicant_location_id --patstat-patent-properties-table patentcity.external.patstat_patent_properties --destination-table patentcity.tmp.patentcity25 --flavor 25 --credentials $KEY_FILE Build data \u00b6 # Format data as patentcity v1 ## sort data (required since chunked at extraction) patentcity io order patentcity.tmp.patentcity25 --by publication_number --destination-table patentcity.tmp.tmp25 --credentials credentials-patentcity.json patentcity io order patentcity.tmp.patentcity45 --by publication_number --destination-table patentcity.tmp.tmp45 --credentials credentials-patentcity.json ## extract data gsutil -m rm \"gs://tmp/flat_patentcity*.jsonl.gz\" bq extract --destination_format NEWLINE_DELIMITED_JSON --compression GZIP patentcity:tmp.tmp25 \"gs://tmp/flat_patentcity25_*.jsonl.gz\" bq extract --destination_format NEWLINE_DELIMITED_JSON --compression GZIP patentcity:tmp.tmp45 \"gs://tmp/flat_patentcity45_*.jsonl.gz\" ## remove staged tables bq rm patentcity:tmp.tmp25 bq rm patentcity:tmp.tmp45 ## download data gsutil -m cp \"gs://tmp/flat_patentcity*.jsonl.gz\" ./ ## nest ls flat_patentcity25_*.jsonl.gz | cut -d_ -f 2 ,3 | parallel -j+0 --eta \"\"\"gunzip flat_{} && jq -s -c 'group_by(.publication_number)[] | {publication_number: .[0].publication_number, publication_date: .[0].publication_date, country_code: .[0].country_code, pubnum: .[0].pubnum, kind_code: .[0].kind_code, appln_id: .[0].appln_id, family_id: .[0].docdb_family_id, origin: .[0].origin, patentee: [ .[] | {is_inv: .is_inv, is_asg: .is_app, loc_text: .address_, loc_recId: .recId, loc_locationLabel: .locationLabel, loc_country: .country, loc_state: .state, loc_county: .county, loc_city: .city, loc_district: .district, loc_postalCode: .postalCode, loc_street: .street, loc_building: .building, loc_houseNumber: .houseNumber, loc_longitude: .longitude, loc_latitude: .latitude, loc_matchType: .matchType, loc_matchLevel: .matchLevel, loc_seqNumber: .seqNumber, loc_source: .source, loc_key: .key, loc_statisticalArea1: .statisticalArea1, loc_statisticalArea1Code: .statisticalArea1Code, loc_statisticalArea2: .statisticalArea2, loc_statisticalArea2Code: .statisticalArea2Code, loc_statisticalArea3: .statisticalArea3, loc_statisticalArea3Code: .statisticalArea3Code} ] }' flat_{.} >> {.} && gzip {.} && gzip flat_{.}\"\"\" ls flat_patentcity45_*.jsonl.gz | cut -d_ -f 2 ,3 | parallel -j+0 --eta \"\"\"gunzip flat_{} && jq -s -c 'group_by(.publication_number)[] | {publication_number: .[0].publication_number, publication_date: .[0].publication_date, country_code: .[0].country_code, pubnum: .[0].pubnum, kind_code: .[0].kind_code, appln_id: .[0].appln_id, family_id: .[0].docdb_family_id, origin: .[0].origin, patentee: [.[] | {name_text: .person_name, person_id: .person_id, is_inv: .is_inv, is_asg: .is_asg, loc_text: .address_, loc_recId: .recId, loc_locationLabel: .locationLabel, loc_country: .country, loc_state: .state, loc_county: .county, loc_city: .city, loc_district: .district, loc_postalCode: .postalCode, loc_street: .street, loc_building: .building, loc_houseNumber: .houseNumber, loc_longitude: .longitude, loc_latitude: .latitude, loc_matchType: .matchType, loc_matchLevel: .matchLevel, loc_seqNumber: .seqNumber, loc_source: .source, loc_key: .key, loc_statisticalArea1: .statisticalArea1, loc_statisticalArea1Code: .statisticalArea1Code, loc_statisticalArea2: .statisticalArea2, loc_statisticalArea2Code: .statisticalArea2Code, loc_statisticalArea3: .statisticalArea3, loc_statisticalArea3Code: .statisticalArea3Code}]}' flat_{.} >> {.} && gzip {.} && gzip flat_{.}\"\"\" ## upload data gsutil -m mv \"./patentcity*.jsonl.gz\" gs://gder_dev/v1/ # Load to BQ URI = \"\" # e.g. \"gs://gder_dev/v100rc4/patentcity*.jsonl.gz\" RELEASETABLE = \"\" #e.g. \"patentcity:patentcity.wgp_v100rc4\" bq load --source_format = NEWLINE_DELIMITED_JSON --max_bad_records = 1000 --ignore_unknown_values --replace ${ RELEASETABLE } ${ URI } schema/patentcity_v1.sm.json","title":"WGP"},{"location":"RECIPE_WGP/#recipe-wgp","text":"Note The below snippets provide guidance for the main steps of the WGP pipeline.","title":"RECIPE WGP"},{"location":"RECIPE_WGP/#join-individuals-and-geocoded-addresses","text":"Warning For some reasons, the flavor 25 join yields inconsistent results. We don't know why. As a turn around, we use the addresses collected by de Rassenfosse et al (2019) but we do not use their geocoding files. We geocode the addresses ourselves. wgp45 # Load individual - location_id crossover bq load --replace --source_format CSV --autodetect patentcity:external.person_location_id gs://gder_dev/person_location_id.csv.gz # Build Geoc index (patent city flavor) patentcity utils get-gmaps-index-wgp --flavor 45 addresses_florian45.csv >> addresses_florian45.jsonl patentcity geo gmaps.harmonize addresses_florian45.jsonl --out-format csv >> addresses_florian45_patentcity.csv mv addresses_florian45_patentcity.csv addresses_florian45_patentcity.tmp.csv && csvstack -n source -g GMAPS addresses_florian45_patentcity.tmp.csv >> addresses_florian45_patentcity.csv mv addresses_florian45_patentcity.csv addresses_florian45_patentcity.tmp.csv && csvstack -n origin -g WGP45 addresses_florian45_patentcity.tmp.csv >> addresses_florian45_patentcity.csv # Add statistical areas mv addresses_florian45_patentcity.csv addresses_florian45_patentcity.tmp.csv && patentcity geo add.statisticalareas addresses_florian45_patentcity.tmp.csv \"assets/statisticalareas_*.csv\" >> addresses_florian45_patentcity.csv # Load addresses gzip addresses_florian45_patentcity.csv gsutil -m cp \"addresses*patentcity.csv.gz\" gs://gder_dev/ bq load --replace --autodetect --source_format CSV --max_bad_records 100 patentcity:external.addresses_florian45_patentcity gs://gder_dev/addresses_florian45_patentcity.csv.gz # Join KEY_FILE = \"credentials-patentcity.json\" patentcity io build-wgp-as-patentcity patentcity.external.addresses_florian45_patentcity patentcity.external.person_location_id --tls206-table patentcity.external.tls206 --tls207-table patentcity.external.tls207 --patstat-patent-properties-table patentcity.external.patstat_patent_properties --destination-table patentcity.tmp.patentcity45 --flavor 45 --credentials $KEY_FILE wgp25 (fixed) # Load individual - recid crossover # TODO add `recId` to inventor_applicant_location_id.csv >> inventor_applicant_recid.csv bq load --replace --source_format CSV --autodetect patentcity:external.inventor_applicant_recid gs://gder_dev/inventor_applicant_recid.csv.gz # Build Geoc index (patent city flavor) ## extract data for OFFICE in DE FR GB US ; do python patentcity/io.py get-wgp25-recid $OFFICE patentcity.external.inventor_applicant_recid patentcity.tmp.loc_ ${ (L)OFFICE } patentwgp25 credentials-patentcity.json ; bq extract --destination_format CSV -F \"|\" patentcity:tmp.loc_ ${ (L)OFFICE } patentwgp25 gs://gder_dev/loc_ ${ (L)OFFICE } patentwgp25.txt ; done ; # Geocode ## follow the same procedure as for PatentCity see RECIPE_PATENTCITY.md ## harmonize HERE and GMAPS outputs ls geoc_*patentwgp25.gmaps.txt | cut -d. -f1,2 | parallel --eta 'patentcity geo gmaps.harmonize {}.txt --out-format csv >> {}.csv' ## remove extra recId field (returned by HERE) ls geoc_*patentwgp25.here.csv.gz | parallel --eta 'mv {} {.}.tmp.gz && csvcut -C 4 {.}.tmp.gz >> {.} && gzip {.}' # add source and origin ls geoc_*patentwgp25.here.csv.gz | parallel --eta 'mv {} {.}.tmp.gz && csvstack -n source -g HERE {.}.tmp.gz >> {.} && gzip {.}' ls geoc_*patentwgp25.gmaps.csv.gz | parallel --eta 'mv {} {.}.tmp.gz && csvstack -n source -g GMAPS {.}.tmp.gz >> {.} && gzip {.}' # pack everything together in addresses_cyril25_patentcity.csv zcat geoc_depatentwgp25.gmaps.csv.gz | head -n 1 >> addresses_cyril25_patentcity.csv # this is just the header zcat geoc_*patentwgp25.*.csv*.gz | grep -v \"recId\" | sort -u >> addresses_cyril25_patentcity.csv gzip addresses_cyril25_patentcity.csv # add origin mv addresses_cyril25_patentcity.csv.gz addresses_cyril25_patentcity.csv.tmp.gz && csvstack -n origin -g WGP25 addresses_cyril25_patentcity.csv.tmp.gz >> addresses_cyril25_patentcity.csv # Add statistical areas mv addresses_cyril25_patentcity.csv addresses_cyril25_patentcity.tmp.csv && patentcity geo add.statisticalareas addresses_cyril25_patentcity.tmp.csv \"assets/statisticalareas_*.csv\" >> addresses_cyril25_patentcity.csv gzip addresses_cyril25_patentcity.csv # Load addresses gsutil -m cp \"addresses*patentcity.csv.gz\" gs://gder_dev/ bq load --replace --autodetect --source_format CSV --max_bad_records 100 patentcity:external.addresses_cyril25_patentcity gs://gder_dev/addresses_cyril25_patentcity.csv.gz # Join KEY_FILE = \"credentials-patentcity.json\" patentcity io build-wgp-as-patentcity patentcity.external.addresses_cyril25_patentcity patentcity.external.inventor_applicant_recid --patstat-patent-properties-table patentcity.external.patstat_patent_properties --destination-table patentcity.tmp.patentcity25 --flavor 25 --credentials $KEY_FILE wgp25 (broken) # Load individual - location_id crossover bq load --replace --source_format CSV --autodetect patentcity:external.inventor_applicant_location_id gs://gder_dev/inventor_applicant_location_id.csv.gz # Build Geoc index (patent city flavor) patentcity utils get-gmaps-index-wgp --flavor 25 addresses_florian25.csv >> addresses_florian25.jsonl patentcity geo gmaps.harmonize addresses_florian25.jsonl --out-format csv >> addresses_florian25_patentcity.csv mv addresses_florian25_patentcity.csv addresses_florian25_patentcity.tmp.csv && csvstack -n source -g GMAPS addresses_florian25_patentcity.tmp.csv >> addresses_florian25_patentcity.csv mv addresses_florian25_patentcity.csv addresses_florian25_patentcity.tmp.csv && csvstack -n origin -g WGP25 addresses_florian25_patentcity.tmp.csv >> addresses_florian25_patentcity.csv # Load addresses gsutil -m cp \"addresses*patentcity.csv.gz\" gs://gder_dev/ bq load --replace --autodetect --source_format CSV --max_bad_records 100 patentcity:external.addresses_florian25_patentcity gs://gder_dev/addresses_florian25_patentcity.csv.gz # Join KEY_FILE = \"credentials-patentcity.json\" patentcity io build-wgp-as-patentcity patentcity.external.addresses_florian25_patentcity patentcity.external.inventor_applicant_location_id --patstat-patent-properties-table patentcity.external.patstat_patent_properties --destination-table patentcity.tmp.patentcity25 --flavor 25 --credentials $KEY_FILE","title":"Join individuals and geocoded addresses"},{"location":"RECIPE_WGP/#build-data","text":"# Format data as patentcity v1 ## sort data (required since chunked at extraction) patentcity io order patentcity.tmp.patentcity25 --by publication_number --destination-table patentcity.tmp.tmp25 --credentials credentials-patentcity.json patentcity io order patentcity.tmp.patentcity45 --by publication_number --destination-table patentcity.tmp.tmp45 --credentials credentials-patentcity.json ## extract data gsutil -m rm \"gs://tmp/flat_patentcity*.jsonl.gz\" bq extract --destination_format NEWLINE_DELIMITED_JSON --compression GZIP patentcity:tmp.tmp25 \"gs://tmp/flat_patentcity25_*.jsonl.gz\" bq extract --destination_format NEWLINE_DELIMITED_JSON --compression GZIP patentcity:tmp.tmp45 \"gs://tmp/flat_patentcity45_*.jsonl.gz\" ## remove staged tables bq rm patentcity:tmp.tmp25 bq rm patentcity:tmp.tmp45 ## download data gsutil -m cp \"gs://tmp/flat_patentcity*.jsonl.gz\" ./ ## nest ls flat_patentcity25_*.jsonl.gz | cut -d_ -f 2 ,3 | parallel -j+0 --eta \"\"\"gunzip flat_{} && jq -s -c 'group_by(.publication_number)[] | {publication_number: .[0].publication_number, publication_date: .[0].publication_date, country_code: .[0].country_code, pubnum: .[0].pubnum, kind_code: .[0].kind_code, appln_id: .[0].appln_id, family_id: .[0].docdb_family_id, origin: .[0].origin, patentee: [ .[] | {is_inv: .is_inv, is_asg: .is_app, loc_text: .address_, loc_recId: .recId, loc_locationLabel: .locationLabel, loc_country: .country, loc_state: .state, loc_county: .county, loc_city: .city, loc_district: .district, loc_postalCode: .postalCode, loc_street: .street, loc_building: .building, loc_houseNumber: .houseNumber, loc_longitude: .longitude, loc_latitude: .latitude, loc_matchType: .matchType, loc_matchLevel: .matchLevel, loc_seqNumber: .seqNumber, loc_source: .source, loc_key: .key, loc_statisticalArea1: .statisticalArea1, loc_statisticalArea1Code: .statisticalArea1Code, loc_statisticalArea2: .statisticalArea2, loc_statisticalArea2Code: .statisticalArea2Code, loc_statisticalArea3: .statisticalArea3, loc_statisticalArea3Code: .statisticalArea3Code} ] }' flat_{.} >> {.} && gzip {.} && gzip flat_{.}\"\"\" ls flat_patentcity45_*.jsonl.gz | cut -d_ -f 2 ,3 | parallel -j+0 --eta \"\"\"gunzip flat_{} && jq -s -c 'group_by(.publication_number)[] | {publication_number: .[0].publication_number, publication_date: .[0].publication_date, country_code: .[0].country_code, pubnum: .[0].pubnum, kind_code: .[0].kind_code, appln_id: .[0].appln_id, family_id: .[0].docdb_family_id, origin: .[0].origin, patentee: [.[] | {name_text: .person_name, person_id: .person_id, is_inv: .is_inv, is_asg: .is_asg, loc_text: .address_, loc_recId: .recId, loc_locationLabel: .locationLabel, loc_country: .country, loc_state: .state, loc_county: .county, loc_city: .city, loc_district: .district, loc_postalCode: .postalCode, loc_street: .street, loc_building: .building, loc_houseNumber: .houseNumber, loc_longitude: .longitude, loc_latitude: .latitude, loc_matchType: .matchType, loc_matchLevel: .matchLevel, loc_seqNumber: .seqNumber, loc_source: .source, loc_key: .key, loc_statisticalArea1: .statisticalArea1, loc_statisticalArea1Code: .statisticalArea1Code, loc_statisticalArea2: .statisticalArea2, loc_statisticalArea2Code: .statisticalArea2Code, loc_statisticalArea3: .statisticalArea3, loc_statisticalArea3Code: .statisticalArea3Code}]}' flat_{.} >> {.} && gzip {.} && gzip flat_{.}\"\"\" ## upload data gsutil -m mv \"./patentcity*.jsonl.gz\" gs://gder_dev/v1/ # Load to BQ URI = \"\" # e.g. \"gs://gder_dev/v100rc4/patentcity*.jsonl.gz\" RELEASETABLE = \"\" #e.g. \"patentcity:patentcity.wgp_v100rc4\" bq load --source_format = NEWLINE_DELIMITED_JSON --max_bad_records = 1000 --ignore_unknown_values --replace ${ RELEASETABLE } ${ URI } schema/patentcity_v1.sm.json","title":"Build data"},{"location":"RECORD_DATA/","text":"DATA \u00b6 \u2139\ufe0f File names refer to data files in gs://patentcity_dev/v1 Name Content data *patentff.txt.tar.gz tar file containing format ff office * patents ( .txt blobs) List[text] *patentff.jsonl.gz jsonl file with format ff office * patents, to be used with brew v1 {\"publication_number\": \"\", \"text\": \"\", \"hash_id\": \"\"} entrel_*patentff.jsonl.gz jsonl files of extracted entities and relations from office * patents {\"publication_number\":\"\", \"patentee\": [{}, {}]} entrelgeoc_*patentxx.jsonl.gz same but with geocoded data in addition \" \" loc_*patentxx.txt_tmp.gz loc data (extracted from entrel_*patentff.jsonl.gz ) recId | loc_text loc_*patentxx.txt.gz same but wth prepared loc text recId | loc_text loc_*patentxx.tbd.txt.gz loc data (preped) which has not been processed yet (ie tbd) recId | loc_text loc_*patentxx.tbd.txt_rr.gz loc data (preped) to be processed at round rr recId | loc_text loc_*patentxx.count.txt_tmp.gz loc data with their number of occurences #occ recId | loc_text loc_*patentxx.count.txt.gz same but loc data preped #occ recId | loc_text loc_*patentxx.sorted.txt.gz loc data (preped) unique and sorted by descending order of occurences recId | loc_text loc_*patentxx.gmaps[here].txt_tmp.gz loc data sent to gmaps[here] recId | loc_text loc_*patentxx.gmaps[here].txt.gz loc data (preped)sent to gmaps[here] recId | loc_text geoc_*patentxx.gmaps.txt.gz geocoded data using GMAPS recId {gmaps output json} geoc_*patentxx.gmaps[here].csv.gz geocoded data using GMAPS [here]& harmonized with HERE data structure ,,,","title":"DATA"},{"location":"RECORD_DATA/#data","text":"\u2139\ufe0f File names refer to data files in gs://patentcity_dev/v1 Name Content data *patentff.txt.tar.gz tar file containing format ff office * patents ( .txt blobs) List[text] *patentff.jsonl.gz jsonl file with format ff office * patents, to be used with brew v1 {\"publication_number\": \"\", \"text\": \"\", \"hash_id\": \"\"} entrel_*patentff.jsonl.gz jsonl files of extracted entities and relations from office * patents {\"publication_number\":\"\", \"patentee\": [{}, {}]} entrelgeoc_*patentxx.jsonl.gz same but with geocoded data in addition \" \" loc_*patentxx.txt_tmp.gz loc data (extracted from entrel_*patentff.jsonl.gz ) recId | loc_text loc_*patentxx.txt.gz same but wth prepared loc text recId | loc_text loc_*patentxx.tbd.txt.gz loc data (preped) which has not been processed yet (ie tbd) recId | loc_text loc_*patentxx.tbd.txt_rr.gz loc data (preped) to be processed at round rr recId | loc_text loc_*patentxx.count.txt_tmp.gz loc data with their number of occurences #occ recId | loc_text loc_*patentxx.count.txt.gz same but loc data preped #occ recId | loc_text loc_*patentxx.sorted.txt.gz loc data (preped) unique and sorted by descending order of occurences recId | loc_text loc_*patentxx.gmaps[here].txt_tmp.gz loc data sent to gmaps[here] recId | loc_text loc_*patentxx.gmaps[here].txt.gz loc data (preped)sent to gmaps[here] recId | loc_text geoc_*patentxx.gmaps.txt.gz geocoded data using GMAPS recId {gmaps output json} geoc_*patentxx.gmaps[here].csv.gz geocoded data using GMAPS [here]& harmonized with HERE data structure ,,,","title":"DATA"},{"location":"US/","text":"US OVERVIEW \u00b6 Background \u00b6 XX \ud83d\udcda Data source \u00b6 From the earliest patent that we consider US1A to patent XX (excluded), we collected image data (png) from Espacenet and OCRed the first page using Tesseract v5. Patent office Time span (publication year) Kind code(s) US 1836-1980 A ; B1,B2 * Notes : : Before 2001; *: After 2001 Publication number (range) Data source Pre-processing E.g. Format # US1A-US1583766A Espacenet OCR US75A 1 US1583767A-US1920166A Espacenet OCR US1602651A 2 US1920167A-US3554066A Espacenet OCR US2427801A 3 US3554067A-... Espacenet OCR US3564067A 4 \ud83d\ude9c Extraction schema \u00b6 See the annotation guidelines \ud83d\udd2e Models \u00b6 See the models card Other \u00b6 See the geocoding and citizenship and deduplication documentation.","title":"Overview"},{"location":"US/#us-overview","text":"","title":"US OVERVIEW"},{"location":"US/#background","text":"XX","title":"Background"},{"location":"US/#data-source","text":"From the earliest patent that we consider US1A to patent XX (excluded), we collected image data (png) from Espacenet and OCRed the first page using Tesseract v5. Patent office Time span (publication year) Kind code(s) US 1836-1980 A ; B1,B2 * Notes : : Before 2001; *: After 2001 Publication number (range) Data source Pre-processing E.g. Format # US1A-US1583766A Espacenet OCR US75A 1 US1583767A-US1920166A Espacenet OCR US1602651A 2 US1920167A-US3554066A Espacenet OCR US2427801A 3 US3554067A-... Espacenet OCR US3564067A 4","title":"\ud83d\udcda Data source"},{"location":"US/#extraction-schema","text":"See the annotation guidelines","title":"\ud83d\ude9c Extraction schema"},{"location":"US/#models","text":"See the models card","title":"\ud83d\udd2e Models"},{"location":"US/#other","text":"See the geocoding and citizenship and deduplication documentation.","title":"Other"},{"location":"US_ANNOTATION_GUIDELINES/","text":"ANNOTATION GUIDELINES \u00b6 Warning GitHub markdown does not fully support visual annotation components (e.g. entity boxes) used below. We invite user interested in the annotation guidelines to download the documents and open it in a development environment supporting extended markdown syntax (e.g. MacDown, PyCharm, etc) and/or save it as a pdf. Preliminary comments \u00b6 The patent corpus that we consider for US has 4 types of formats and spans the period 1836-1980. The formatting is different from one format to the next one. In publication prior to US1248454A, the relevant information are contained in the first paragraph and in the header (format 1), it is subsequently only contained in the header. See Figures 1,2, 3 and 4 for an example of each format type. From publication US3930271A onward, we use information provided by the USPTO in the Patentsview database. Format 1 , from 1836 to 1926 \u00b6 This first format starts with patent US1A and ends with patent US1583766A published in 1926, it is characterized by the presence of the item \"be it known\" at the top of the text. We extract 4 different \"entities\". Entity Content E.g. INV Inventor full name Be it known that I, JAMES M. GARDINER INV , ... ASG Assignee full name ASSIGNOR OF ONE-HALF TO SMITH FULMER ASG LOC Location of the inventor/assignee residing at Mikkalo, in the county of Gilliam and State of Oregon LOC CIT Citizenship of inventor JOHN SCHLATTER, a citizen of United States CIT Entities are tied together with 2 types of relations. Relation Content E.g. LOCATION Links an INV/ASG to its LOC SEDWARD WILLIAM YOUNG INV --> LOCATION --> Tytherley, Wimborne, Dorset, England LOC CITIZENSHIP Links an INV/ASG to its CIT WILLIAM H. BAKER INV --> CITIZENSHIP --> citizen of the United States CIT Format 2 , from 1926 to 1933 \u00b6 This second format starts with patent US1583767A and ends with patent US1920166A. All the information are contained in a header just below the title. We extract 4 different \"entities\". Entity Content E.g. INV Inventor full name PHILIP B. ROHNER INV OF CARROLL, IOWA ASG Assignee full name ASSIGNOR TO NICHOLAS POWER COMPANY, INC. ASG , OF NEW YORK, N. Y., SMITH FULMER ASG LOC Location of the assignee/inventor WARBEN NOBLE AND LEON W. PITTMAN, OF DETROIT, MICHIGAN LOC CIT Citizenship of assignee STOW MANUFACTURING COMPANY, OF BINGHAMTON, NEW YORK, A CORPORATION OF NEW YORK CIT Entities are tied together with 2 types of relations. Relation Content E.g. LOCATION Links an INV/ASG to its LOC ISIDOR EDWARD BRENNER INV --> LOCATION --> CHICAGO, ILLINOIS LOC CITIZENSHIP Links an ASG to its CIT EASTERN EXPANDED METAL COMPANY ASG --> CITIZENSHIP --> CORPORATION . OF MASSACHUSETTS CIT Format 3 , from 1933 to 1971 \u00b6 This third format starts with patent US1920167A and ends with patent US3554066A. The information is still in the header under the title but adopts a different formatting. Note that the ending point for format 3 is not very clear as a few publications continue to have a similar format after US3554066A, although most of them have format 4. We extract 4 different \"entities\". Entity Content E.g. INV Inventor full name Vincent S. Farricielli INV , New Haven, Conn. ASG Assignee full name assignor, by mesne assignments, to Mohasco Industries, Inc. ASG , Bridgeport, Pa. LOC Location of the assignee/inventor Hugh Graham Webster and Ray W. Thomas, Detroit, Mich LOC CIT Citizenship of assignee , assignors to Esso Research and Engineer ing Company, a corporation of Delaware CIT Entities are tied together with 2 types of relations. Relation Content E.g. LOCATION Links an INV/ASG to its LOC George Norwitz INV --> LOCATION --> Philadelphia, Pa. LOC CITIZENSHIP Links an ASG to its CIT The De Laval Separator Company ASG --> CITIZENSHIP --> Corporation of New Jersey CIT Format 4 , from 1971 \u00b6 In this fourth format, the information is structured in the front page of the patent. For these patents, the identity of the inventor and the assignee are clearly stated along with their addresses. We consider patent US3554067A to be the first patent of Format 4, but some publications are closer to format 3 even after this number. We consider all cases. We extract 4 different \"entities\". Entity Content E.g. INV Inventor full name Inventor: Vincent S. Farricielli INV , New Haven, Conn. ASG Assignee full name Assignee: Hannes Marker ASG , Garmisch-Partenkirchen Germany. LOC Location of the assignee/inventor Theodore A. Rich Scotia, N.Y. LOC Entities are tied together with 1 type of relations. Relation Content E.g. LOCATION Links an INV/ASG to its LOC Willi Wolff INV --> LOCATION --> Schildgen, Germany LOC Named Entity recognition \u00b6 Format 1 \u00b6 INV \u00b6 General case \u00b6 The tag INV refers to the full name of an inventor. This is a person that is not referred to as the assignee and is sometimes specifically referred to as the inventor. Specific cases \u00b6 Inventor in the header (example 1) Inventor in the text (example 2) Examples Inventor in header , from patent US1108402A PAUL SCHMITZ INV , OF COLOGNE-NIEHL, GERMANY Inventor in text , from patent US913422A Be it known that I, CHARLES M. McConrnok INV ASG \u00b6 General case \u00b6 The tag ASG refers to the full name of the assignee, usually a person but can also be a firm. Specific cases \u00b6 Assignee as a person (example 1) Assignee as a firm (example 2) Examples person , from patent US1030738A ASSIGNOR OF NINE THIRTY-SECONDS TO JOSEPH ANTOINE HILAIRE HEBERT ASG firm , from patent US1488673A ASSIGNOR TO MIEHELE PRINTING PRESS & MANUFACTURING COMPANY ASG LOC \u00b6 General case \u00b6 The tag LOC refers to the full location of an inventor or an assignee. The granularity of the location information is the city in the standard case. In some rare instances, the full address is given, in which case only the city/county/state/country must be labeled. Specific cases \u00b6 Location in header : the location is given in the header in the form: CITY/STATE or CITY/COUNTRY (example 1) Location in text : the location is also given in the text following the name of the inventor. The location is usually given as \"in [CITY] in the county of [COUNTY] and state of [STATE]\" (example 2) Detailed address : in some rare cases, a more detailed information is given such as the borough or the full postal address. In which case only information more aggregated than city is labeled (example 3) Examples location in header , from patent US1030738A WILLIAM. V. B. AMES, OF CHICAGO, ILLINOIS LOC location in text , from patent US1530731 resident of Osceola in the county of Clarke and State of Iowa LOC detailed address , from patent US114318 a resident of the borough of Brooklyn, county of Kings, city and State of New York LOC CIT \u00b6 General case \u00b6 The tag CIT refers either to the citizenship of the inventor (or assignee when applicable) or to the legal origin of an assignee firm. The initial a (\"a firm\", \"a citizen\") must not be labeled. Specific cases \u00b6 Citizenship of the inventor : the citizenship usually follows \"a citizen of\" (example 1), or \"a subject of\" (example 2) Assignee as a firm (example 3) Examples Citizen of , from patent US1030738A CHARLES B. CLEMENTS, a citizen of the United States CIT Subject of , from patent US1244286A Joseph C. Breinl, a subject of the Emperor of Austria CIT Firm , from patent US1488673A AMERICAN GRAPHOPHONE COMPANY, OF BRIDGEPORT, CONNECTICUT, A CORPORATION OF WEST VIRGINIA CIT Format 2 \u00b6 INV \u00b6 General case \u00b6 The tag INV refers to the full name of an inventor. This is a person that is not referred to as the assignee and is sometimes specifically referred to as the inventor. Examples Standard Case , from patent US1634855 OSCAR SIVERTZEN INV , OF TRONDHJEM, NORWAY ASG \u00b6 General case \u00b6 XX Specific cases \u00b6 Person Assignee : Some patents report that a person (not the inventor) has some rights over the patent. See example 2. Examples Standard Case , from patent US198045 MARCUS B.BERHMAN, OF BROOKLYN, NEW YORK, ASSIGNOR TO THE LOX SEAL CORPORATION ASG , OF BROOKLYN, NEW YORK, A CORPORATION OF NEW YORK Person Assignee , from patent US1908223 LOFTUS B.CUDDY, OF SEWICKLEY, PENNSYLVANIA, ASSIGNOR OF ONE-HALF TO KINLEY J.TENER ASG , OF PITTSBURGH, PENNSYLVANIA LOC \u00b6 General case \u00b6 XX Specific cases \u00b6 Location of inventor and assignee (example 1) Location of the inventor : in the case where there is no assignee, only the location of the inventor is available (example 2). But in some case, the location of the assignee is not given even if there is an assignee (example 3). Examples Location of inventor and assignee , from patent US1861234 WILLIAM W.KNIGHT, OF CICERO, ILLINOIS LOC , ASSIGNOR TO ROTH RUBBER COMPANY, OF CICERO, ILLINOIS LOC , A CORPORATION OF ILLINOIS Location of inventor , from patent US1690033 WARREN NOBLE, OF DETROIT, MICHIGAN LOC Location of inventor with assignee , from patent US1700112 WILLIAM E. BEATTY, OF LAUREL HILL, NEW YORK LOC , ASSIGNOR TO ELEVATOR, SUPPLIES COMPANY, INC., A CORPORATION OF NEW JERSEY. CIT \u00b6 General case \u00b6 The tag CIT refers either to the citizenship of the assignee i.e. the legal origin of the firm when applicable. The initial a (\"a firm\", \"a corporation\") must not be labeled. Examples Standard Case , from patent US1832319 ASSIGNMENTS, TO UNION CARBIDE AND CARBON RESEARCH LABORATORIES, INC, OF NEW YORK, N.Y., A CORPORATION OF NEW YORK CIT Format 3 \u00b6 INV \u00b6 General case \u00b6 The tag INV refers to the full name of an inventor. This is a person that is not referred to as the assignee and is sometimes specifically referred to as the inventor. Examples Standard Case , from patent US2924015 Richard M.Gurries INV , San Jose, Calif. ASG \u00b6 General case \u00b6 The tag ASG refers to the full name of the assignee, usually a person but can also be a firm. Examples Standard Case , from patent US2831921 Samuel P.Morgan, Jr., Morristown, NJ, assignor to Bell Telephone Laboratories, Incorporated ASG , New York, NY, a corporation of New York LOC \u00b6 General case \u00b6 The tag LOC refers to the location of the inventor or assignee and is given by the city and state. The state itself is given as the US Government Printing Office code (GPO). Examples Standard Case , from patent US2224950 Alfred Burke, New York, N.Y LOC CIT \u00b6 General case \u00b6 The tag CIT refers either to the citizenship of the assignee i.e. the legal origin of the firm when applicable. The initial a (\"a firm\", \"a corporation\") must not be labeled. Examples Standard Case , from patent US2924016 Richard Diener, Berlin-Hermsdorf, Germany, assignor to Berliner Maschinenbau-Actien-Gesellschaft, Berlin, Germany, a corporation of Germany CIT Format 4 \u00b6 INV \u00b6 General case \u00b6 The tag INV refers to the full name of an inventor. Specific cases \u00b6 Format 3: the format 3 corresponds to a format that is very close the format 3 describes above (see example 1) Format 4: the standard case which is structured with a dedicated field named: inventor(s) (example 2) Deceased: in some rare case, the inventor is dead and an administrator is designated. Only the (dead) inventor should be labeled then (see example 3) Examples Format 3 , from patent US3719374A Francisco M. Serrano INV , Paris, France, assignor to Format 4 , from patent US3702536A Inventor: John W. Gregory INV , Middleburg Heights, Ohio Decreased , from patent US3718608A Inventors: Daniel W. Mason INV , Peabody; Henry H. Nester INV , deceased, late of Peabody, Mass. by Dianne L. Nester, administratrix LOC \u00b6 General case \u00b6 The tag LOC refers to the location of the inventor or assignee and is given by the city and state. Specific cases \u00b6 Format 3: the format 3 corresponds to a format that is very close the format 3 describes above (see example 1) Format 4: the standard case which is structured. The location appears in the field inventor and/or assignee (example 2) all of / both of: in some cases with multiple inventors, the location is designated in two times (INV1, [CITY] and INV2, [CITY], both of [STATE]) (see example 3). Full address: in some cases, the full postal address is given. In this case, only the city and more aggregated geographical entities should be labeled (see example 4). Examples Format 3 , from patent US3702735A Andrew E. Potter, Jr., Houston, Tex LOC Format 4 , from patent US3692296 Inventor: William W. Higginbotham, Monroe, Mich. LOC all of , from patent US3697893A James L. Faustlin, Plano LOC ; Eliseo Saenz, Garland LOC , both of Tex LOC full address , from patent US3624981A Arthur Fischer, Altheimer Strasse 219, Tumlingen , Germany LOC ASG \u00b6 General case \u00b6 The tag ASG refers either to the name of the assignee. Specific cases \u00b6 Format 3: the format 3 corresponds to a format that is very close the format 3 describes above (see example 1) Format 4: the standard case which is structured with a dedicated field named: assignee (example 2) The United States of America: when the assignee is part of the government, the assignee is referred to as \"the United States of America, as represented by XX\". In such a case, only \"the United States of America\" should be labeled (example 3) do not tag the representant Examples Format 3 , from patent US3608112A Finn T. Ergens, Milwaukeee, Wis., assignor to Outboard Marine Corporation ASG , Milwaukee, Wis. Format 4 , from patent US3621396A Assignee: Bell Telephone Laboratory, Inc. ASG USA , from patent US3722202A Assignee: The United States of America ASG as represented by the Secretary of Agriculture Relationships \u00b6 See the common annotation guidelines . Examples \u00b6 Figure 1: US1248454 \u00b6 Figure 2: US1612578 \u00b6 Figure 3: US2954064 \u00b6 Figure 4: US-3578005 \u00b6","title":"Annotation Guidelines"},{"location":"US_ANNOTATION_GUIDELINES/#annotation-guidelines","text":"Warning GitHub markdown does not fully support visual annotation components (e.g. entity boxes) used below. We invite user interested in the annotation guidelines to download the documents and open it in a development environment supporting extended markdown syntax (e.g. MacDown, PyCharm, etc) and/or save it as a pdf.","title":"ANNOTATION GUIDELINES"},{"location":"US_ANNOTATION_GUIDELINES/#preliminary-comments","text":"The patent corpus that we consider for US has 4 types of formats and spans the period 1836-1980. The formatting is different from one format to the next one. In publication prior to US1248454A, the relevant information are contained in the first paragraph and in the header (format 1), it is subsequently only contained in the header. See Figures 1,2, 3 and 4 for an example of each format type. From publication US3930271A onward, we use information provided by the USPTO in the Patentsview database.","title":"Preliminary comments"},{"location":"US_ANNOTATION_GUIDELINES/#format-1-from-1836-to-1926","text":"This first format starts with patent US1A and ends with patent US1583766A published in 1926, it is characterized by the presence of the item \"be it known\" at the top of the text. We extract 4 different \"entities\". Entity Content E.g. INV Inventor full name Be it known that I, JAMES M. GARDINER INV , ... ASG Assignee full name ASSIGNOR OF ONE-HALF TO SMITH FULMER ASG LOC Location of the inventor/assignee residing at Mikkalo, in the county of Gilliam and State of Oregon LOC CIT Citizenship of inventor JOHN SCHLATTER, a citizen of United States CIT Entities are tied together with 2 types of relations. Relation Content E.g. LOCATION Links an INV/ASG to its LOC SEDWARD WILLIAM YOUNG INV --> LOCATION --> Tytherley, Wimborne, Dorset, England LOC CITIZENSHIP Links an INV/ASG to its CIT WILLIAM H. BAKER INV --> CITIZENSHIP --> citizen of the United States CIT","title":"Format 1, from 1836 to 1926"},{"location":"US_ANNOTATION_GUIDELINES/#format-2-from-1926-to-1933","text":"This second format starts with patent US1583767A and ends with patent US1920166A. All the information are contained in a header just below the title. We extract 4 different \"entities\". Entity Content E.g. INV Inventor full name PHILIP B. ROHNER INV OF CARROLL, IOWA ASG Assignee full name ASSIGNOR TO NICHOLAS POWER COMPANY, INC. ASG , OF NEW YORK, N. Y., SMITH FULMER ASG LOC Location of the assignee/inventor WARBEN NOBLE AND LEON W. PITTMAN, OF DETROIT, MICHIGAN LOC CIT Citizenship of assignee STOW MANUFACTURING COMPANY, OF BINGHAMTON, NEW YORK, A CORPORATION OF NEW YORK CIT Entities are tied together with 2 types of relations. Relation Content E.g. LOCATION Links an INV/ASG to its LOC ISIDOR EDWARD BRENNER INV --> LOCATION --> CHICAGO, ILLINOIS LOC CITIZENSHIP Links an ASG to its CIT EASTERN EXPANDED METAL COMPANY ASG --> CITIZENSHIP --> CORPORATION . OF MASSACHUSETTS CIT","title":"Format 2, from 1926 to 1933"},{"location":"US_ANNOTATION_GUIDELINES/#format-3-from-1933-to-1971","text":"This third format starts with patent US1920167A and ends with patent US3554066A. The information is still in the header under the title but adopts a different formatting. Note that the ending point for format 3 is not very clear as a few publications continue to have a similar format after US3554066A, although most of them have format 4. We extract 4 different \"entities\". Entity Content E.g. INV Inventor full name Vincent S. Farricielli INV , New Haven, Conn. ASG Assignee full name assignor, by mesne assignments, to Mohasco Industries, Inc. ASG , Bridgeport, Pa. LOC Location of the assignee/inventor Hugh Graham Webster and Ray W. Thomas, Detroit, Mich LOC CIT Citizenship of assignee , assignors to Esso Research and Engineer ing Company, a corporation of Delaware CIT Entities are tied together with 2 types of relations. Relation Content E.g. LOCATION Links an INV/ASG to its LOC George Norwitz INV --> LOCATION --> Philadelphia, Pa. LOC CITIZENSHIP Links an ASG to its CIT The De Laval Separator Company ASG --> CITIZENSHIP --> Corporation of New Jersey CIT","title":"Format 3, from 1933 to 1971"},{"location":"US_ANNOTATION_GUIDELINES/#format-4-from-1971","text":"In this fourth format, the information is structured in the front page of the patent. For these patents, the identity of the inventor and the assignee are clearly stated along with their addresses. We consider patent US3554067A to be the first patent of Format 4, but some publications are closer to format 3 even after this number. We consider all cases. We extract 4 different \"entities\". Entity Content E.g. INV Inventor full name Inventor: Vincent S. Farricielli INV , New Haven, Conn. ASG Assignee full name Assignee: Hannes Marker ASG , Garmisch-Partenkirchen Germany. LOC Location of the assignee/inventor Theodore A. Rich Scotia, N.Y. LOC Entities are tied together with 1 type of relations. Relation Content E.g. LOCATION Links an INV/ASG to its LOC Willi Wolff INV --> LOCATION --> Schildgen, Germany LOC","title":"Format 4, from 1971"},{"location":"US_ANNOTATION_GUIDELINES/#named-entity-recognition","text":"","title":"Named Entity recognition"},{"location":"US_ANNOTATION_GUIDELINES/#format-1","text":"","title":"Format 1"},{"location":"US_ANNOTATION_GUIDELINES/#inv","text":"","title":"INV"},{"location":"US_ANNOTATION_GUIDELINES/#general-case","text":"The tag INV refers to the full name of an inventor. This is a person that is not referred to as the assignee and is sometimes specifically referred to as the inventor.","title":"General case"},{"location":"US_ANNOTATION_GUIDELINES/#specific-cases","text":"Inventor in the header (example 1) Inventor in the text (example 2) Examples Inventor in header , from patent US1108402A PAUL SCHMITZ INV , OF COLOGNE-NIEHL, GERMANY Inventor in text , from patent US913422A Be it known that I, CHARLES M. McConrnok INV","title":"Specific cases"},{"location":"US_ANNOTATION_GUIDELINES/#asg","text":"","title":"ASG"},{"location":"US_ANNOTATION_GUIDELINES/#general-case_1","text":"The tag ASG refers to the full name of the assignee, usually a person but can also be a firm.","title":"General case"},{"location":"US_ANNOTATION_GUIDELINES/#specific-cases_1","text":"Assignee as a person (example 1) Assignee as a firm (example 2) Examples person , from patent US1030738A ASSIGNOR OF NINE THIRTY-SECONDS TO JOSEPH ANTOINE HILAIRE HEBERT ASG firm , from patent US1488673A ASSIGNOR TO MIEHELE PRINTING PRESS & MANUFACTURING COMPANY ASG","title":"Specific cases"},{"location":"US_ANNOTATION_GUIDELINES/#loc","text":"","title":"LOC"},{"location":"US_ANNOTATION_GUIDELINES/#general-case_2","text":"The tag LOC refers to the full location of an inventor or an assignee. The granularity of the location information is the city in the standard case. In some rare instances, the full address is given, in which case only the city/county/state/country must be labeled.","title":"General case"},{"location":"US_ANNOTATION_GUIDELINES/#specific-cases_2","text":"Location in header : the location is given in the header in the form: CITY/STATE or CITY/COUNTRY (example 1) Location in text : the location is also given in the text following the name of the inventor. The location is usually given as \"in [CITY] in the county of [COUNTY] and state of [STATE]\" (example 2) Detailed address : in some rare cases, a more detailed information is given such as the borough or the full postal address. In which case only information more aggregated than city is labeled (example 3) Examples location in header , from patent US1030738A WILLIAM. V. B. AMES, OF CHICAGO, ILLINOIS LOC location in text , from patent US1530731 resident of Osceola in the county of Clarke and State of Iowa LOC detailed address , from patent US114318 a resident of the borough of Brooklyn, county of Kings, city and State of New York LOC","title":"Specific cases"},{"location":"US_ANNOTATION_GUIDELINES/#cit","text":"","title":"CIT"},{"location":"US_ANNOTATION_GUIDELINES/#general-case_3","text":"The tag CIT refers either to the citizenship of the inventor (or assignee when applicable) or to the legal origin of an assignee firm. The initial a (\"a firm\", \"a citizen\") must not be labeled.","title":"General case"},{"location":"US_ANNOTATION_GUIDELINES/#specific-cases_3","text":"Citizenship of the inventor : the citizenship usually follows \"a citizen of\" (example 1), or \"a subject of\" (example 2) Assignee as a firm (example 3) Examples Citizen of , from patent US1030738A CHARLES B. CLEMENTS, a citizen of the United States CIT Subject of , from patent US1244286A Joseph C. Breinl, a subject of the Emperor of Austria CIT Firm , from patent US1488673A AMERICAN GRAPHOPHONE COMPANY, OF BRIDGEPORT, CONNECTICUT, A CORPORATION OF WEST VIRGINIA CIT","title":"Specific cases"},{"location":"US_ANNOTATION_GUIDELINES/#format-2","text":"","title":"Format 2"},{"location":"US_ANNOTATION_GUIDELINES/#inv_1","text":"","title":"INV"},{"location":"US_ANNOTATION_GUIDELINES/#general-case_4","text":"The tag INV refers to the full name of an inventor. This is a person that is not referred to as the assignee and is sometimes specifically referred to as the inventor. Examples Standard Case , from patent US1634855 OSCAR SIVERTZEN INV , OF TRONDHJEM, NORWAY","title":"General case"},{"location":"US_ANNOTATION_GUIDELINES/#asg_1","text":"","title":"ASG"},{"location":"US_ANNOTATION_GUIDELINES/#general-case_5","text":"XX","title":"General case"},{"location":"US_ANNOTATION_GUIDELINES/#specific-cases_4","text":"Person Assignee : Some patents report that a person (not the inventor) has some rights over the patent. See example 2. Examples Standard Case , from patent US198045 MARCUS B.BERHMAN, OF BROOKLYN, NEW YORK, ASSIGNOR TO THE LOX SEAL CORPORATION ASG , OF BROOKLYN, NEW YORK, A CORPORATION OF NEW YORK Person Assignee , from patent US1908223 LOFTUS B.CUDDY, OF SEWICKLEY, PENNSYLVANIA, ASSIGNOR OF ONE-HALF TO KINLEY J.TENER ASG , OF PITTSBURGH, PENNSYLVANIA","title":"Specific cases"},{"location":"US_ANNOTATION_GUIDELINES/#loc_1","text":"","title":"LOC"},{"location":"US_ANNOTATION_GUIDELINES/#general-case_6","text":"XX","title":"General case"},{"location":"US_ANNOTATION_GUIDELINES/#specific-cases_5","text":"Location of inventor and assignee (example 1) Location of the inventor : in the case where there is no assignee, only the location of the inventor is available (example 2). But in some case, the location of the assignee is not given even if there is an assignee (example 3). Examples Location of inventor and assignee , from patent US1861234 WILLIAM W.KNIGHT, OF CICERO, ILLINOIS LOC , ASSIGNOR TO ROTH RUBBER COMPANY, OF CICERO, ILLINOIS LOC , A CORPORATION OF ILLINOIS Location of inventor , from patent US1690033 WARREN NOBLE, OF DETROIT, MICHIGAN LOC Location of inventor with assignee , from patent US1700112 WILLIAM E. BEATTY, OF LAUREL HILL, NEW YORK LOC , ASSIGNOR TO ELEVATOR, SUPPLIES COMPANY, INC., A CORPORATION OF NEW JERSEY.","title":"Specific cases"},{"location":"US_ANNOTATION_GUIDELINES/#cit_1","text":"","title":"CIT"},{"location":"US_ANNOTATION_GUIDELINES/#general-case_7","text":"The tag CIT refers either to the citizenship of the assignee i.e. the legal origin of the firm when applicable. The initial a (\"a firm\", \"a corporation\") must not be labeled. Examples Standard Case , from patent US1832319 ASSIGNMENTS, TO UNION CARBIDE AND CARBON RESEARCH LABORATORIES, INC, OF NEW YORK, N.Y., A CORPORATION OF NEW YORK CIT","title":"General case"},{"location":"US_ANNOTATION_GUIDELINES/#format-3","text":"","title":"Format 3"},{"location":"US_ANNOTATION_GUIDELINES/#inv_2","text":"","title":"INV"},{"location":"US_ANNOTATION_GUIDELINES/#general-case_8","text":"The tag INV refers to the full name of an inventor. This is a person that is not referred to as the assignee and is sometimes specifically referred to as the inventor. Examples Standard Case , from patent US2924015 Richard M.Gurries INV , San Jose, Calif.","title":"General case"},{"location":"US_ANNOTATION_GUIDELINES/#asg_2","text":"","title":"ASG"},{"location":"US_ANNOTATION_GUIDELINES/#general-case_9","text":"The tag ASG refers to the full name of the assignee, usually a person but can also be a firm. Examples Standard Case , from patent US2831921 Samuel P.Morgan, Jr., Morristown, NJ, assignor to Bell Telephone Laboratories, Incorporated ASG , New York, NY, a corporation of New York","title":"General case"},{"location":"US_ANNOTATION_GUIDELINES/#loc_2","text":"","title":"LOC"},{"location":"US_ANNOTATION_GUIDELINES/#general-case_10","text":"The tag LOC refers to the location of the inventor or assignee and is given by the city and state. The state itself is given as the US Government Printing Office code (GPO). Examples Standard Case , from patent US2224950 Alfred Burke, New York, N.Y LOC","title":"General case"},{"location":"US_ANNOTATION_GUIDELINES/#cit_2","text":"","title":"CIT"},{"location":"US_ANNOTATION_GUIDELINES/#general-case_11","text":"The tag CIT refers either to the citizenship of the assignee i.e. the legal origin of the firm when applicable. The initial a (\"a firm\", \"a corporation\") must not be labeled. Examples Standard Case , from patent US2924016 Richard Diener, Berlin-Hermsdorf, Germany, assignor to Berliner Maschinenbau-Actien-Gesellschaft, Berlin, Germany, a corporation of Germany CIT","title":"General case"},{"location":"US_ANNOTATION_GUIDELINES/#format-4","text":"","title":"Format 4"},{"location":"US_ANNOTATION_GUIDELINES/#inv_3","text":"","title":"INV"},{"location":"US_ANNOTATION_GUIDELINES/#general-case_12","text":"The tag INV refers to the full name of an inventor.","title":"General case"},{"location":"US_ANNOTATION_GUIDELINES/#specific-cases_6","text":"Format 3: the format 3 corresponds to a format that is very close the format 3 describes above (see example 1) Format 4: the standard case which is structured with a dedicated field named: inventor(s) (example 2) Deceased: in some rare case, the inventor is dead and an administrator is designated. Only the (dead) inventor should be labeled then (see example 3) Examples Format 3 , from patent US3719374A Francisco M. Serrano INV , Paris, France, assignor to Format 4 , from patent US3702536A Inventor: John W. Gregory INV , Middleburg Heights, Ohio Decreased , from patent US3718608A Inventors: Daniel W. Mason INV , Peabody; Henry H. Nester INV , deceased, late of Peabody, Mass. by Dianne L. Nester, administratrix","title":"Specific cases"},{"location":"US_ANNOTATION_GUIDELINES/#loc_3","text":"","title":"LOC"},{"location":"US_ANNOTATION_GUIDELINES/#general-case_13","text":"The tag LOC refers to the location of the inventor or assignee and is given by the city and state.","title":"General case"},{"location":"US_ANNOTATION_GUIDELINES/#specific-cases_7","text":"Format 3: the format 3 corresponds to a format that is very close the format 3 describes above (see example 1) Format 4: the standard case which is structured. The location appears in the field inventor and/or assignee (example 2) all of / both of: in some cases with multiple inventors, the location is designated in two times (INV1, [CITY] and INV2, [CITY], both of [STATE]) (see example 3). Full address: in some cases, the full postal address is given. In this case, only the city and more aggregated geographical entities should be labeled (see example 4). Examples Format 3 , from patent US3702735A Andrew E. Potter, Jr., Houston, Tex LOC Format 4 , from patent US3692296 Inventor: William W. Higginbotham, Monroe, Mich. LOC all of , from patent US3697893A James L. Faustlin, Plano LOC ; Eliseo Saenz, Garland LOC , both of Tex LOC full address , from patent US3624981A Arthur Fischer, Altheimer Strasse 219, Tumlingen , Germany LOC","title":"Specific cases"},{"location":"US_ANNOTATION_GUIDELINES/#asg_3","text":"","title":"ASG"},{"location":"US_ANNOTATION_GUIDELINES/#general-case_14","text":"The tag ASG refers either to the name of the assignee.","title":"General case"},{"location":"US_ANNOTATION_GUIDELINES/#specific-cases_8","text":"Format 3: the format 3 corresponds to a format that is very close the format 3 describes above (see example 1) Format 4: the standard case which is structured with a dedicated field named: assignee (example 2) The United States of America: when the assignee is part of the government, the assignee is referred to as \"the United States of America, as represented by XX\". In such a case, only \"the United States of America\" should be labeled (example 3) do not tag the representant Examples Format 3 , from patent US3608112A Finn T. Ergens, Milwaukeee, Wis., assignor to Outboard Marine Corporation ASG , Milwaukee, Wis. Format 4 , from patent US3621396A Assignee: Bell Telephone Laboratory, Inc. ASG USA , from patent US3722202A Assignee: The United States of America ASG as represented by the Secretary of Agriculture","title":"Specific cases"},{"location":"US_ANNOTATION_GUIDELINES/#relationships","text":"See the common annotation guidelines .","title":"Relationships"},{"location":"US_ANNOTATION_GUIDELINES/#examples","text":"","title":"Examples"},{"location":"US_ANNOTATION_GUIDELINES/#figure-1-us1248454","text":"","title":"Figure 1: US1248454"},{"location":"US_ANNOTATION_GUIDELINES/#figure-2-us1612578","text":"","title":"Figure 2: US1612578"},{"location":"US_ANNOTATION_GUIDELINES/#figure-3-us2954064","text":"","title":"Figure 3: US2954064"},{"location":"US_ANNOTATION_GUIDELINES/#figure-4-us-3578005","text":"","title":"Figure 4: US-3578005"},{"location":"US_MODEL_CARD/","text":"MODELS \u00b6 \u2139\ufe0f Model Overview \u00b6 Name en_ent_uspatent01 Language English (en) Pipeline ner Authors Bergeaud and Verluise Date (last) 02/2021 License MIT \ud83d\udc77 Training \u00b6 FORMAT = uspatent01 # uspatent02 uspatent03 uspatent04 spacy train configs/en_t2vner.cfg --paths.train data/train_ent_ ${ FORMAT } .spacy --paths.dev data/train_ent_ ${ FORMAT } .spacy --output models/de_ent_ ${ FORMAT } \ud83d\udd2e Model Performance \u00b6 en_ent_uspatent01/model-best \u00b6 ALL ASG CIT INV LOC p 0.98 0.94 0.98 1 0.98 r 0.99 0.96 0.98 0.99 0.99 f 0.99 0.95 0.98 0.99 0.99 en_ent_uspatent02/model-best \u00b6 ALL ASG CIT INV LOC p 0.98 0.96 0.98 1 0.98 r 0.99 0.96 0.97 1 0.99 f 0.98 0.96 0.98 1 0.99 en_ent_uspatent03/model-best \u00b6 ALL ASG CIT INV LOC p 0.97 0.96 0.97 0.99 0.97 r 0.97 0.96 0.97 0.98 0.98 f 0.97 0.96 0.97 0.98 0.98 en_ent_uspatent04/model-best \u00b6 ALL ASG INV LOC p 0.99 0.99 1 0.99 r 0.99 0.98 1 0.99 f 0.99 0.98 1 0.99 \ud83c\udfaf Intended use \u00b6 en_ent_uspatent* have been specifically trained on US patents. The model's performance are not guaranteed out of this scope. \ud83d\udd02 Versions and alternative approaches \u00b6 Version Comment 1.0 ent - v3 spaCy","title":"Models"},{"location":"US_MODEL_CARD/#models","text":"","title":"MODELS"},{"location":"US_MODEL_CARD/#i-model-overview","text":"Name en_ent_uspatent01 Language English (en) Pipeline ner Authors Bergeaud and Verluise Date (last) 02/2021 License MIT","title":"\u2139\ufe0f Model Overview"},{"location":"US_MODEL_CARD/#training","text":"FORMAT = uspatent01 # uspatent02 uspatent03 uspatent04 spacy train configs/en_t2vner.cfg --paths.train data/train_ent_ ${ FORMAT } .spacy --paths.dev data/train_ent_ ${ FORMAT } .spacy --output models/de_ent_ ${ FORMAT }","title":"\ud83d\udc77 Training"},{"location":"US_MODEL_CARD/#model-performance","text":"","title":"\ud83d\udd2e Model Performance"},{"location":"US_MODEL_CARD/#en_ent_uspatent01model-best","text":"ALL ASG CIT INV LOC p 0.98 0.94 0.98 1 0.98 r 0.99 0.96 0.98 0.99 0.99 f 0.99 0.95 0.98 0.99 0.99","title":"en_ent_uspatent01/model-best"},{"location":"US_MODEL_CARD/#en_ent_uspatent02model-best","text":"ALL ASG CIT INV LOC p 0.98 0.96 0.98 1 0.98 r 0.99 0.96 0.97 1 0.99 f 0.98 0.96 0.98 1 0.99","title":"en_ent_uspatent02/model-best"},{"location":"US_MODEL_CARD/#en_ent_uspatent03model-best","text":"ALL ASG CIT INV LOC p 0.97 0.96 0.97 0.99 0.97 r 0.97 0.96 0.97 0.98 0.98 f 0.97 0.96 0.97 0.98 0.98","title":"en_ent_uspatent03/model-best"},{"location":"US_MODEL_CARD/#en_ent_uspatent04model-best","text":"ALL ASG INV LOC p 0.99 0.99 1 0.99 r 0.99 0.98 1 0.99 f 0.99 0.98 1 0.99","title":"en_ent_uspatent04/model-best"},{"location":"US_MODEL_CARD/#intended-use","text":"en_ent_uspatent* have been specifically trained on US patents. The model's performance are not guaranteed out of this scope.","title":"\ud83c\udfaf Intended use"},{"location":"US_MODEL_CARD/#versions-and-alternative-approaches","text":"Version Comment 1.0 ent - v3 spaCy","title":"\ud83d\udd02 Versions and alternative approaches"},{"location":"XX_CIT_EVALUATION/","text":"CITIZENSHIP \u00b6 Problem \u00b6 The CIT text extracted from the text is just a span of natural language (e.g. \"a citizen of the United States\"). This cannot be used as such. Approach \u00b6 We use a Finite State Transducer. The task of the Finite State Transducer is to map these spans to a well definite set of codes, here the ISO-3 code of the country of citizenship (e.g. USA). Below we evaluate the FST on US and GB data. Note: since there is no \"learning\" in the FST, overfitting is not really an issue and we do not distinguish between the training and the test set. Results \u00b6 Data Accuracy with fuzzy-match Accuracy w/o no fuzzy-match gold_cit_gbpatentocr01.csv 98.50% 98.25% gold_cit_uspatentocr01.csv 98.94% 95.21% gold_cit_uspatentocr02.csv 93.40% 84.49% gold_cit_uspatentocr03.csv 92.31% 90.60% In all cases, the fuzzy-match improves the overall FST accuracy. Snippet # Eval on gold_cit_uspatentocr03.csv python patentcity/eval.py cit-fst data/gold_cit_uspatentocr03.csv --fst-file lib/cit_fst.json --verbose Error analysis \u00b6 gold_cit_gbpatentocr01.csv \u00b6 publication_number text gold pred res 54 GB-1107922-A Corporation organized. NIU False 66 GB-1124610-A citizens of the Federal -Republic of Germany DDR DEU False 67 GB-1127891-A limited liability Company OMN False 72 GB-1138246-A Corporation organised and existing under the laws of the S USA NIU False 242 GB-1474266-A British subject and New Zealand citizen NZL GBR False 320 GB-204013-A company incorporated under the laws of ureat Britain and Ireland GBR IRL False 422 GB-362896-A Limited Liability Company OMN False 442 GB-391456-A corporation organized and In NIU False 471 GB-429108-A subject of the King of Great GBR False 521 GB-508540-A Corporation organized deep achi under the laws of the State of West USA NIU False 726 GB-859666-A corporation organized and existing under the laws of the NIU False 774 GB-950313-A corporation organized the operative magnification ratio. NIU False gold_cit_uspatentocr01.csv \u00b6 publication_number text gold pred res 80 US-00832896-A1 CORPORATION OF, NEV USA False 103 US-01047532-A1 CORPORATION OF NEW USA False 173 US-01485740-A1 CORPORATION OF NEW USA False 193 US-01208544-A1 citizen of the United USA NIU False 386 US-00330257-A1 citizen of the Dominion of Can-ada CAN OMN False 431 US-01249770-A1 CORPORATION OF PENNSYL-VANTA USA False gold_cit_uspatentocr02.csv \u00b6 publication_number text gold pred res 10 US-01731832-A1 CORPORATION CF. OTLIO USA LAO False 14 US-01757421-A1 CORPORATION OF CONNECTI- USA False 64 US-01740886-A1 COR-PORATION OF GEORGIA USA GEO False 67 US-01659670-A1 CORPORATION OF ILLI-\" NOIS USA False 112 US-01838948-A1 CORPORATION OF MICHI USA False 125 US-01677149-A1 CORPORATION OF NEW USA False 126 US-01879349-A1 CORPORATION OF NEW 7 USA False 177 US-01777067-A1 CORPORATION OF NEW\" JERSEY USA JEY False 178 US-01911978-A1 CORPORATION OF NEW. JERSEY USA JEY False 179 US-01630895-A1 CORPORATION OF NEW. JERSEY USA JEY False 180 US-01859075-A1 CORPORATION OF NEW. YORE USA False 185 US-01756906-A1 CORPORATION OF NEWYORE USA False 188 US-01717493-A1 CORPORATION OF OFTO USA False 223 US-01598039-A1 CORPORATION OF PENN- USA False 237 US-01666523-A1 CORPORATION OF PENNSYL-VANTA USA False 238 US-01914412-A1 CORPORATION OF PENNSZL-VANTA USA False 239 US-01704180-A1 CORPORATION OF RHODEISLAND USA LAO False 243 US-01608767-A1 CORPORATION OF THAAS USA THA False 249 US-01717172-A1 CORPORATION OF WIs-~CONSIN USA False 284 US-01694877-A1 CORPORATIONYORK USA False gold_cit_uspatentocr03.csv \u00b6 publication_number text gold pred res 7 US-02344331-A1 corporation of Cali- USA MLI False 42 US-02437791-A1 corporation of Hlinois USA False 59 US-02905903-A1 corporation of Mlinois USA MLI False 60 US-03012554-A1 corporation of New USA False 78 US-02226153-A1 corporation of New. Jersey USA JEY False 80 US-02169128-A1 corporation of Penn- USA False 81 US-02853443-A1 corporation of Pennsyivania USA IRN False 85 US-02992650-A1 corporation of Ulinois USA False 98 US-02870832-A1 corporation ofIilinois USA FJI False","title":"Citizenship"},{"location":"XX_CIT_EVALUATION/#citizenship","text":"","title":"CITIZENSHIP"},{"location":"XX_CIT_EVALUATION/#problem","text":"The CIT text extracted from the text is just a span of natural language (e.g. \"a citizen of the United States\"). This cannot be used as such.","title":"Problem"},{"location":"XX_CIT_EVALUATION/#approach","text":"We use a Finite State Transducer. The task of the Finite State Transducer is to map these spans to a well definite set of codes, here the ISO-3 code of the country of citizenship (e.g. USA). Below we evaluate the FST on US and GB data. Note: since there is no \"learning\" in the FST, overfitting is not really an issue and we do not distinguish between the training and the test set.","title":"Approach"},{"location":"XX_CIT_EVALUATION/#results","text":"Data Accuracy with fuzzy-match Accuracy w/o no fuzzy-match gold_cit_gbpatentocr01.csv 98.50% 98.25% gold_cit_uspatentocr01.csv 98.94% 95.21% gold_cit_uspatentocr02.csv 93.40% 84.49% gold_cit_uspatentocr03.csv 92.31% 90.60% In all cases, the fuzzy-match improves the overall FST accuracy. Snippet # Eval on gold_cit_uspatentocr03.csv python patentcity/eval.py cit-fst data/gold_cit_uspatentocr03.csv --fst-file lib/cit_fst.json --verbose","title":"Results"},{"location":"XX_CIT_EVALUATION/#error-analysis","text":"","title":"Error analysis"},{"location":"XX_CIT_EVALUATION/#gold_cit_gbpatentocr01csv","text":"publication_number text gold pred res 54 GB-1107922-A Corporation organized. NIU False 66 GB-1124610-A citizens of the Federal -Republic of Germany DDR DEU False 67 GB-1127891-A limited liability Company OMN False 72 GB-1138246-A Corporation organised and existing under the laws of the S USA NIU False 242 GB-1474266-A British subject and New Zealand citizen NZL GBR False 320 GB-204013-A company incorporated under the laws of ureat Britain and Ireland GBR IRL False 422 GB-362896-A Limited Liability Company OMN False 442 GB-391456-A corporation organized and In NIU False 471 GB-429108-A subject of the King of Great GBR False 521 GB-508540-A Corporation organized deep achi under the laws of the State of West USA NIU False 726 GB-859666-A corporation organized and existing under the laws of the NIU False 774 GB-950313-A corporation organized the operative magnification ratio. NIU False","title":"gold_cit_gbpatentocr01.csv"},{"location":"XX_CIT_EVALUATION/#gold_cit_uspatentocr01csv","text":"publication_number text gold pred res 80 US-00832896-A1 CORPORATION OF, NEV USA False 103 US-01047532-A1 CORPORATION OF NEW USA False 173 US-01485740-A1 CORPORATION OF NEW USA False 193 US-01208544-A1 citizen of the United USA NIU False 386 US-00330257-A1 citizen of the Dominion of Can-ada CAN OMN False 431 US-01249770-A1 CORPORATION OF PENNSYL-VANTA USA False","title":"gold_cit_uspatentocr01.csv"},{"location":"XX_CIT_EVALUATION/#gold_cit_uspatentocr02csv","text":"publication_number text gold pred res 10 US-01731832-A1 CORPORATION CF. OTLIO USA LAO False 14 US-01757421-A1 CORPORATION OF CONNECTI- USA False 64 US-01740886-A1 COR-PORATION OF GEORGIA USA GEO False 67 US-01659670-A1 CORPORATION OF ILLI-\" NOIS USA False 112 US-01838948-A1 CORPORATION OF MICHI USA False 125 US-01677149-A1 CORPORATION OF NEW USA False 126 US-01879349-A1 CORPORATION OF NEW 7 USA False 177 US-01777067-A1 CORPORATION OF NEW\" JERSEY USA JEY False 178 US-01911978-A1 CORPORATION OF NEW. JERSEY USA JEY False 179 US-01630895-A1 CORPORATION OF NEW. JERSEY USA JEY False 180 US-01859075-A1 CORPORATION OF NEW. YORE USA False 185 US-01756906-A1 CORPORATION OF NEWYORE USA False 188 US-01717493-A1 CORPORATION OF OFTO USA False 223 US-01598039-A1 CORPORATION OF PENN- USA False 237 US-01666523-A1 CORPORATION OF PENNSYL-VANTA USA False 238 US-01914412-A1 CORPORATION OF PENNSZL-VANTA USA False 239 US-01704180-A1 CORPORATION OF RHODEISLAND USA LAO False 243 US-01608767-A1 CORPORATION OF THAAS USA THA False 249 US-01717172-A1 CORPORATION OF WIs-~CONSIN USA False 284 US-01694877-A1 CORPORATIONYORK USA False","title":"gold_cit_uspatentocr02.csv"},{"location":"XX_CIT_EVALUATION/#gold_cit_uspatentocr03csv","text":"publication_number text gold pred res 7 US-02344331-A1 corporation of Cali- USA MLI False 42 US-02437791-A1 corporation of Hlinois USA False 59 US-02905903-A1 corporation of Mlinois USA MLI False 60 US-03012554-A1 corporation of New USA False 78 US-02226153-A1 corporation of New. Jersey USA JEY False 80 US-02169128-A1 corporation of Penn- USA False 81 US-02853443-A1 corporation of Pennsyivania USA IRN False 85 US-02992650-A1 corporation of Ulinois USA False 98 US-02870832-A1 corporation ofIilinois USA FJI False","title":"gold_cit_uspatentocr03.csv"},{"location":"XX_DEDUPLICATION_EVALUATION/","text":"DEDUPLICATION \u00b6 Problem \u00b6 In some formats (e.g. uspatent01), patentees are reported twice on the same document. This can be detrimental to metrics such as the average number of inventors/assignees per patent, etc. We would like to flag duplicates to avoid results contamination. Approach \u00b6 For each patent of affected formats, we look at the pairwise relative levenshtein distance of all detected patentee names. Then we look for the threshold maximizing accuracy (based on a manually labelled gold set). Definition We call relative levenshtein distance the levenshtein distance between 2 strings (lower caps) divided by the average character lengths of the two strings Results \u00b6 uspatent01 \u00b6 Done Best threshold: 0.43 Accuracy: 0.974","title":"Deduplication"},{"location":"XX_DEDUPLICATION_EVALUATION/#deduplication","text":"","title":"DEDUPLICATION"},{"location":"XX_DEDUPLICATION_EVALUATION/#problem","text":"In some formats (e.g. uspatent01), patentees are reported twice on the same document. This can be detrimental to metrics such as the average number of inventors/assignees per patent, etc. We would like to flag duplicates to avoid results contamination.","title":"Problem"},{"location":"XX_DEDUPLICATION_EVALUATION/#approach","text":"For each patent of affected formats, we look at the pairwise relative levenshtein distance of all detected patentee names. Then we look for the threshold maximizing accuracy (based on a manually labelled gold set). Definition We call relative levenshtein distance the levenshtein distance between 2 strings (lower caps) divided by the average character lengths of the two strings","title":"Approach"},{"location":"XX_DEDUPLICATION_EVALUATION/#results","text":"","title":"Results"},{"location":"XX_DEDUPLICATION_EVALUATION/#uspatent01","text":"Done Best threshold: 0.43 Accuracy: 0.974","title":"uspatent01"},{"location":"XX_GEOC_REPORT/","text":"GEOCODING \u00b6 Patentcity \u00b6 Office Nb addresses HERE HERE no match GMAPS GMAPS no match DD 38097 38097 10945 10945 1390 DE 548606 548606 143598 143598 16158 FR 63488 63488 34490 34490 12223 GB 1177925 1177925 231331 231331 10144 US 1149671 1149671 285158 285158 20477 Total 2977787 2977787 705522 705522 60392 Round 00 \u00b6 Office Nb addresses HERE HERE no match GMAPS GMAPS no match DD 31783 31783 9097 9097 1088 DE 395635 395635 99594 99594 13989 FR 53810 53810 29332 29332 8581 GB 247173 247173 48411 48411 3308 US 247420 247420 43587 43587 2269 Total 975821 975821 230021 230021 29235 Round 01 \u00b6 Office Nb addresses HERE HERE no match GMAPS GMAPS no match DD 6315 6315 1848 1848 302 DE 152972 152972 44004 44004 2169 FR 9679 9679 5158 5158 3642 GB 373798 372996 111340 111340 1628 US 372580 372581 103398 103398 7679 Total 915344 914542 265748 265748 15420 Round 02 \u00b6 Office Nb addresses HERE HERE no match GMAPS GMAPS no match DD 0 0 0 0 0 DE 0 0 0 0 0 FR 0 0 0 0 0 GB 324271 324271 71580 71580 5208 US 464633 464633 138173 138173 10529 Total 788904 788904 209753 209753 15737 15.06.21 \u00b6 Office HERE GMAPS Comment DD 38097 10944 HERE=expected,GMAPS=expected DE 548606 172420 HERE=expected,GMAPS>expected FR 63488 34489 HERE=expected,GMAPS=expected GB 942732 230727 HERE<expected,GMAPS~expected US 1074909 281366 HERE<expected,GMAPS~expected WGP25 \u00b6 Office Nb addresses HERE HERE no match GMAPS GMAPS no match DD - - - - - DE 146987 146987 26594 26594 972 FR 238682 238682 13837 13837 389 GB 404533 404533 79903 79903 2261 US 153828 153828 1638 1638 50 Total 944030 944030 121972 121972 3672","title":"Geocoding"},{"location":"XX_GEOC_REPORT/#geocoding","text":"","title":"GEOCODING"},{"location":"XX_GEOC_REPORT/#patentcity","text":"Office Nb addresses HERE HERE no match GMAPS GMAPS no match DD 38097 38097 10945 10945 1390 DE 548606 548606 143598 143598 16158 FR 63488 63488 34490 34490 12223 GB 1177925 1177925 231331 231331 10144 US 1149671 1149671 285158 285158 20477 Total 2977787 2977787 705522 705522 60392","title":"Patentcity"},{"location":"XX_GEOC_REPORT/#round-00","text":"Office Nb addresses HERE HERE no match GMAPS GMAPS no match DD 31783 31783 9097 9097 1088 DE 395635 395635 99594 99594 13989 FR 53810 53810 29332 29332 8581 GB 247173 247173 48411 48411 3308 US 247420 247420 43587 43587 2269 Total 975821 975821 230021 230021 29235","title":"Round 00"},{"location":"XX_GEOC_REPORT/#round-01","text":"Office Nb addresses HERE HERE no match GMAPS GMAPS no match DD 6315 6315 1848 1848 302 DE 152972 152972 44004 44004 2169 FR 9679 9679 5158 5158 3642 GB 373798 372996 111340 111340 1628 US 372580 372581 103398 103398 7679 Total 915344 914542 265748 265748 15420","title":"Round 01"},{"location":"XX_GEOC_REPORT/#round-02","text":"Office Nb addresses HERE HERE no match GMAPS GMAPS no match DD 0 0 0 0 0 DE 0 0 0 0 0 FR 0 0 0 0 0 GB 324271 324271 71580 71580 5208 US 464633 464633 138173 138173 10529 Total 788904 788904 209753 209753 15737","title":"Round 02"},{"location":"XX_GEOC_REPORT/#150621","text":"Office HERE GMAPS Comment DD 38097 10944 HERE=expected,GMAPS=expected DE 548606 172420 HERE=expected,GMAPS>expected FR 63488 34489 HERE=expected,GMAPS=expected GB 942732 230727 HERE<expected,GMAPS~expected US 1074909 281366 HERE<expected,GMAPS~expected","title":"15.06.21"},{"location":"XX_GEOC_REPORT/#wgp25","text":"Office Nb addresses HERE HERE no match GMAPS GMAPS no match DD - - - - - DE 146987 146987 26594 26594 972 FR 238682 238682 13837 13837 389 GB 404533 404533 79903 79903 2261 US 153828 153828 1638 1638 50 Total 944030 944030 121972 121972 3672","title":"WGP25"},{"location":"XX_REL_ANNOTATION_GUIDELINES/","text":"ANNOTATION GUIDELINES \u00b6 Preliminary comments \u00b6 Each corpus has its specific set of relationship that are detailed in a separate documents. See DD , DE , FR , GB and US annotation guidelines General case \u00b6 The labelling of relationship between entities follow the general rule that the relation should go from the object to its attributes. For example, in the case of a link between an entity LOC and an entity INV , the relationship should go from INV to LOC . Specific casees \u00b6 From the set of annotated entities, the context should be sufficient to use the general rule without ambiguity. Standard cases are presented in Examples 1 to 3 below. Two specific cases are worth mentionning: Multiple similar objects for a given subject (e.g. two LOC for a same ASG ) Multiple subjects for a given object (e.g. two INV for a same CIT ) These cases can happen for two reasons, either because the context commands it (see examples 4 and 5) or because one of the entities has been split into multiple parts for example because of a bad OCR, or because of the wording (see example 6). In any cases, all the corresponding relationship should be annotated. Examples \u00b6 Example 1 \u00b6 Example 2 \u00b6 Example 3 \u00b6 Example 4 \u00b6 Example 5 \u00b6 Example 6 \u00b6","title":"Annotation Guidelines"},{"location":"XX_REL_ANNOTATION_GUIDELINES/#annotation-guidelines","text":"","title":"ANNOTATION GUIDELINES"},{"location":"XX_REL_ANNOTATION_GUIDELINES/#preliminary-comments","text":"Each corpus has its specific set of relationship that are detailed in a separate documents. See DD , DE , FR , GB and US annotation guidelines","title":"Preliminary comments"},{"location":"XX_REL_ANNOTATION_GUIDELINES/#general-case","text":"The labelling of relationship between entities follow the general rule that the relation should go from the object to its attributes. For example, in the case of a link between an entity LOC and an entity INV , the relationship should go from INV to LOC .","title":"General case"},{"location":"XX_REL_ANNOTATION_GUIDELINES/#specific-casees","text":"From the set of annotated entities, the context should be sufficient to use the general rule without ambiguity. Standard cases are presented in Examples 1 to 3 below. Two specific cases are worth mentionning: Multiple similar objects for a given subject (e.g. two LOC for a same ASG ) Multiple subjects for a given object (e.g. two INV for a same CIT ) These cases can happen for two reasons, either because the context commands it (see examples 4 and 5) or because one of the entities has been split into multiple parts for example because of a bad OCR, or because of the wording (see example 6). In any cases, all the corresponding relationship should be annotated.","title":"Specific casees"},{"location":"XX_REL_ANNOTATION_GUIDELINES/#examples","text":"","title":"Examples"},{"location":"XX_REL_ANNOTATION_GUIDELINES/#example-1","text":"","title":"Example 1"},{"location":"XX_REL_ANNOTATION_GUIDELINES/#example-2","text":"","title":"Example 2"},{"location":"XX_REL_ANNOTATION_GUIDELINES/#example-3","text":"","title":"Example 3"},{"location":"XX_REL_ANNOTATION_GUIDELINES/#example-4","text":"","title":"Example 4"},{"location":"XX_REL_ANNOTATION_GUIDELINES/#example-5","text":"","title":"Example 5"},{"location":"XX_REL_ANNOTATION_GUIDELINES/#example-6","text":"","title":"Example 6"},{"location":"XX_REL_CARD/","text":"MODELS \u00b6 Train and Evaluate \u00b6 # generate configs patentcity search relationship-params configs/rel_search.yaml # Grid search for all formats for FORMAT in $( cat lib/formats.txt ) ; do ls configs/rel_*.yaml | grep -v search | grep -v best | parallel --eta \"patentcity eval relationship-model data/gold_rel_ ${ FORMAT } .jsonl {} --report json>> {.}_ ${ FORMAT } .json\" && echo \"\\n## ${ FORMAT } \" >> doc/XX_REL_CARD.md && patentcity search relationship-best \"configs/rel_*_ ${ FORMAT } .json\" >> doc/XX_REL_CARD.md ; done ; # -> Fill rel_best_*.yaml using logged results in XX_REL_CARD.md # Generate CARD with best configs for FORMAT in $( cat lib/formats.txt ) ; do patentcity eval relationship-model data/gold_rel_ ${ FORMAT } .jsonl configs/rel_best_ ${ FORMAT } .yaml >> doc/XX_REL_CARD.md ; done ; ddpatent01 \u00b6 ALL LOCATION CITIZENSHIP OCCUPATION p 0.99 0.99 0.992 r 0.979 0.992 0.936 f 0.985 0.991 0.964 ddpatent02 \u00b6 ALL LOCATION CITIZENSHIP OCCUPATION p 0.907 0.981 0.767 r 0.89 0.933 0.803 f 0.899 0.956 0.785 depatent01 \u00b6 ALL LOCATION CITIZENSHIP OCCUPATION p 0.967 0.991 r 0.875 0.997 f 0.918 0.994 depatent02 \u00b6 ALL LOCATION CITIZENSHIP OCCUPATION p 0.994 0.996 0.985 r 0.988 0.987 0.992 f 0.991 0.991 0.988 frpatent01 \u00b6 ALL LOCATION CITIZENSHIP OCCUPATION p 0.99 0.99 r 0.962 0.962 f 0.976 0.976 frpatent02 \u00b6 ALL LOCATION CITIZENSHIP OCCUPATION p 0.984 0.984 r 0.997 0.997 f 0.991 0.991 gbpatent01 \u00b6 ALL LOCATION CITIZENSHIP OCCUPATION p 0.954 0.974 0.924 0.961 r 0.93 0.926 0.931 0.943 f 0.942 0.949 0.928 0.952 uspatent01 \u00b6 ALL LOCATION CITIZENSHIP OCCUPATION p 0.983 0.983 0.981 r 0.972 0.97 0.978 f 0.977 0.977 0.98 uspatent02 \u00b6 ALL LOCATION CITIZENSHIP OCCUPATION p 0.978 0.977 0.983 r 0.986 0.989 0.975 f 0.982 0.983 0.979 uspatent03 \u00b6 ALL LOCATION CITIZENSHIP OCCUPATION p 0.987 0.993 0.97 r 0.994 0.998 0.982 f 0.991 0.995 0.976 uspatent04 \u00b6 ALL LOCATION CITIZENSHIP OCCUPATION p 0.98 0.98 r 0.815 0.815 f 0.89 0.89","title":"Models"},{"location":"XX_REL_CARD/#models","text":"","title":"MODELS"},{"location":"XX_REL_CARD/#train-and-evaluate","text":"# generate configs patentcity search relationship-params configs/rel_search.yaml # Grid search for all formats for FORMAT in $( cat lib/formats.txt ) ; do ls configs/rel_*.yaml | grep -v search | grep -v best | parallel --eta \"patentcity eval relationship-model data/gold_rel_ ${ FORMAT } .jsonl {} --report json>> {.}_ ${ FORMAT } .json\" && echo \"\\n## ${ FORMAT } \" >> doc/XX_REL_CARD.md && patentcity search relationship-best \"configs/rel_*_ ${ FORMAT } .json\" >> doc/XX_REL_CARD.md ; done ; # -> Fill rel_best_*.yaml using logged results in XX_REL_CARD.md # Generate CARD with best configs for FORMAT in $( cat lib/formats.txt ) ; do patentcity eval relationship-model data/gold_rel_ ${ FORMAT } .jsonl configs/rel_best_ ${ FORMAT } .yaml >> doc/XX_REL_CARD.md ; done ;","title":"Train and Evaluate"},{"location":"XX_REL_CARD/#ddpatent01","text":"ALL LOCATION CITIZENSHIP OCCUPATION p 0.99 0.99 0.992 r 0.979 0.992 0.936 f 0.985 0.991 0.964","title":"ddpatent01"},{"location":"XX_REL_CARD/#ddpatent02","text":"ALL LOCATION CITIZENSHIP OCCUPATION p 0.907 0.981 0.767 r 0.89 0.933 0.803 f 0.899 0.956 0.785","title":"ddpatent02"},{"location":"XX_REL_CARD/#depatent01","text":"ALL LOCATION CITIZENSHIP OCCUPATION p 0.967 0.991 r 0.875 0.997 f 0.918 0.994","title":"depatent01"},{"location":"XX_REL_CARD/#depatent02","text":"ALL LOCATION CITIZENSHIP OCCUPATION p 0.994 0.996 0.985 r 0.988 0.987 0.992 f 0.991 0.991 0.988","title":"depatent02"},{"location":"XX_REL_CARD/#frpatent01","text":"ALL LOCATION CITIZENSHIP OCCUPATION p 0.99 0.99 r 0.962 0.962 f 0.976 0.976","title":"frpatent01"},{"location":"XX_REL_CARD/#frpatent02","text":"ALL LOCATION CITIZENSHIP OCCUPATION p 0.984 0.984 r 0.997 0.997 f 0.991 0.991","title":"frpatent02"},{"location":"XX_REL_CARD/#gbpatent01","text":"ALL LOCATION CITIZENSHIP OCCUPATION p 0.954 0.974 0.924 0.961 r 0.93 0.926 0.931 0.943 f 0.942 0.949 0.928 0.952","title":"gbpatent01"},{"location":"XX_REL_CARD/#uspatent01","text":"ALL LOCATION CITIZENSHIP OCCUPATION p 0.983 0.983 0.981 r 0.972 0.97 0.978 f 0.977 0.977 0.98","title":"uspatent01"},{"location":"XX_REL_CARD/#uspatent02","text":"ALL LOCATION CITIZENSHIP OCCUPATION p 0.978 0.977 0.983 r 0.986 0.989 0.975 f 0.982 0.983 0.979","title":"uspatent02"},{"location":"XX_REL_CARD/#uspatent03","text":"ALL LOCATION CITIZENSHIP OCCUPATION p 0.987 0.993 0.97 r 0.994 0.998 0.982 f 0.991 0.995 0.976","title":"uspatent03"},{"location":"XX_REL_CARD/#uspatent04","text":"ALL LOCATION CITIZENSHIP OCCUPATION p 0.98 0.98 r 0.815 0.815 f 0.89 0.89","title":"uspatent04"},{"location":"XX_STATISTICAL_AREAS/","text":"STATISTICAL AREAS \u00b6 Problem \u00b6 We harvest administrative areas from the geocoding. They are already useful, but they have some limitations. In particular, they are not fully satisgying regarding the following features: between country comparability. We would like to be able to compare countries based on comparable objects (e.g. NUTS ) common usage. We want to be able to interoperate our data with external statistics (e.g. demographic data, economic data, structural data) Approach \u00b6 We define three levels of \"statistical areas\". Level 1 is more aggregated than level 2 and so on. The below table details the statistical areas for each country. Country code Statistical area 1 Statistical area 2 Statistical area 3 DD - - - DE NUTS1 NUTS2 NUTS3 FR NUTS1 NUTS2 NUTS3 GB NUTS1 NUTS2 NUTS3 US State Commuting Zone (1990) County Info NUTS Europe (2021) Postal code to NUTS Europe (2021) County to Commuting zone (1990) Mapping key? Except for the US, we can use the postal code as the primary key for statistical areas. For the US, we us the combination of the state and county (or state and city if county is null). WITH tmp AS ( SELECT country_code , CAST ( patentee . loc_state IS NOT NULL AS INT64 ) AS has_state , CAST ( patentee . loc_county IS NOT NULL AS INT64 ) AS has_county , CAST ( patentee . loc_postalCode IS NOT NULL AS INT64 ) AS has_postalCode , FROM ` patentcity . patentcity . v100rc3 ` , UNNEST ( patentee ) AS patentee # WHERE # publication_date <= 19800000 ) SELECT country_code , SUM ( has_state ) as has_state , SUM ( has_county ) as has_county , SUM ( has_postalCode ) as has_postalCode FROM tmp GROUP BY country_code country_code has_state has_county has_postalCode DD 495479 495479 495479 DE 7284246 6555370 7366705 FR 1881112 1872960 1864284 GB 1759783 1709290 1750767 US 39675118 29133272 12382827 Related issue \u00b6 Administrative areas obtained directly from the geocoding services ( loc_state and loc_counties ) also exhibit intrinsic limitations: spelling inconsistencies between geocoding services (e.g. \"Constance\" vs \"Konstanz\") semantic inconsistencies between geocoding services (e.g. districts vs kreis as level 3 adminstritative area for DE) Although we recommend the use of statistical areas, we also propose a solution using hand-made crossover tables. We do not implement the harmonization directly in the database as this is partly destructive. The solution (and its history) is described by issue #7 .","title":"Statistical areas"},{"location":"XX_STATISTICAL_AREAS/#statistical-areas","text":"","title":"STATISTICAL AREAS"},{"location":"XX_STATISTICAL_AREAS/#problem","text":"We harvest administrative areas from the geocoding. They are already useful, but they have some limitations. In particular, they are not fully satisgying regarding the following features: between country comparability. We would like to be able to compare countries based on comparable objects (e.g. NUTS ) common usage. We want to be able to interoperate our data with external statistics (e.g. demographic data, economic data, structural data)","title":"Problem"},{"location":"XX_STATISTICAL_AREAS/#approach","text":"We define three levels of \"statistical areas\". Level 1 is more aggregated than level 2 and so on. The below table details the statistical areas for each country. Country code Statistical area 1 Statistical area 2 Statistical area 3 DD - - - DE NUTS1 NUTS2 NUTS3 FR NUTS1 NUTS2 NUTS3 GB NUTS1 NUTS2 NUTS3 US State Commuting Zone (1990) County Info NUTS Europe (2021) Postal code to NUTS Europe (2021) County to Commuting zone (1990) Mapping key? Except for the US, we can use the postal code as the primary key for statistical areas. For the US, we us the combination of the state and county (or state and city if county is null). WITH tmp AS ( SELECT country_code , CAST ( patentee . loc_state IS NOT NULL AS INT64 ) AS has_state , CAST ( patentee . loc_county IS NOT NULL AS INT64 ) AS has_county , CAST ( patentee . loc_postalCode IS NOT NULL AS INT64 ) AS has_postalCode , FROM ` patentcity . patentcity . v100rc3 ` , UNNEST ( patentee ) AS patentee # WHERE # publication_date <= 19800000 ) SELECT country_code , SUM ( has_state ) as has_state , SUM ( has_county ) as has_county , SUM ( has_postalCode ) as has_postalCode FROM tmp GROUP BY country_code country_code has_state has_county has_postalCode DD 495479 495479 495479 DE 7284246 6555370 7366705 FR 1881112 1872960 1864284 GB 1759783 1709290 1750767 US 39675118 29133272 12382827","title":"Approach"},{"location":"XX_STATISTICAL_AREAS/#related-issue","text":"Administrative areas obtained directly from the geocoding services ( loc_state and loc_counties ) also exhibit intrinsic limitations: spelling inconsistencies between geocoding services (e.g. \"Constance\" vs \"Konstanz\") semantic inconsistencies between geocoding services (e.g. districts vs kreis as level 3 adminstritative area for DE) Although we recommend the use of statistical areas, we also propose a solution using hand-made crossover tables. We do not implement the harmonization directly in the database as this is partly destructive. The solution (and its history) is described by issue #7 .","title":"Related issue"},{"location":"XX_TRUNC_REPORT/","text":"TRUNC REPORT \u00b6 format max start_span ddpatent01 600 ddpatent02 700 depatent01 400 depatent02 900 frpatent01 700 frpatent02 1100 gbpatent01 800 uspatent01 600 uspatent02 300 uspatent03 400 uspatent04 600 REPORT gold_ent_ddpatent01.jsonl \u00b6 \u2139\ufe0f Unit: char Doc lengths \u00b6 ```shell script 300 400 +++ 500 +++++++ 600 ++++++ 700 ++ 800 1300 1400 1500 1600 1700 1800 + 1900 ++ 2000 ++ 2100 2200 2300 2400 2500 2600 2700 2800 2900 3000 + 3100 ++ 3200 ++++ 3300 +++++++++ 3400 +++++++++ 3500 +++++++++ 3600 +++++++++++++ 3700 ++++++++++ 3800 +++ 3900 + 4000 4400 ### Span starts ```shell script 100 + 200 +++++++++++ 300 ++++++++++++++++++++++ 400 +++++++++++++++++++++++++++++++++++++++++++++ 500 ++++++++++++++++ 600 ++ 700 800 900 1000 1200 1300 1800 1900 2000 2100 2300 2600 3400 REPORT gold_ent_ddpatent02.jsonl \u00b6 \u2139\ufe0f Unit: char Doc lengths \u00b6 ```shell script 400 500 + 600 700 + 800 + 900 + 1000 ++ 1100 +++++ 1200 ++++++ 1300 +++++++ 1400 ++++++++++++ 1500 +++++++++ 1600 ++++++++++++ 1700 ++++++++++ 1800 ++++++++++ 1900 ++++++ 2000 ++++ 2100 ++ 2200 + 2300 2400 2500 2600 2800 ### Span starts ```shell script 100 200 + 300 ++++++++++++++++++++++ 400 ++++++++++++++++++++++++++++++++++++++++++++ 500 +++++++++++++++++++++ 600 +++++ 700 + 800 900 1000 1100 1200 1300 1400 1500 1600 1700 REPORT gold_ent_depatent01.jsonl \u00b6 \u2139\ufe0f Unit: char Doc lengths \u00b6 ```shell script 0 100 +++++ 200 +++++ 300 +++ 400 + 500 +++ 600 700 800 900 1000 1100 1200 1300 1400 + 1500 1600 1700 1800 + 1900 ++ 2000 +++ 2100 ++++ 2200 +++ 2300 +++ 2400 + 2500 + 2600 2700 + 2800 +++ 2900 +++++ 3000 +++++++ 3100 +++++++++++ 3200 ++++++++++ 3300 +++++++ 3400 +++ 3500 3600 4300 ### Span starts ```shell script 0 ++++++++++++++++++++++++ 100 +++++++++++++++++++++++++++++++++++++ 200 ++++++++++++++++++++++++++ 300 ++++++++ 400 500 800 900 1100 1200 1300 1400 1700 1800 2400 2700 2800 2900 3000 3100 3200 3300 REPORT gold_ent_depatent02.jsonl \u00b6 \u2139\ufe0f Unit: char Doc lengths \u00b6 ```shell script 300 400 +++++ 500 +++++++ 600 ++++++++++++++ 700 ++++++++++++++++++ 800 ++++++++++++++++ 900 ++++++++++ 1000 ++ 1100 1200 2300 2400 2900 3000 3200 3300 3400 3700 3800 3900 4000 4100 4200 + 4300 + 4400 +++ 4500 +++ 4600 +++ 4700 +++++ 4800 ++ 4900 + 5000 5100 ### Span starts ```shell script 0 +++ 100 ++++++++ 200 300 ++++++ 400 +++++++++++++++ 500 +++++++++++++++++ 600 +++++++++++++ 700 ++++++++ 800 ++ 900 1000 1200 1300 1400 1500 1600 1700 1800 1900 2000 2100 2200 2300 2400 2500 2600 2700 2800 +++ 2900 +++++ 3000 +++++ 3100 +++ 3200 + 3300 3400 3500 3800 REPORT gold_ent_frpatent01.jsonl \u00b6 \u2139\ufe0f Unit: char Doc lengths \u00b6 ```shell script 900 1000 1100 1200 1300 1500 1600 1700 1800 1900 2000 2100 2200 2300 2400 2500 2600 2700 + 2800 ++++ 2900 +++++++ 3000 +++++++++++++++ 3100 ++++++++++++++ 3200 +++++++ 3300 3400 3500 3600 3700 3800 3900 4000 ++ 4100 ++++ 4200 +++++ 4300 +++++++ 4400 +++++++++ 4500 ++++++ 4600 +++ 4700 + 4800 4900 ### Span starts ```shell script 0 + 100 ++++++++++++++++++++++++++ 200 ++++++++++++++++++++++++++++++++++++++++ 300 +++++++++++++++++++++ 400 +++ 500 +++ 600 + 700 800 900 1000 1100 1200 1300 1400 1500 1600 1700 1800 1900 2100 2300 2400 2500 2600 2900 3400 REPORT gold_ent_frpatent02.jsonl \u00b6 \u2139\ufe0f Unit: char Doc lengths \u00b6 ```shell script 700 +++ 800 +++++++++++++ 900 +++++++++++++++++++++++++ 1000 ++++++++++++++++++++++++ 1100 ++++++++++++++++++++ 1200 ++++++++++ 1300 + 1400 4100 4400 4500 ### Span starts ```shell script 100 200 300 400 +++ 500 +++++++++ 600 ++++++++++++++++++++++++ 700 +++++++++++++++++++++++++++++++++++++++ 800 +++++++++ 900 +++++ 1000 ++++ 1100 + 1200 1300 REPORT gold_ent_gbpatent01.jsonl \u00b6 \u2139\ufe0f Unit: char Doc lengths \u00b6 ```shell script 1000 1800 2000 2100 2200 2300 2400 2500 + 2600 + 2700 + 2800 ++ 2900 ++ 3000 + 3100 ++ 3200 ++ 3300 ++ 3400 +++ 3500 +++ 3600 +++ 3700 +++ 3800 ++++ 3900 ++++++ 4000 +++++++ 4100 ++++++++ 4200 ++++++++ 4300 +++++++++ 4400 ++++++++++ 4500 ++++++ 4600 ++ 4700 + 4800 ### Span starts ```shell script 0 ++ 100 ++++ 200 +++++++++++++++++ 300 +++++++++++++++++++++ 400 ++++++++++++++++++++++ 500 +++++++++++++ 600 +++++ 700 ++ 800 900 1000 1100 1200 1300 1400 1500 1600 1700 1800 1900 2000 2100 2200 2300 2400 2500 2600 2700 2800 2900 3000 3100 3200 3300 3400 3500 3600 3700 3800 3900 4000 4100 4200 4300 4400 REPORT gold_ent_uspatent01.jsonl \u00b6 \u2139\ufe0f Unit: char Doc lengths \u00b6 ```shell script 1700 1900 2000 2100 2200 2300 2400 2600 2700 2800 2900 + 3000 + 3100 3200 3300 3400 3500 3600 3700 3800 3900 4000 + 4100 ++ 4200 + 4300 + 4400 ++ 4500 ++++ 4600 ++++++++++ 4700 +++++++++++++ 4800 ++++++++++++++++++ 4900 +++++++++++++++++ 5000 ++++++++++ 5100 +++ 5200 5300 5400 5500 5600 5900 6000 6200 6300 ### Span starts ```shell script 0 +++++++++++++++++++++++++++++++ 100 +++++++++++++++ 200 +++++++++++++ 300 ++++++++++++++++++++++++ 400 ++++++++++ 500 + 600 700 800 900 1000 1100 1200 1500 1600 1700 1900 2000 2100 2200 2300 2400 2500 2600 2700 2800 2900 3000 3100 3200 3400 3500 3600 3700 3800 3900 4000 4100 4200 4300 4400 4500 4600 4700 4800 REPORT gold_ent_uspatent02.jsonl \u00b6 \u2139\ufe0f Unit: char Doc lengths \u00b6 ```shell script 1300 2000 2200 2800 2900 3000 3100 3200 3300 3400 3500 3600 3700 3800 3900 + 4000 + 4100 + 4200 +++ 4300 +++++++ 4400 ++++++++++++ 4500 +++++++++++++ 4600 +++++++++++++ 4700 ++++++++++++ 4800 ++++++++++ 4900 ++++++++ 5000 ++++++ 5100 +++ 5200 + 5300 ### Span starts ```shell script 0 ++++++++++++++++++++++++++++++++++++ 100 +++++++++++++++++++++++++++++++++++++++++++++++++++ 200 +++++++++ 300 600 700 1000 1900 2000 2100 2200 2300 2400 2500 2600 2800 2900 3000 3100 3200 3300 3500 3600 3800 4000 4100 4300 4400 4500 4600 4700 REPORT gold_ent_uspatent03.jsonl \u00b6 \u2139\ufe0f Unit: char Doc lengths \u00b6 ```shell script 3000 3100 3600 3800 3900 4000 4200 4300 4400 4500 4600 4700 4800 4900 ++ 5000 +++ 5100 ++++++++ 5200 +++++++++++ 5300 +++++++++++++ 5400 ++++++++++++ 5500 ++++++ 5600 +++ 5700 + 5800 + 5900 + 6000 6100 6200 6400 6500 6600 6700 6800 6900 + 7000 +++ 7100 +++ 7200 ++++ 7300 +++ 7400 ++++ 7500 ++ 7600 + 7700 7800 7900 8100 8200 8400 8500 ### Span starts ```shell script 0 +++++++ 100 ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 200 +++++++++++++++++++++ 300 + 400 500 600 700 800 1400 1500 1700 1800 2500 2600 2700 2800 2900 3100 4200 4800 5300 5400 5500 6100 6200 REPORT gold_ent_uspatent04.jsonl \u00b6 \u2139\ufe0f Unit: char Doc lengths \u00b6 ```shell script 100 800 900 1000 + 1100 +++ 1200 ++++ 1300 ++++++ 1400 ++++++++ 1500 ++++++ 1600 ++++++++ 1700 ++++++++++ 1800 ++++++ 1900 +++ 2000 ++++ 2100 +++ 2200 ++ 2300 ++ 2400 ++ 2500 + 2600 + 2700 2800 2900 3000 3100 3300 3400 3500 3600 3800 4100 4500 4800 5000 5300 5400 5500 5600 5700 5800 5900 6000 6100 6200 6300 6400 6500 6600 6700 + 6800 + 6900 + 7000 ++ 7100 ++ 7200 + 7300 + 7400 + 7500 7600 7700 ### Span starts ```shell script 0 +++++++++ 100 +++++++++++++++++++++++++++++++++++++++++++++ 200 ++++++++++++++++++++++++++++++ 300 ++++++++ 400 +++ 500 + 600 700 800 900 1000 1100 1200 1300 1400 4400","title":"TRUNC REPORT"},{"location":"XX_TRUNC_REPORT/#trunc-report","text":"format max start_span ddpatent01 600 ddpatent02 700 depatent01 400 depatent02 900 frpatent01 700 frpatent02 1100 gbpatent01 800 uspatent01 600 uspatent02 300 uspatent03 400 uspatent04 600","title":"TRUNC REPORT"},{"location":"XX_TRUNC_REPORT/#report-gold_ent_ddpatent01jsonl","text":"\u2139\ufe0f Unit: char","title":"REPORT gold_ent_ddpatent01.jsonl"},{"location":"XX_TRUNC_REPORT/#doc-lengths","text":"```shell script 300 400 +++ 500 +++++++ 600 ++++++ 700 ++ 800 1300 1400 1500 1600 1700 1800 + 1900 ++ 2000 ++ 2100 2200 2300 2400 2500 2600 2700 2800 2900 3000 + 3100 ++ 3200 ++++ 3300 +++++++++ 3400 +++++++++ 3500 +++++++++ 3600 +++++++++++++ 3700 ++++++++++ 3800 +++ 3900 + 4000 4400 ### Span starts ```shell script 100 + 200 +++++++++++ 300 ++++++++++++++++++++++ 400 +++++++++++++++++++++++++++++++++++++++++++++ 500 ++++++++++++++++ 600 ++ 700 800 900 1000 1200 1300 1800 1900 2000 2100 2300 2600 3400","title":"Doc lengths"},{"location":"XX_TRUNC_REPORT/#report-gold_ent_ddpatent02jsonl","text":"\u2139\ufe0f Unit: char","title":"REPORT gold_ent_ddpatent02.jsonl"},{"location":"XX_TRUNC_REPORT/#doc-lengths_1","text":"```shell script 400 500 + 600 700 + 800 + 900 + 1000 ++ 1100 +++++ 1200 ++++++ 1300 +++++++ 1400 ++++++++++++ 1500 +++++++++ 1600 ++++++++++++ 1700 ++++++++++ 1800 ++++++++++ 1900 ++++++ 2000 ++++ 2100 ++ 2200 + 2300 2400 2500 2600 2800 ### Span starts ```shell script 100 200 + 300 ++++++++++++++++++++++ 400 ++++++++++++++++++++++++++++++++++++++++++++ 500 +++++++++++++++++++++ 600 +++++ 700 + 800 900 1000 1100 1200 1300 1400 1500 1600 1700","title":"Doc lengths"},{"location":"XX_TRUNC_REPORT/#report-gold_ent_depatent01jsonl","text":"\u2139\ufe0f Unit: char","title":"REPORT gold_ent_depatent01.jsonl"},{"location":"XX_TRUNC_REPORT/#doc-lengths_2","text":"```shell script 0 100 +++++ 200 +++++ 300 +++ 400 + 500 +++ 600 700 800 900 1000 1100 1200 1300 1400 + 1500 1600 1700 1800 + 1900 ++ 2000 +++ 2100 ++++ 2200 +++ 2300 +++ 2400 + 2500 + 2600 2700 + 2800 +++ 2900 +++++ 3000 +++++++ 3100 +++++++++++ 3200 ++++++++++ 3300 +++++++ 3400 +++ 3500 3600 4300 ### Span starts ```shell script 0 ++++++++++++++++++++++++ 100 +++++++++++++++++++++++++++++++++++++ 200 ++++++++++++++++++++++++++ 300 ++++++++ 400 500 800 900 1100 1200 1300 1400 1700 1800 2400 2700 2800 2900 3000 3100 3200 3300","title":"Doc lengths"},{"location":"XX_TRUNC_REPORT/#report-gold_ent_depatent02jsonl","text":"\u2139\ufe0f Unit: char","title":"REPORT gold_ent_depatent02.jsonl"},{"location":"XX_TRUNC_REPORT/#doc-lengths_3","text":"```shell script 300 400 +++++ 500 +++++++ 600 ++++++++++++++ 700 ++++++++++++++++++ 800 ++++++++++++++++ 900 ++++++++++ 1000 ++ 1100 1200 2300 2400 2900 3000 3200 3300 3400 3700 3800 3900 4000 4100 4200 + 4300 + 4400 +++ 4500 +++ 4600 +++ 4700 +++++ 4800 ++ 4900 + 5000 5100 ### Span starts ```shell script 0 +++ 100 ++++++++ 200 300 ++++++ 400 +++++++++++++++ 500 +++++++++++++++++ 600 +++++++++++++ 700 ++++++++ 800 ++ 900 1000 1200 1300 1400 1500 1600 1700 1800 1900 2000 2100 2200 2300 2400 2500 2600 2700 2800 +++ 2900 +++++ 3000 +++++ 3100 +++ 3200 + 3300 3400 3500 3800","title":"Doc lengths"},{"location":"XX_TRUNC_REPORT/#report-gold_ent_frpatent01jsonl","text":"\u2139\ufe0f Unit: char","title":"REPORT gold_ent_frpatent01.jsonl"},{"location":"XX_TRUNC_REPORT/#doc-lengths_4","text":"```shell script 900 1000 1100 1200 1300 1500 1600 1700 1800 1900 2000 2100 2200 2300 2400 2500 2600 2700 + 2800 ++++ 2900 +++++++ 3000 +++++++++++++++ 3100 ++++++++++++++ 3200 +++++++ 3300 3400 3500 3600 3700 3800 3900 4000 ++ 4100 ++++ 4200 +++++ 4300 +++++++ 4400 +++++++++ 4500 ++++++ 4600 +++ 4700 + 4800 4900 ### Span starts ```shell script 0 + 100 ++++++++++++++++++++++++++ 200 ++++++++++++++++++++++++++++++++++++++++ 300 +++++++++++++++++++++ 400 +++ 500 +++ 600 + 700 800 900 1000 1100 1200 1300 1400 1500 1600 1700 1800 1900 2100 2300 2400 2500 2600 2900 3400","title":"Doc lengths"},{"location":"XX_TRUNC_REPORT/#report-gold_ent_frpatent02jsonl","text":"\u2139\ufe0f Unit: char","title":"REPORT gold_ent_frpatent02.jsonl"},{"location":"XX_TRUNC_REPORT/#doc-lengths_5","text":"```shell script 700 +++ 800 +++++++++++++ 900 +++++++++++++++++++++++++ 1000 ++++++++++++++++++++++++ 1100 ++++++++++++++++++++ 1200 ++++++++++ 1300 + 1400 4100 4400 4500 ### Span starts ```shell script 100 200 300 400 +++ 500 +++++++++ 600 ++++++++++++++++++++++++ 700 +++++++++++++++++++++++++++++++++++++++ 800 +++++++++ 900 +++++ 1000 ++++ 1100 + 1200 1300","title":"Doc lengths"},{"location":"XX_TRUNC_REPORT/#report-gold_ent_gbpatent01jsonl","text":"\u2139\ufe0f Unit: char","title":"REPORT gold_ent_gbpatent01.jsonl"},{"location":"XX_TRUNC_REPORT/#doc-lengths_6","text":"```shell script 1000 1800 2000 2100 2200 2300 2400 2500 + 2600 + 2700 + 2800 ++ 2900 ++ 3000 + 3100 ++ 3200 ++ 3300 ++ 3400 +++ 3500 +++ 3600 +++ 3700 +++ 3800 ++++ 3900 ++++++ 4000 +++++++ 4100 ++++++++ 4200 ++++++++ 4300 +++++++++ 4400 ++++++++++ 4500 ++++++ 4600 ++ 4700 + 4800 ### Span starts ```shell script 0 ++ 100 ++++ 200 +++++++++++++++++ 300 +++++++++++++++++++++ 400 ++++++++++++++++++++++ 500 +++++++++++++ 600 +++++ 700 ++ 800 900 1000 1100 1200 1300 1400 1500 1600 1700 1800 1900 2000 2100 2200 2300 2400 2500 2600 2700 2800 2900 3000 3100 3200 3300 3400 3500 3600 3700 3800 3900 4000 4100 4200 4300 4400","title":"Doc lengths"},{"location":"XX_TRUNC_REPORT/#report-gold_ent_uspatent01jsonl","text":"\u2139\ufe0f Unit: char","title":"REPORT gold_ent_uspatent01.jsonl"},{"location":"XX_TRUNC_REPORT/#doc-lengths_7","text":"```shell script 1700 1900 2000 2100 2200 2300 2400 2600 2700 2800 2900 + 3000 + 3100 3200 3300 3400 3500 3600 3700 3800 3900 4000 + 4100 ++ 4200 + 4300 + 4400 ++ 4500 ++++ 4600 ++++++++++ 4700 +++++++++++++ 4800 ++++++++++++++++++ 4900 +++++++++++++++++ 5000 ++++++++++ 5100 +++ 5200 5300 5400 5500 5600 5900 6000 6200 6300 ### Span starts ```shell script 0 +++++++++++++++++++++++++++++++ 100 +++++++++++++++ 200 +++++++++++++ 300 ++++++++++++++++++++++++ 400 ++++++++++ 500 + 600 700 800 900 1000 1100 1200 1500 1600 1700 1900 2000 2100 2200 2300 2400 2500 2600 2700 2800 2900 3000 3100 3200 3400 3500 3600 3700 3800 3900 4000 4100 4200 4300 4400 4500 4600 4700 4800","title":"Doc lengths"},{"location":"XX_TRUNC_REPORT/#report-gold_ent_uspatent02jsonl","text":"\u2139\ufe0f Unit: char","title":"REPORT gold_ent_uspatent02.jsonl"},{"location":"XX_TRUNC_REPORT/#doc-lengths_8","text":"```shell script 1300 2000 2200 2800 2900 3000 3100 3200 3300 3400 3500 3600 3700 3800 3900 + 4000 + 4100 + 4200 +++ 4300 +++++++ 4400 ++++++++++++ 4500 +++++++++++++ 4600 +++++++++++++ 4700 ++++++++++++ 4800 ++++++++++ 4900 ++++++++ 5000 ++++++ 5100 +++ 5200 + 5300 ### Span starts ```shell script 0 ++++++++++++++++++++++++++++++++++++ 100 +++++++++++++++++++++++++++++++++++++++++++++++++++ 200 +++++++++ 300 600 700 1000 1900 2000 2100 2200 2300 2400 2500 2600 2800 2900 3000 3100 3200 3300 3500 3600 3800 4000 4100 4300 4400 4500 4600 4700","title":"Doc lengths"},{"location":"XX_TRUNC_REPORT/#report-gold_ent_uspatent03jsonl","text":"\u2139\ufe0f Unit: char","title":"REPORT gold_ent_uspatent03.jsonl"},{"location":"XX_TRUNC_REPORT/#doc-lengths_9","text":"```shell script 3000 3100 3600 3800 3900 4000 4200 4300 4400 4500 4600 4700 4800 4900 ++ 5000 +++ 5100 ++++++++ 5200 +++++++++++ 5300 +++++++++++++ 5400 ++++++++++++ 5500 ++++++ 5600 +++ 5700 + 5800 + 5900 + 6000 6100 6200 6400 6500 6600 6700 6800 6900 + 7000 +++ 7100 +++ 7200 ++++ 7300 +++ 7400 ++++ 7500 ++ 7600 + 7700 7800 7900 8100 8200 8400 8500 ### Span starts ```shell script 0 +++++++ 100 ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++ 200 +++++++++++++++++++++ 300 + 400 500 600 700 800 1400 1500 1700 1800 2500 2600 2700 2800 2900 3100 4200 4800 5300 5400 5500 6100 6200","title":"Doc lengths"},{"location":"XX_TRUNC_REPORT/#report-gold_ent_uspatent04jsonl","text":"\u2139\ufe0f Unit: char","title":"REPORT gold_ent_uspatent04.jsonl"},{"location":"XX_TRUNC_REPORT/#doc-lengths_10","text":"```shell script 100 800 900 1000 + 1100 +++ 1200 ++++ 1300 ++++++ 1400 ++++++++ 1500 ++++++ 1600 ++++++++ 1700 ++++++++++ 1800 ++++++ 1900 +++ 2000 ++++ 2100 +++ 2200 ++ 2300 ++ 2400 ++ 2500 + 2600 + 2700 2800 2900 3000 3100 3300 3400 3500 3600 3800 4100 4500 4800 5000 5300 5400 5500 5600 5700 5800 5900 6000 6100 6200 6300 6400 6500 6600 6700 + 6800 + 6900 + 7000 ++ 7100 ++ 7200 + 7300 + 7400 + 7500 7600 7700 ### Span starts ```shell script 0 +++++++++ 100 +++++++++++++++++++++++++++++++++++++++++++++ 200 ++++++++++++++++++++++++++++++ 300 ++++++++ 400 +++ 500 + 600 700 800 900 1000 1100 1200 1300 1400 4400","title":"Doc lengths"}]}